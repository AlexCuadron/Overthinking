diff --git a/venv/lib/python3.9/site-packages/tomli/_re.py b/venv/lib/python3.9/site-packages/tomli/_re.py
new file mode 100644
index 000000000..513486618
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomli/_re.py
@@ -0,0 +1,112 @@
+# SPDX-License-Identifier: MIT
+# SPDX-FileCopyrightText: 2021 Taneli Hukkinen
+# Licensed to PSF under a Contributor Agreement.
+
+from __future__ import annotations
+
+from datetime import date, datetime, time, timedelta, timezone, tzinfo
+from functools import lru_cache
+import re
+from typing import Any, Final
+
+from ._types import ParseFloat
+
+# E.g.
+# - 00:32:00.999999
+# - 00:32:00
+_TIME_RE_STR: Final = (
+    r"([01][0-9]|2[0-3]):([0-5][0-9]):([0-5][0-9])(?:\.([0-9]{1,6})[0-9]*)?"
+)
+
+RE_NUMBER: Final = re.compile(
+    r"""
+0
+(?:
+    x[0-9A-Fa-f](?:_?[0-9A-Fa-f])*   # hex
+    |
+    b[01](?:_?[01])*                 # bin
+    |
+    o[0-7](?:_?[0-7])*               # oct
+)
+|
+[+-]?(?:0|[1-9](?:_?[0-9])*)         # dec, integer part
+(?P<floatpart>
+    (?:\.[0-9](?:_?[0-9])*)?         # optional fractional part
+    (?:[eE][+-]?[0-9](?:_?[0-9])*)?  # optional exponent part
+)
+""",
+    flags=re.VERBOSE,
+)
+RE_LOCALTIME: Final = re.compile(_TIME_RE_STR)
+RE_DATETIME: Final = re.compile(
+    rf"""
+([0-9]{{4}})-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01])  # date, e.g. 1988-10-27
+(?:
+    [Tt ]
+    {_TIME_RE_STR}
+    (?:([Zz])|([+-])([01][0-9]|2[0-3]):([0-5][0-9]))?  # optional time offset
+)?
+""",
+    flags=re.VERBOSE,
+)
+
+
+def match_to_datetime(match: re.Match) -> datetime | date:
+    """Convert a `RE_DATETIME` match to `datetime.datetime` or `datetime.date`.
+
+    Raises ValueError if the match does not correspond to a valid date
+    or datetime.
+    """
+    (
+        year_str,
+        month_str,
+        day_str,
+        hour_str,
+        minute_str,
+        sec_str,
+        micros_str,
+        zulu_time,
+        offset_sign_str,
+        offset_hour_str,
+        offset_minute_str,
+    ) = match.groups()
+    year, month, day = int(year_str), int(month_str), int(day_str)
+    if hour_str is None:
+        return date(year, month, day)
+    hour, minute, sec = int(hour_str), int(minute_str), int(sec_str)
+    micros = int(micros_str.ljust(6, "0")) if micros_str else 0
+    if offset_sign_str:
+        tz: tzinfo | None = cached_tz(
+            offset_hour_str, offset_minute_str, offset_sign_str
+        )
+    elif zulu_time:
+        tz = timezone.utc
+    else:  # local date-time
+        tz = None
+    return datetime(year, month, day, hour, minute, sec, micros, tzinfo=tz)
+
+
+# No need to limit cache size. This is only ever called on input
+# that matched RE_DATETIME, so there is an implicit bound of
+# 24 (hours) * 60 (minutes) * 2 (offset direction) = 2880.
+@lru_cache(maxsize=None)
+def cached_tz(hour_str: str, minute_str: str, sign_str: str) -> timezone:
+    sign = 1 if sign_str == "+" else -1
+    return timezone(
+        timedelta(
+            hours=sign * int(hour_str),
+            minutes=sign * int(minute_str),
+        )
+    )
+
+
+def match_to_localtime(match: re.Match) -> time:
+    hour_str, minute_str, sec_str, micros_str = match.groups()
+    micros = int(micros_str.ljust(6, "0")) if micros_str else 0
+    return time(int(hour_str), int(minute_str), int(sec_str), micros)
+
+
+def match_to_number(match: re.Match, parse_float: ParseFloat) -> Any:
+    if match.group("floatpart"):
+        return parse_float(match.group())
+    return int(match.group(), 0)
diff --git a/venv/lib/python3.9/site-packages/tomli/_types.py b/venv/lib/python3.9/site-packages/tomli/_types.py
new file mode 100644
index 000000000..d949412e0
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomli/_types.py
@@ -0,0 +1,10 @@
+# SPDX-License-Identifier: MIT
+# SPDX-FileCopyrightText: 2021 Taneli Hukkinen
+# Licensed to PSF under a Contributor Agreement.
+
+from typing import Any, Callable, Tuple
+
+# Type annotations
+ParseFloat = Callable[[str], Any]
+Key = Tuple[str, ...]
+Pos = int
diff --git a/venv/lib/python3.9/site-packages/tomli/py.typed b/venv/lib/python3.9/site-packages/tomli/py.typed
new file mode 100644
index 000000000..7632ecf77
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomli/py.typed
@@ -0,0 +1 @@
+# Marker file for PEP 561
diff --git a/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/INSTALLER b/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/INSTALLER
new file mode 100644
index 000000000..a1b589e38
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/INSTALLER
@@ -0,0 +1 @@
+pip
diff --git a/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/LICENSE b/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/LICENSE
new file mode 100644
index 000000000..44cf2b30e
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/LICENSE
@@ -0,0 +1,20 @@
+Copyright (c) 2018 Sébastien Eustace
+
+Permission is hereby granted, free of charge, to any person obtaining
+a copy of this software and associated documentation files (the
+"Software"), to deal in the Software without restriction, including
+without limitation the rights to use, copy, modify, merge, publish,
+distribute, sublicense, and/or sell copies of the Software, and to
+permit persons to whom the Software is furnished to do so, subject to
+the following conditions:
+
+The above copyright notice and this permission notice shall be
+included in all copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
+LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
+OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
+WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
diff --git a/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/METADATA b/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/METADATA
new file mode 100644
index 000000000..3f74211b6
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/METADATA
@@ -0,0 +1,70 @@
+Metadata-Version: 2.1
+Name: tomlkit
+Version: 0.13.2
+Summary: Style preserving TOML library
+Home-page: https://github.com/sdispater/tomlkit
+License: MIT
+Author: Sébastien Eustace
+Author-email: sebastien@eustace.io
+Requires-Python: >=3.8
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: Programming Language :: Python :: 3.12
+Project-URL: Repository, https://github.com/sdispater/tomlkit
+Description-Content-Type: text/markdown
+
+[github_release]: https://img.shields.io/github/release/sdispater/tomlkit.svg?logo=github&logoColor=white
+[pypi_version]: https://img.shields.io/pypi/v/tomlkit.svg?logo=python&logoColor=white
+[python_versions]: https://img.shields.io/pypi/pyversions/tomlkit.svg?logo=python&logoColor=white
+[github_license]: https://img.shields.io/github/license/sdispater/tomlkit.svg?logo=github&logoColor=white
+[github_action]: https://github.com/sdispater/tomlkit/actions/workflows/tests.yml/badge.svg
+
+[![GitHub Release][github_release]](https://github.com/sdispater/tomlkit/releases/)
+[![PyPI Version][pypi_version]](https://pypi.org/project/tomlkit/)
+[![Python Versions][python_versions]](https://pypi.org/project/tomlkit/)
+[![License][github_license]](https://github.com/sdispater/tomlkit/blob/master/LICENSE)
+<br>
+[![Tests][github_action]](https://github.com/sdispater/tomlkit/actions/workflows/tests.yml)
+
+# TOML Kit - Style-preserving TOML library for Python
+
+TOML Kit is a **1.0.0-compliant** [TOML](https://toml.io/) library.
+
+It includes a parser that preserves all comments, indentations, whitespace and internal element ordering,
+and makes them accessible and editable via an intuitive API.
+
+You can also create new TOML documents from scratch using the provided helpers.
+
+Part of the implementation has been adapted, improved and fixed from [Molten](https://github.com/LeopoldArkham/Molten).
+
+## Usage
+
+See the [documentation](https://tomlkit.readthedocs.io/) for more information.
+
+## Installation
+
+If you are using [Poetry](https://poetry.eustace.io),
+add `tomlkit` to your `pyproject.toml` file by using:
+
+```bash
+poetry add tomlkit
+```
+
+If not, you can use `pip`:
+
+```bash
+pip install tomlkit
+```
+
+## Running tests
+
+Please clone the repo with submodules with the following command
+`git clone --recurse-submodules https://github.com/sdispater/tomlkit.git`.
+We need the submodule - `toml-test` for running the tests.
+
+You can run the tests with `poetry run pytest -q tests`
+
diff --git a/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/RECORD b/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/RECORD
new file mode 100644
index 000000000..c3c4ee3c5
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/RECORD
@@ -0,0 +1,32 @@
+tomlkit-0.13.2.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+tomlkit-0.13.2.dist-info/LICENSE,sha256=8vm0YLpxnaZiat0mTTeC8nWk_3qrZ3vtoIszCRHiOts,1062
+tomlkit-0.13.2.dist-info/METADATA,sha256=O7-SDziwqmggbN-pKWf4rRLVMk5NbC6LeunlqFHITGk,2668
+tomlkit-0.13.2.dist-info/RECORD,,
+tomlkit-0.13.2.dist-info/WHEEL,sha256=sP946D7jFCHeNz5Iq4fL4Lu-PrWrFsgfLXbbkciIZwg,88
+tomlkit/__init__.py,sha256=255jILi1FC2a1kEdynuZoqKosXQjkf7-GN1MUJjCCZk,1282
+tomlkit/__pycache__/__init__.cpython-39.pyc,,
+tomlkit/__pycache__/_compat.cpython-39.pyc,,
+tomlkit/__pycache__/_types.cpython-39.pyc,,
+tomlkit/__pycache__/_utils.cpython-39.pyc,,
+tomlkit/__pycache__/api.cpython-39.pyc,,
+tomlkit/__pycache__/container.cpython-39.pyc,,
+tomlkit/__pycache__/exceptions.cpython-39.pyc,,
+tomlkit/__pycache__/items.cpython-39.pyc,,
+tomlkit/__pycache__/parser.cpython-39.pyc,,
+tomlkit/__pycache__/source.cpython-39.pyc,,
+tomlkit/__pycache__/toml_char.cpython-39.pyc,,
+tomlkit/__pycache__/toml_document.cpython-39.pyc,,
+tomlkit/__pycache__/toml_file.cpython-39.pyc,,
+tomlkit/_compat.py,sha256=gp7P7qNh0yY1dg0wyjiCDbVwFTdUo7p0QwjV4T3Funs,513
+tomlkit/_types.py,sha256=42ht2m-_pJPvQ_uMKMIJf4KL6F9N0NoDa0fymfTeIC4,2619
+tomlkit/_utils.py,sha256=m4OyWq9nw5MGabHhQKTIu1YtUD8SVJyoTImHTN6L7Yc,4089
+tomlkit/api.py,sha256=DsY3yS2rPZN0BdLytZ-hnbAHmaNfT5f8X6B01KrPDso,7763
+tomlkit/container.py,sha256=T8FtBLDL9HXkg1D4z3QOvT_pMIyk17F24qHuaF1XNW4,29470
+tomlkit/exceptions.py,sha256=e-0iKjv-u2ngE6G6XMOxaoBNnKBfPNjDLmaw4YDHpoU,5703
+tomlkit/items.py,sha256=DOB6Sf0y0hZTaUgoMQAmyt6sUbmNMoM-bDBIlliQ2lA,53543
+tomlkit/parser.py,sha256=INQ9Cbmmwq6fHVWZa73jTQXi0XtiLckldT6zKY5Jt4w,37935
+tomlkit/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+tomlkit/source.py,sha256=Nith7mmPmhTf5dMSRc41bY9cuIRR_4CoqOjC-fxzfCo,4835
+tomlkit/toml_char.py,sha256=w3sQZ0dolZ1qjZ2Rxj_svvlpRNNGB_fjfBcYD0gFnDs,1291
+tomlkit/toml_document.py,sha256=OCTkWXd3P58EZT4SD8_ddc1YpkMaqtlS5_stHTBmMOI,110
+tomlkit/toml_file.py,sha256=4gVZvvs_Q1_soWaVxBo80rRzny849boXt2LzdMXQ04I,1599
diff --git a/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/WHEEL b/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/WHEEL
new file mode 100644
index 000000000..d73ccaae8
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit-0.13.2.dist-info/WHEEL
@@ -0,0 +1,4 @@
+Wheel-Version: 1.0
+Generator: poetry-core 1.9.0
+Root-Is-Purelib: true
+Tag: py3-none-any
diff --git a/venv/lib/python3.9/site-packages/tomlkit/__init__.py b/venv/lib/python3.9/site-packages/tomlkit/__init__.py
new file mode 100644
index 000000000..fbbab82fa
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit/__init__.py
@@ -0,0 +1,59 @@
+from tomlkit.api import TOMLDocument
+from tomlkit.api import aot
+from tomlkit.api import array
+from tomlkit.api import boolean
+from tomlkit.api import comment
+from tomlkit.api import date
+from tomlkit.api import datetime
+from tomlkit.api import document
+from tomlkit.api import dump
+from tomlkit.api import dumps
+from tomlkit.api import float_
+from tomlkit.api import inline_table
+from tomlkit.api import integer
+from tomlkit.api import item
+from tomlkit.api import key
+from tomlkit.api import key_value
+from tomlkit.api import load
+from tomlkit.api import loads
+from tomlkit.api import nl
+from tomlkit.api import parse
+from tomlkit.api import register_encoder
+from tomlkit.api import string
+from tomlkit.api import table
+from tomlkit.api import time
+from tomlkit.api import unregister_encoder
+from tomlkit.api import value
+from tomlkit.api import ws
+
+
+__version__ = "0.13.2"
+__all__ = [
+    "aot",
+    "array",
+    "boolean",
+    "comment",
+    "date",
+    "datetime",
+    "document",
+    "dump",
+    "dumps",
+    "float_",
+    "inline_table",
+    "integer",
+    "item",
+    "key",
+    "key_value",
+    "load",
+    "loads",
+    "nl",
+    "parse",
+    "string",
+    "table",
+    "time",
+    "TOMLDocument",
+    "value",
+    "ws",
+    "register_encoder",
+    "unregister_encoder",
+]
diff --git a/venv/lib/python3.9/site-packages/tomlkit/_compat.py b/venv/lib/python3.9/site-packages/tomlkit/_compat.py
new file mode 100644
index 000000000..8e76b7fde
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit/_compat.py
@@ -0,0 +1,22 @@
+from __future__ import annotations
+
+import contextlib
+import sys
+
+from typing import Any
+
+
+PY38 = sys.version_info >= (3, 8)
+
+
+def decode(string: Any, encodings: list[str] | None = None):
+    if not isinstance(string, bytes):
+        return string
+
+    encodings = encodings or ["utf-8", "latin1", "ascii"]
+
+    for encoding in encodings:
+        with contextlib.suppress(UnicodeEncodeError, UnicodeDecodeError):
+            return string.decode(encoding)
+
+    return string.decode(encodings[0], errors="ignore")
diff --git a/venv/lib/python3.9/site-packages/tomlkit/_types.py b/venv/lib/python3.9/site-packages/tomlkit/_types.py
new file mode 100644
index 000000000..501bf4dca
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit/_types.py
@@ -0,0 +1,82 @@
+from __future__ import annotations
+
+from typing import TYPE_CHECKING
+from typing import Any
+from typing import TypeVar
+
+
+WT = TypeVar("WT", bound="WrapperType")
+
+if TYPE_CHECKING:  # pragma: no cover
+    # Define _CustomList and _CustomDict as a workaround for:
+    # https://github.com/python/mypy/issues/11427
+    #
+    # According to this issue, the typeshed contains a "lie"
+    # (it adds MutableSequence to the ancestry of list and MutableMapping to
+    # the ancestry of dict) which completely messes with the type inference for
+    # Table, InlineTable, Array and Container.
+    #
+    # Importing from builtins is preferred over simple assignment, see issues:
+    # https://github.com/python/mypy/issues/8715
+    # https://github.com/python/mypy/issues/10068
+    from builtins import dict as _CustomDict
+    from builtins import float as _CustomFloat
+    from builtins import int as _CustomInt
+    from builtins import list as _CustomList
+    from typing import Callable
+    from typing import Concatenate
+    from typing import ParamSpec
+    from typing import Protocol
+
+    P = ParamSpec("P")
+
+    class WrapperType(Protocol):
+        def _new(self: WT, value: Any) -> WT: ...
+
+else:
+    from collections.abc import MutableMapping
+    from collections.abc import MutableSequence
+    from numbers import Integral
+    from numbers import Real
+
+    class _CustomList(MutableSequence, list):
+        """Adds MutableSequence mixin while pretending to be a builtin list"""
+
+        def __add__(self, other):
+            new_list = self.copy()
+            new_list.extend(other)
+            return new_list
+
+        def __iadd__(self, other):
+            self.extend(other)
+            return self
+
+    class _CustomDict(MutableMapping, dict):
+        """Adds MutableMapping mixin while pretending to be a builtin dict"""
+
+        def __or__(self, other):
+            new_dict = self.copy()
+            new_dict.update(other)
+            return new_dict
+
+        def __ior__(self, other):
+            self.update(other)
+            return self
+
+    class _CustomInt(Integral, int):
+        """Adds Integral mixin while pretending to be a builtin int"""
+
+    class _CustomFloat(Real, float):
+        """Adds Real mixin while pretending to be a builtin float"""
+
+
+def wrap_method(
+    original_method: Callable[Concatenate[WT, P], Any],
+) -> Callable[Concatenate[WT, P], Any]:
+    def wrapper(self: WT, *args: P.args, **kwargs: P.kwargs) -> Any:
+        result = original_method(self, *args, **kwargs)
+        if result is NotImplemented:
+            return result
+        return self._new(result)
+
+    return wrapper
diff --git a/venv/lib/python3.9/site-packages/tomlkit/_utils.py b/venv/lib/python3.9/site-packages/tomlkit/_utils.py
new file mode 100644
index 000000000..f87fd7b58
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit/_utils.py
@@ -0,0 +1,158 @@
+from __future__ import annotations
+
+import re
+
+from collections.abc import Mapping
+from datetime import date
+from datetime import datetime
+from datetime import time
+from datetime import timedelta
+from datetime import timezone
+from typing import Collection
+
+from tomlkit._compat import decode
+
+
+RFC_3339_LOOSE = re.compile(
+    "^"
+    r"(([0-9]+)-(\d{2})-(\d{2}))?"  # Date
+    "("
+    "([Tt ])?"  # Separator
+    r"(\d{2}):(\d{2}):(\d{2})(\.([0-9]+))?"  # Time
+    r"(([Zz])|([\+|\-]([01][0-9]|2[0-3]):([0-5][0-9])))?"  # Timezone
+    ")?"
+    "$"
+)
+
+RFC_3339_DATETIME = re.compile(
+    "^"
+    "([0-9]+)-(0[1-9]|1[012])-(0[1-9]|[12][0-9]|3[01])"  # Date
+    "[Tt ]"  # Separator
+    r"([01][0-9]|2[0-3]):([0-5][0-9]):([0-5][0-9]|60)(\.([0-9]+))?"  # Time
+    r"(([Zz])|([\+|\-]([01][0-9]|2[0-3]):([0-5][0-9])))?"  # Timezone
+    "$"
+)
+
+RFC_3339_DATE = re.compile("^([0-9]+)-(0[1-9]|1[012])-(0[1-9]|[12][0-9]|3[01])$")
+
+RFC_3339_TIME = re.compile(
+    r"^([01][0-9]|2[0-3]):([0-5][0-9]):([0-5][0-9]|60)(\.([0-9]+))?$"
+)
+
+_utc = timezone(timedelta(), "UTC")
+
+
+def parse_rfc3339(string: str) -> datetime | date | time:
+    m = RFC_3339_DATETIME.match(string)
+    if m:
+        year = int(m.group(1))
+        month = int(m.group(2))
+        day = int(m.group(3))
+        hour = int(m.group(4))
+        minute = int(m.group(5))
+        second = int(m.group(6))
+        microsecond = 0
+
+        if m.group(7):
+            microsecond = int((f"{m.group(8):<06s}")[:6])
+
+        if m.group(9):
+            # Timezone
+            tz = m.group(9)
+            if tz.upper() == "Z":
+                tzinfo = _utc
+            else:
+                sign = m.group(11)[0]
+                hour_offset, minute_offset = int(m.group(12)), int(m.group(13))
+                offset = timedelta(seconds=hour_offset * 3600 + minute_offset * 60)
+                if sign == "-":
+                    offset = -offset
+
+                tzinfo = timezone(offset, f"{sign}{m.group(12)}:{m.group(13)}")
+
+            return datetime(
+                year, month, day, hour, minute, second, microsecond, tzinfo=tzinfo
+            )
+        else:
+            return datetime(year, month, day, hour, minute, second, microsecond)
+
+    m = RFC_3339_DATE.match(string)
+    if m:
+        year = int(m.group(1))
+        month = int(m.group(2))
+        day = int(m.group(3))
+
+        return date(year, month, day)
+
+    m = RFC_3339_TIME.match(string)
+    if m:
+        hour = int(m.group(1))
+        minute = int(m.group(2))
+        second = int(m.group(3))
+        microsecond = 0
+
+        if m.group(4):
+            microsecond = int((f"{m.group(5):<06s}")[:6])
+
+        return time(hour, minute, second, microsecond)
+
+    raise ValueError("Invalid RFC 339 string")
+
+
+# https://toml.io/en/v1.0.0#string
+CONTROL_CHARS = frozenset(chr(c) for c in range(0x20)) | {chr(0x7F)}
+_escaped = {
+    "b": "\b",
+    "t": "\t",
+    "n": "\n",
+    "f": "\f",
+    "r": "\r",
+    '"': '"',
+    "\\": "\\",
+}
+_compact_escapes = {
+    **{v: f"\\{k}" for k, v in _escaped.items()},
+    '"""': '""\\"',
+}
+_basic_escapes = CONTROL_CHARS | {'"', "\\"}
+
+
+def _unicode_escape(seq: str) -> str:
+    return "".join(f"\\u{ord(c):04x}" for c in seq)
+
+
+def escape_string(s: str, escape_sequences: Collection[str] = _basic_escapes) -> str:
+    s = decode(s)
+
+    res = []
+    start = 0
+
+    def flush(inc=1):
+        if start != i:
+            res.append(s[start:i])
+
+        return i + inc
+
+    found_sequences = {seq for seq in escape_sequences if seq in s}
+
+    i = 0
+    while i < len(s):
+        for seq in found_sequences:
+            seq_len = len(seq)
+            if s[i:].startswith(seq):
+                start = flush(seq_len)
+                res.append(_compact_escapes.get(seq) or _unicode_escape(seq))
+                i += seq_len - 1  # fast-forward escape sequence
+        i += 1
+
+    flush()
+
+    return "".join(res)
+
+
+def merge_dicts(d1: dict, d2: dict) -> dict:
+    for k, v in d2.items():
+        if k in d1 and isinstance(d1[k], dict) and isinstance(v, Mapping):
+            merge_dicts(d1[k], v)
+        else:
+            d1[k] = d2[k]
diff --git a/venv/lib/python3.9/site-packages/tomlkit/api.py b/venv/lib/python3.9/site-packages/tomlkit/api.py
new file mode 100644
index 000000000..a7f6a61e2
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit/api.py
@@ -0,0 +1,310 @@
+from __future__ import annotations
+
+import contextlib
+import datetime as _datetime
+
+from collections.abc import Mapping
+from typing import IO
+from typing import Iterable
+from typing import TypeVar
+
+from tomlkit._utils import parse_rfc3339
+from tomlkit.container import Container
+from tomlkit.exceptions import UnexpectedCharError
+from tomlkit.items import CUSTOM_ENCODERS
+from tomlkit.items import AoT
+from tomlkit.items import Array
+from tomlkit.items import Bool
+from tomlkit.items import Comment
+from tomlkit.items import Date
+from tomlkit.items import DateTime
+from tomlkit.items import DottedKey
+from tomlkit.items import Encoder
+from tomlkit.items import Float
+from tomlkit.items import InlineTable
+from tomlkit.items import Integer
+from tomlkit.items import Item as _Item
+from tomlkit.items import Key
+from tomlkit.items import SingleKey
+from tomlkit.items import String
+from tomlkit.items import StringType as _StringType
+from tomlkit.items import Table
+from tomlkit.items import Time
+from tomlkit.items import Trivia
+from tomlkit.items import Whitespace
+from tomlkit.items import item
+from tomlkit.parser import Parser
+from tomlkit.toml_document import TOMLDocument
+
+
+def loads(string: str | bytes) -> TOMLDocument:
+    """
+    Parses a string into a TOMLDocument.
+
+    Alias for parse().
+    """
+    return parse(string)
+
+
+def dumps(data: Mapping, sort_keys: bool = False) -> str:
+    """
+    Dumps a TOMLDocument into a string.
+    """
+    if not isinstance(data, Container) and isinstance(data, Mapping):
+        data = item(dict(data), _sort_keys=sort_keys)
+
+    try:
+        # data should be a `Container` (and therefore implement `as_string`)
+        # for all type safe invocations of this function
+        return data.as_string()  # type: ignore[attr-defined]
+    except AttributeError as ex:
+        msg = f"Expecting Mapping or TOML Container, {type(data)} given"
+        raise TypeError(msg) from ex
+
+
+def load(fp: IO[str] | IO[bytes]) -> TOMLDocument:
+    """
+    Load toml document from a file-like object.
+    """
+    return parse(fp.read())
+
+
+def dump(data: Mapping, fp: IO[str], *, sort_keys: bool = False) -> None:
+    """
+    Dump a TOMLDocument into a writable file stream.
+
+    :param data: a dict-like object to dump
+    :param sort_keys: if true, sort the keys in alphabetic order
+
+    :Example:
+
+    >>> with open("output.toml", "w") as fp:
+    ...     tomlkit.dump(data, fp)
+    """
+    fp.write(dumps(data, sort_keys=sort_keys))
+
+
+def parse(string: str | bytes) -> TOMLDocument:
+    """
+    Parses a string or bytes into a TOMLDocument.
+    """
+    return Parser(string).parse()
+
+
+def document() -> TOMLDocument:
+    """
+    Returns a new TOMLDocument instance.
+    """
+    return TOMLDocument()
+
+
+# Items
+def integer(raw: str | int) -> Integer:
+    """Create an integer item from a number or string."""
+    return item(int(raw))
+
+
+def float_(raw: str | float) -> Float:
+    """Create an float item from a number or string."""
+    return item(float(raw))
+
+
+def boolean(raw: str) -> Bool:
+    """Turn `true` or `false` into a boolean item."""
+    return item(raw == "true")
+
+
+def string(
+    raw: str,
+    *,
+    literal: bool = False,
+    multiline: bool = False,
+    escape: bool = True,
+) -> String:
+    """Create a string item.
+
+    By default, this function will create *single line basic* strings, but
+    boolean flags (e.g. ``literal=True`` and/or ``multiline=True``)
+    can be used for personalization.
+
+    For more information, please check the spec: `<https://toml.io/en/v1.0.0#string>`__.
+
+    Common escaping rules will be applied for basic strings.
+    This can be controlled by explicitly setting ``escape=False``.
+    Please note that, if you disable escaping, you will have to make sure that
+    the given strings don't contain any forbidden character or sequence.
+    """
+    type_ = _StringType.select(literal, multiline)
+    return String.from_raw(raw, type_, escape)
+
+
+def date(raw: str) -> Date:
+    """Create a TOML date."""
+    value = parse_rfc3339(raw)
+    if not isinstance(value, _datetime.date):
+        raise ValueError("date() only accepts date strings.")
+
+    return item(value)
+
+
+def time(raw: str) -> Time:
+    """Create a TOML time."""
+    value = parse_rfc3339(raw)
+    if not isinstance(value, _datetime.time):
+        raise ValueError("time() only accepts time strings.")
+
+    return item(value)
+
+
+def datetime(raw: str) -> DateTime:
+    """Create a TOML datetime."""
+    value = parse_rfc3339(raw)
+    if not isinstance(value, _datetime.datetime):
+        raise ValueError("datetime() only accepts datetime strings.")
+
+    return item(value)
+
+
+def array(raw: str = "[]") -> Array:
+    """Create an array item for its string representation.
+
+    :Example:
+
+    >>> array("[1, 2, 3]")  # Create from a string
+    [1, 2, 3]
+    >>> a = array()
+    >>> a.extend([1, 2, 3])  # Create from a list
+    >>> a
+    [1, 2, 3]
+    """
+    return value(raw)
+
+
+def table(is_super_table: bool | None = None) -> Table:
+    """Create an empty table.
+
+    :param is_super_table: if true, the table is a super table
+
+    :Example:
+
+    >>> doc = document()
+    >>> foo = table(True)
+    >>> bar = table()
+    >>> bar.update({'x': 1})
+    >>> foo.append('bar', bar)
+    >>> doc.append('foo', foo)
+    >>> print(doc.as_string())
+    [foo.bar]
+    x = 1
+    """
+    return Table(Container(), Trivia(), False, is_super_table)
+
+
+def inline_table() -> InlineTable:
+    """Create an inline table.
+
+    :Example:
+
+    >>> table = inline_table()
+    >>> table.update({'x': 1, 'y': 2})
+    >>> print(table.as_string())
+    {x = 1, y = 2}
+    """
+    return InlineTable(Container(), Trivia(), new=True)
+
+
+def aot() -> AoT:
+    """Create an array of table.
+
+    :Example:
+
+    >>> doc = document()
+    >>> aot = aot()
+    >>> aot.append(item({'x': 1}))
+    >>> doc.append('foo', aot)
+    >>> print(doc.as_string())
+    [[foo]]
+    x = 1
+    """
+    return AoT([])
+
+
+def key(k: str | Iterable[str]) -> Key:
+    """Create a key from a string. When a list of string is given,
+    it will create a dotted key.
+
+    :Example:
+
+    >>> doc = document()
+    >>> doc.append(key('foo'), 1)
+    >>> doc.append(key(['bar', 'baz']), 2)
+    >>> print(doc.as_string())
+    foo = 1
+    bar.baz = 2
+    """
+    if isinstance(k, str):
+        return SingleKey(k)
+    return DottedKey([key(_k) for _k in k])
+
+
+def value(raw: str) -> _Item:
+    """Parse a simple value from a string.
+
+    :Example:
+
+    >>> value("1")
+    1
+    >>> value("true")
+    True
+    >>> value("[1, 2, 3]")
+    [1, 2, 3]
+    """
+    parser = Parser(raw)
+    v = parser._parse_value()
+    if not parser.end():
+        raise parser.parse_error(UnexpectedCharError, char=parser._current)
+    return v
+
+
+def key_value(src: str) -> tuple[Key, _Item]:
+    """Parse a key-value pair from a string.
+
+    :Example:
+
+    >>> key_value("foo = 1")
+    (Key('foo'), 1)
+    """
+    return Parser(src)._parse_key_value()
+
+
+def ws(src: str) -> Whitespace:
+    """Create a whitespace from a string."""
+    return Whitespace(src, fixed=True)
+
+
+def nl() -> Whitespace:
+    """Create a newline item."""
+    return ws("\n")
+
+
+def comment(string: str) -> Comment:
+    """Create a comment item."""
+    return Comment(Trivia(comment_ws="  ", comment="# " + string))
+
+
+E = TypeVar("E", bound=Encoder)
+
+
+def register_encoder(encoder: E) -> E:
+    """Add a custom encoder, which should be a function that will be called
+    if the value can't otherwise be converted. It should takes a single value
+    and return a TOMLKit item or raise a ``TypeError``.
+    """
+    CUSTOM_ENCODERS.append(encoder)
+    return encoder
+
+
+def unregister_encoder(encoder: Encoder) -> None:
+    """Unregister a custom encoder."""
+    with contextlib.suppress(ValueError):
+        CUSTOM_ENCODERS.remove(encoder)
diff --git a/venv/lib/python3.9/site-packages/tomlkit/container.py b/venv/lib/python3.9/site-packages/tomlkit/container.py
new file mode 100644
index 000000000..7890880e2
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit/container.py
@@ -0,0 +1,894 @@
+from __future__ import annotations
+
+import copy
+
+from typing import Any
+from typing import Iterator
+
+from tomlkit._compat import decode
+from tomlkit._types import _CustomDict
+from tomlkit._utils import merge_dicts
+from tomlkit.exceptions import KeyAlreadyPresent
+from tomlkit.exceptions import NonExistentKey
+from tomlkit.exceptions import TOMLKitError
+from tomlkit.items import AoT
+from tomlkit.items import Comment
+from tomlkit.items import Item
+from tomlkit.items import Key
+from tomlkit.items import Null
+from tomlkit.items import SingleKey
+from tomlkit.items import Table
+from tomlkit.items import Trivia
+from tomlkit.items import Whitespace
+from tomlkit.items import item as _item
+
+
+_NOT_SET = object()
+
+
+class Container(_CustomDict):
+    """
+    A container for items within a TOMLDocument.
+
+    This class implements the `dict` interface with copy/deepcopy protocol.
+    """
+
+    def __init__(self, parsed: bool = False) -> None:
+        self._map: dict[SingleKey, int | tuple[int, ...]] = {}
+        self._body: list[tuple[Key | None, Item]] = []
+        self._parsed = parsed
+        self._table_keys = []
+
+    @property
+    def body(self) -> list[tuple[Key | None, Item]]:
+        return self._body
+
+    def unwrap(self) -> dict[str, Any]:
+        """Returns as pure python object (ppo)"""
+        unwrapped = {}
+        for k, v in self.items():
+            if k is None:
+                continue
+
+            if isinstance(k, Key):
+                k = k.key
+
+            if hasattr(v, "unwrap"):
+                v = v.unwrap()
+
+            if k in unwrapped:
+                merge_dicts(unwrapped[k], v)
+            else:
+                unwrapped[k] = v
+
+        return unwrapped
+
+    @property
+    def value(self) -> dict[str, Any]:
+        """The wrapped dict value"""
+        d = {}
+        for k, v in self._body:
+            if k is None:
+                continue
+
+            k = k.key
+            v = v.value
+
+            if isinstance(v, Container):
+                v = v.value
+
+            if k in d:
+                merge_dicts(d[k], v)
+            else:
+                d[k] = v
+
+        return d
+
+    def parsing(self, parsing: bool) -> None:
+        self._parsed = parsing
+
+        for _, v in self._body:
+            if isinstance(v, Table):
+                v.value.parsing(parsing)
+            elif isinstance(v, AoT):
+                for t in v.body:
+                    t.value.parsing(parsing)
+
+    def add(self, key: Key | Item | str, item: Item | None = None) -> Container:
+        """
+        Adds an item to the current Container.
+
+        :Example:
+
+        >>> # add a key-value pair
+        >>> doc.add('key', 'value')
+        >>> # add a comment or whitespace or newline
+        >>> doc.add(comment('# comment'))
+        """
+        if item is None:
+            if not isinstance(key, (Comment, Whitespace)):
+                raise ValueError(
+                    "Non comment/whitespace items must have an associated key"
+                )
+
+            key, item = None, key
+
+        return self.append(key, item)
+
+    def _handle_dotted_key(self, key: Key, value: Item) -> None:
+        if isinstance(value, (Table, AoT)):
+            raise TOMLKitError("Can't add a table to a dotted key")
+        name, *mid, last = key
+        name._dotted = True
+        table = current = Table(Container(True), Trivia(), False, is_super_table=True)
+        for _name in mid:
+            _name._dotted = True
+            new_table = Table(Container(True), Trivia(), False, is_super_table=True)
+            current.append(_name, new_table)
+            current = new_table
+
+        last.sep = key.sep
+        current.append(last, value)
+
+        self.append(name, table)
+        return
+
+    def _get_last_index_before_table(self) -> int:
+        last_index = -1
+        for i, (k, v) in enumerate(self._body):
+            if isinstance(v, Null):
+                continue  # Null elements are inserted after deletion
+
+            if isinstance(v, Whitespace) and not v.is_fixed():
+                continue
+
+            if isinstance(v, (Table, AoT)) and not k.is_dotted():
+                break
+            last_index = i
+        return last_index + 1
+
+    def _validate_out_of_order_table(self, key: SingleKey | None = None) -> None:
+        if key is None:
+            for k in self._map:
+                assert k is not None
+                self._validate_out_of_order_table(k)
+            return
+        if key not in self._map or not isinstance(self._map[key], tuple):
+            return
+        OutOfOrderTableProxy.validate(self, self._map[key])
+
+    def append(
+        self, key: Key | str | None, item: Item, validate: bool = True
+    ) -> Container:
+        """Similar to :meth:`add` but both key and value must be given."""
+        if not isinstance(key, Key) and key is not None:
+            key = SingleKey(key)
+
+        if not isinstance(item, Item):
+            item = _item(item)
+
+        if key is not None and key.is_multi():
+            self._handle_dotted_key(key, item)
+            return self
+
+        if isinstance(item, (AoT, Table)) and item.name is None:
+            item.name = key.key
+
+        prev = self._previous_item()
+        prev_ws = isinstance(prev, Whitespace) or ends_with_whitespace(prev)
+        if isinstance(item, Table):
+            if not self._parsed:
+                item.invalidate_display_name()
+            if (
+                self._body
+                and not (self._parsed or item.trivia.indent or prev_ws)
+                and not key.is_dotted()
+            ):
+                item.trivia.indent = "\n"
+
+        if isinstance(item, AoT) and self._body and not self._parsed:
+            item.invalidate_display_name()
+            if item and not ("\n" in item[0].trivia.indent or prev_ws):
+                item[0].trivia.indent = "\n" + item[0].trivia.indent
+
+        if key is not None and key in self:
+            current_idx = self._map[key]
+            if isinstance(current_idx, tuple):
+                current_body_element = self._body[current_idx[-1]]
+            else:
+                current_body_element = self._body[current_idx]
+
+            current = current_body_element[1]
+
+            if isinstance(item, Table):
+                if not isinstance(current, (Table, AoT)):
+                    raise KeyAlreadyPresent(key)
+
+                if item.is_aot_element():
+                    # New AoT element found later on
+                    # Adding it to the current AoT
+                    if not isinstance(current, AoT):
+                        current = AoT([current, item], parsed=self._parsed)
+
+                        self._replace(key, key, current)
+                    else:
+                        current.append(item)
+
+                    return self
+                elif current.is_aot():
+                    if not item.is_aot_element():
+                        # Tried to define a table after an AoT with the same name.
+                        raise KeyAlreadyPresent(key)
+
+                    current.append(item)
+
+                    return self
+                elif current.is_super_table():
+                    if item.is_super_table():
+                        # We need to merge both super tables
+                        if (
+                            key.is_dotted()
+                            or current_body_element[0].is_dotted()
+                            or self._table_keys[-1] != current_body_element[0]
+                        ):
+                            if key.is_dotted() and not self._parsed:
+                                idx = self._get_last_index_before_table()
+                            else:
+                                idx = len(self._body)
+
+                            if idx < len(self._body):
+                                self._insert_at(idx, key, item)
+                            else:
+                                self._raw_append(key, item)
+
+                            if validate:
+                                self._validate_out_of_order_table(key)
+
+                            return self
+
+                        # Create a new element to replace the old one
+                        current = copy.deepcopy(current)
+                        for k, v in item.value.body:
+                            current.append(k, v)
+                        self._body[
+                            (
+                                current_idx[-1]
+                                if isinstance(current_idx, tuple)
+                                else current_idx
+                            )
+                        ] = (current_body_element[0], current)
+
+                        return self
+                    elif current_body_element[0].is_dotted():
+                        raise TOMLKitError("Redefinition of an existing table")
+                elif not item.is_super_table():
+                    raise KeyAlreadyPresent(key)
+            elif isinstance(item, AoT):
+                if not isinstance(current, AoT):
+                    # Tried to define an AoT after a table with the same name.
+                    raise KeyAlreadyPresent(key)
+
+                for table in item.body:
+                    current.append(table)
+
+                return self
+            else:
+                raise KeyAlreadyPresent(key)
+
+        is_table = isinstance(item, (Table, AoT))
+        if (
+            key is not None
+            and self._body
+            and not self._parsed
+            and (not is_table or key.is_dotted())
+        ):
+            # If there is already at least one table in the current container
+            # and the given item is not a table, we need to find the last
+            # item that is not a table and insert after it
+            # If no such item exists, insert at the top of the table
+            last_index = self._get_last_index_before_table()
+
+            if last_index < len(self._body):
+                return self._insert_at(last_index, key, item)
+            else:
+                previous_item = self._body[-1][1]
+                if not (
+                    isinstance(previous_item, Whitespace)
+                    or ends_with_whitespace(previous_item)
+                    or "\n" in previous_item.trivia.trail
+                ):
+                    previous_item.trivia.trail += "\n"
+
+        self._raw_append(key, item)
+        return self
+
+    def _raw_append(self, key: Key | None, item: Item) -> None:
+        if key in self._map:
+            current_idx = self._map[key]
+            if not isinstance(current_idx, tuple):
+                current_idx = (current_idx,)
+
+            current = self._body[current_idx[-1]][1]
+            if key is not None and not isinstance(current, Table):
+                raise KeyAlreadyPresent(key)
+
+            self._map[key] = (*current_idx, len(self._body))
+        elif key is not None:
+            self._map[key] = len(self._body)
+
+        self._body.append((key, item))
+        if item.is_table():
+            self._table_keys.append(key)
+
+        if key is not None:
+            dict.__setitem__(self, key.key, item.value)
+
+    def _remove_at(self, idx: int) -> None:
+        key = self._body[idx][0]
+        index = self._map.get(key)
+        if index is None:
+            raise NonExistentKey(key)
+        self._body[idx] = (None, Null())
+
+        if isinstance(index, tuple):
+            index = list(index)
+            index.remove(idx)
+            if len(index) == 1:
+                index = index.pop()
+            else:
+                index = tuple(index)
+            self._map[key] = index
+        else:
+            dict.__delitem__(self, key.key)
+            self._map.pop(key)
+
+    def remove(self, key: Key | str) -> Container:
+        """Remove a key from the container."""
+        if not isinstance(key, Key):
+            key = SingleKey(key)
+
+        idx = self._map.pop(key, None)
+        if idx is None:
+            raise NonExistentKey(key)
+
+        if isinstance(idx, tuple):
+            for i in idx:
+                self._body[i] = (None, Null())
+        else:
+            self._body[idx] = (None, Null())
+
+        dict.__delitem__(self, key.key)
+
+        return self
+
+    def _insert_after(
+        self, key: Key | str, other_key: Key | str, item: Any
+    ) -> Container:
+        if key is None:
+            raise ValueError("Key cannot be null in insert_after()")
+
+        if key not in self:
+            raise NonExistentKey(key)
+
+        if not isinstance(key, Key):
+            key = SingleKey(key)
+
+        if not isinstance(other_key, Key):
+            other_key = SingleKey(other_key)
+
+        item = _item(item)
+
+        idx = self._map[key]
+        # Insert after the max index if there are many.
+        if isinstance(idx, tuple):
+            idx = max(idx)
+        current_item = self._body[idx][1]
+        if "\n" not in current_item.trivia.trail:
+            current_item.trivia.trail += "\n"
+
+        # Increment indices after the current index
+        for k, v in self._map.items():
+            if isinstance(v, tuple):
+                new_indices = []
+                for v_ in v:
+                    if v_ > idx:
+                        v_ = v_ + 1
+
+                    new_indices.append(v_)
+
+                self._map[k] = tuple(new_indices)
+            elif v > idx:
+                self._map[k] = v + 1
+
+        self._map[other_key] = idx + 1
+        self._body.insert(idx + 1, (other_key, item))
+
+        if key is not None:
+            dict.__setitem__(self, other_key.key, item.value)
+
+        return self
+
+    def _insert_at(self, idx: int, key: Key | str, item: Any) -> Container:
+        if idx > len(self._body) - 1:
+            raise ValueError(f"Unable to insert at position {idx}")
+
+        if not isinstance(key, Key):
+            key = SingleKey(key)
+
+        item = _item(item)
+
+        if idx > 0:
+            previous_item = self._body[idx - 1][1]
+            if not (
+                isinstance(previous_item, Whitespace)
+                or ends_with_whitespace(previous_item)
+                or isinstance(item, (AoT, Table))
+                or "\n" in previous_item.trivia.trail
+            ):
+                previous_item.trivia.trail += "\n"
+
+        # Increment indices after the current index
+        for k, v in self._map.items():
+            if isinstance(v, tuple):
+                new_indices = []
+                for v_ in v:
+                    if v_ >= idx:
+                        v_ = v_ + 1
+
+                    new_indices.append(v_)
+
+                self._map[k] = tuple(new_indices)
+            elif v >= idx:
+                self._map[k] = v + 1
+
+        if key in self._map:
+            current_idx = self._map[key]
+            if not isinstance(current_idx, tuple):
+                current_idx = (current_idx,)
+            self._map[key] = (*current_idx, idx)
+        else:
+            self._map[key] = idx
+        self._body.insert(idx, (key, item))
+
+        dict.__setitem__(self, key.key, item.value)
+
+        return self
+
+    def item(self, key: Key | str) -> Item:
+        """Get an item for the given key."""
+        if not isinstance(key, Key):
+            key = SingleKey(key)
+
+        idx = self._map.get(key)
+        if idx is None:
+            raise NonExistentKey(key)
+
+        if isinstance(idx, tuple):
+            # The item we are getting is an out of order table
+            # so we need a proxy to retrieve the proper objects
+            # from the parent container
+            return OutOfOrderTableProxy(self, idx)
+
+        return self._body[idx][1]
+
+    def last_item(self) -> Item | None:
+        """Get the last item."""
+        if self._body:
+            return self._body[-1][1]
+
+    def as_string(self) -> str:
+        """Render as TOML string."""
+        s = ""
+        for k, v in self._body:
+            if k is not None:
+                if isinstance(v, Table):
+                    s += self._render_table(k, v)
+                elif isinstance(v, AoT):
+                    s += self._render_aot(k, v)
+                else:
+                    s += self._render_simple_item(k, v)
+            else:
+                s += self._render_simple_item(k, v)
+
+        return s
+
+    def _render_table(self, key: Key, table: Table, prefix: str | None = None) -> str:
+        cur = ""
+
+        if table.display_name is not None:
+            _key = table.display_name
+        else:
+            _key = key.as_string()
+
+            if prefix is not None:
+                _key = prefix + "." + _key
+
+        if not table.is_super_table() or (
+            any(
+                not isinstance(v, (Table, AoT, Whitespace, Null))
+                for _, v in table.value.body
+            )
+            and not key.is_dotted()
+        ):
+            open_, close = "[", "]"
+            if table.is_aot_element():
+                open_, close = "[[", "]]"
+
+            newline_in_table_trivia = (
+                "\n" if "\n" not in table.trivia.trail and len(table.value) > 0 else ""
+            )
+            cur += (
+                f"{table.trivia.indent}"
+                f"{open_}"
+                f"{decode(_key)}"
+                f"{close}"
+                f"{table.trivia.comment_ws}"
+                f"{decode(table.trivia.comment)}"
+                f"{table.trivia.trail}"
+                f"{newline_in_table_trivia}"
+            )
+        elif table.trivia.indent == "\n":
+            cur += table.trivia.indent
+
+        for k, v in table.value.body:
+            if isinstance(v, Table):
+                if v.is_super_table():
+                    if k.is_dotted() and not key.is_dotted():
+                        # Dotted key inside table
+                        cur += self._render_table(k, v)
+                    else:
+                        cur += self._render_table(k, v, prefix=_key)
+                else:
+                    cur += self._render_table(k, v, prefix=_key)
+            elif isinstance(v, AoT):
+                cur += self._render_aot(k, v, prefix=_key)
+            else:
+                cur += self._render_simple_item(
+                    k, v, prefix=_key if key.is_dotted() else None
+                )
+
+        return cur
+
+    def _render_aot(self, key, aot, prefix=None):
+        _key = key.as_string()
+        if prefix is not None:
+            _key = prefix + "." + _key
+
+        cur = ""
+        _key = decode(_key)
+        for table in aot.body:
+            cur += self._render_aot_table(table, prefix=_key)
+
+        return cur
+
+    def _render_aot_table(self, table: Table, prefix: str | None = None) -> str:
+        cur = ""
+        _key = prefix or ""
+        open_, close = "[[", "]]"
+
+        cur += (
+            f"{table.trivia.indent}"
+            f"{open_}"
+            f"{decode(_key)}"
+            f"{close}"
+            f"{table.trivia.comment_ws}"
+            f"{decode(table.trivia.comment)}"
+            f"{table.trivia.trail}"
+        )
+
+        for k, v in table.value.body:
+            if isinstance(v, Table):
+                if v.is_super_table():
+                    if k.is_dotted():
+                        # Dotted key inside table
+                        cur += self._render_table(k, v)
+                    else:
+                        cur += self._render_table(k, v, prefix=_key)
+                else:
+                    cur += self._render_table(k, v, prefix=_key)
+            elif isinstance(v, AoT):
+                cur += self._render_aot(k, v, prefix=_key)
+            else:
+                cur += self._render_simple_item(k, v)
+
+        return cur
+
+    def _render_simple_item(self, key, item, prefix=None):
+        if key is None:
+            return item.as_string()
+
+        _key = key.as_string()
+        if prefix is not None:
+            _key = prefix + "." + _key
+
+        return (
+            f"{item.trivia.indent}"
+            f"{decode(_key)}"
+            f"{key.sep}"
+            f"{decode(item.as_string())}"
+            f"{item.trivia.comment_ws}"
+            f"{decode(item.trivia.comment)}"
+            f"{item.trivia.trail}"
+        )
+
+    def __len__(self) -> int:
+        return dict.__len__(self)
+
+    def __iter__(self) -> Iterator[str]:
+        return iter(dict.keys(self))
+
+    # Dictionary methods
+    def __getitem__(self, key: Key | str) -> Item | Container:
+        item = self.item(key)
+        if isinstance(item, Item) and item.is_boolean():
+            return item.value
+
+        return item
+
+    def __setitem__(self, key: Key | str, value: Any) -> None:
+        if key is not None and key in self:
+            old_key = next(filter(lambda k: k == key, self._map))
+            self._replace(old_key, key, value)
+        else:
+            self.append(key, value)
+
+    def __delitem__(self, key: Key | str) -> None:
+        self.remove(key)
+
+    def setdefault(self, key: Key | str, default: Any) -> Any:
+        super().setdefault(key, default=default)
+        return self[key]
+
+    def _replace(self, key: Key | str, new_key: Key | str, value: Item) -> None:
+        if not isinstance(key, Key):
+            key = SingleKey(key)
+
+        idx = self._map.get(key)
+        if idx is None:
+            raise NonExistentKey(key)
+
+        self._replace_at(idx, new_key, value)
+
+    def _replace_at(
+        self, idx: int | tuple[int], new_key: Key | str, value: Item
+    ) -> None:
+        value = _item(value)
+
+        if isinstance(idx, tuple):
+            for i in idx[1:]:
+                self._body[i] = (None, Null())
+
+            idx = idx[0]
+
+        k, v = self._body[idx]
+        if not isinstance(new_key, Key):
+            if (
+                isinstance(value, (AoT, Table)) != isinstance(v, (AoT, Table))
+                or new_key != k.key
+            ):
+                new_key = SingleKey(new_key)
+            else:  # Inherit the sep of the old key
+                new_key = k
+
+        del self._map[k]
+        self._map[new_key] = idx
+        if new_key != k:
+            dict.__delitem__(self, k)
+
+        if isinstance(value, (AoT, Table)) != isinstance(v, (AoT, Table)):
+            # new tables should appear after all non-table values
+            self.remove(k)
+            for i in range(idx, len(self._body)):
+                if isinstance(self._body[i][1], (AoT, Table)):
+                    self._insert_at(i, new_key, value)
+                    idx = i
+                    break
+            else:
+                idx = -1
+                self.append(new_key, value)
+        else:
+            # Copying trivia
+            if not isinstance(value, (Whitespace, AoT)):
+                value.trivia.indent = v.trivia.indent
+                value.trivia.comment_ws = value.trivia.comment_ws or v.trivia.comment_ws
+                value.trivia.comment = value.trivia.comment or v.trivia.comment
+                value.trivia.trail = v.trivia.trail
+            self._body[idx] = (new_key, value)
+
+        if hasattr(value, "invalidate_display_name"):
+            value.invalidate_display_name()  # type: ignore[attr-defined]
+
+        if isinstance(value, Table):
+            # Insert a cosmetic new line for tables if:
+            # - it does not have it yet OR is not followed by one
+            # - it is not the last item, or
+            # - The table being replaced has a newline
+            last, _ = self._previous_item_with_index()
+            idx = last if idx < 0 else idx
+            has_ws = ends_with_whitespace(value)
+            replace_has_ws = (
+                isinstance(v, Table)
+                and v.value.body
+                and isinstance(v.value.body[-1][1], Whitespace)
+            )
+            next_ws = idx < last and isinstance(self._body[idx + 1][1], Whitespace)
+            if (idx < last or replace_has_ws) and not (next_ws or has_ws):
+                value.append(None, Whitespace("\n"))
+
+            dict.__setitem__(self, new_key.key, value.value)
+
+    def __str__(self) -> str:
+        return str(self.value)
+
+    def __repr__(self) -> str:
+        return repr(self.value)
+
+    def __eq__(self, other: dict) -> bool:
+        if not isinstance(other, dict):
+            return NotImplemented
+
+        return self.value == other
+
+    def _getstate(self, protocol):
+        return (self._parsed,)
+
+    def __reduce__(self):
+        return self.__reduce_ex__(2)
+
+    def __reduce_ex__(self, protocol):
+        return (
+            self.__class__,
+            self._getstate(protocol),
+            (self._map, self._body, self._parsed, self._table_keys),
+        )
+
+    def __setstate__(self, state):
+        self._map = state[0]
+        self._body = state[1]
+        self._parsed = state[2]
+        self._table_keys = state[3]
+
+        for key, item in self._body:
+            if key is not None:
+                dict.__setitem__(self, key.key, item.value)
+
+    def copy(self) -> Container:
+        return copy.copy(self)
+
+    def __copy__(self) -> Container:
+        c = self.__class__(self._parsed)
+        for k, v in dict.items(self):
+            dict.__setitem__(c, k, v)
+
+        c._body += self.body
+        c._map.update(self._map)
+
+        return c
+
+    def _previous_item_with_index(
+        self, idx: int | None = None, ignore=(Null,)
+    ) -> tuple[int, Item] | None:
+        """Find the immediate previous item before index ``idx``"""
+        if idx is None or idx > len(self._body):
+            idx = len(self._body)
+        for i in range(idx - 1, -1, -1):
+            v = self._body[i][-1]
+            if not isinstance(v, ignore):
+                return i, v
+        return None
+
+    def _previous_item(self, idx: int | None = None, ignore=(Null,)) -> Item | None:
+        """Find the immediate previous item before index ``idx``.
+        If ``idx`` is not given, the last item is returned.
+        """
+        prev = self._previous_item_with_index(idx, ignore)
+        return prev[-1] if prev else None
+
+
+class OutOfOrderTableProxy(_CustomDict):
+    @staticmethod
+    def validate(container: Container, indices: tuple[int, ...]) -> None:
+        """Validate out of order tables in the given container"""
+        # Append all items to a temp container to see if there is any error
+        temp_container = Container(True)
+        for i in indices:
+            _, item = container._body[i]
+
+            if isinstance(item, Table):
+                for k, v in item.value.body:
+                    temp_container.append(k, v, validate=False)
+
+        temp_container._validate_out_of_order_table()
+
+    def __init__(self, container: Container, indices: tuple[int, ...]) -> None:
+        self._container = container
+        self._internal_container = Container(True)
+        self._tables = []
+        self._tables_map = {}
+
+        for i in indices:
+            _, item = self._container._body[i]
+
+            if isinstance(item, Table):
+                self._tables.append(item)
+                table_idx = len(self._tables) - 1
+                for k, v in item.value.body:
+                    self._internal_container._raw_append(k, v)
+                    self._tables_map.setdefault(k, []).append(table_idx)
+                    if k is not None:
+                        dict.__setitem__(self, k.key, v)
+
+        self._internal_container._validate_out_of_order_table()
+
+    def unwrap(self) -> str:
+        return self._internal_container.unwrap()
+
+    @property
+    def value(self):
+        return self._internal_container.value
+
+    def __getitem__(self, key: Key | str) -> Any:
+        if key not in self._internal_container:
+            raise NonExistentKey(key)
+
+        return self._internal_container[key]
+
+    def __setitem__(self, key: Key | str, item: Any) -> None:
+        if key in self._tables_map:
+            # Overwrite the first table and remove others
+            indices = self._tables_map[key]
+            while len(indices) > 1:
+                table = self._tables[indices.pop()]
+                self._remove_table(table)
+            self._tables[indices[0]][key] = item
+        elif self._tables:
+            table = self._tables[0]
+            table[key] = item
+        else:
+            self._container[key] = item
+
+        self._internal_container[key] = item
+        if key is not None:
+            dict.__setitem__(self, key, item)
+
+    def _remove_table(self, table: Table) -> None:
+        """Remove table from the parent container"""
+        self._tables.remove(table)
+        for idx, item in enumerate(self._container._body):
+            if item[1] is table:
+                self._container._remove_at(idx)
+                break
+
+    def __delitem__(self, key: Key | str) -> None:
+        if key not in self._tables_map:
+            raise NonExistentKey(key)
+
+        for i in reversed(self._tables_map[key]):
+            table = self._tables[i]
+            del table[key]
+            if not table and len(self._tables) > 1:
+                self._remove_table(table)
+
+        del self._tables_map[key]
+        del self._internal_container[key]
+        if key is not None:
+            dict.__delitem__(self, key)
+
+    def __iter__(self) -> Iterator[str]:
+        return iter(dict.keys(self))
+
+    def __len__(self) -> int:
+        return dict.__len__(self)
+
+    def setdefault(self, key: Key | str, default: Any) -> Any:
+        super().setdefault(key, default=default)
+        return self[key]
+
+
+def ends_with_whitespace(it: Any) -> bool:
+    """Returns ``True`` if the given item ``it`` is a ``Table`` or ``AoT`` object
+    ending with a ``Whitespace``.
+    """
+    return (
+        isinstance(it, Table) and isinstance(it.value._previous_item(), Whitespace)
+    ) or (isinstance(it, AoT) and len(it) > 0 and isinstance(it[-1], Whitespace))
diff --git a/venv/lib/python3.9/site-packages/tomlkit/exceptions.py b/venv/lib/python3.9/site-packages/tomlkit/exceptions.py
new file mode 100644
index 000000000..8c7e6e749
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit/exceptions.py
@@ -0,0 +1,234 @@
+from __future__ import annotations
+
+from typing import Collection
+
+
+class TOMLKitError(Exception):
+    pass
+
+
+class ParseError(ValueError, TOMLKitError):
+    """
+    This error occurs when the parser encounters a syntax error
+    in the TOML being parsed. The error references the line and
+    location within the line where the error was encountered.
+    """
+
+    def __init__(self, line: int, col: int, message: str | None = None) -> None:
+        self._line = line
+        self._col = col
+
+        if message is None:
+            message = "TOML parse error"
+
+        super().__init__(f"{message} at line {self._line} col {self._col}")
+
+    @property
+    def line(self):
+        return self._line
+
+    @property
+    def col(self):
+        return self._col
+
+
+class MixedArrayTypesError(ParseError):
+    """
+    An array was found that had two or more element types.
+    """
+
+    def __init__(self, line: int, col: int) -> None:
+        message = "Mixed types found in array"
+
+        super().__init__(line, col, message=message)
+
+
+class InvalidNumberError(ParseError):
+    """
+    A numeric field was improperly specified.
+    """
+
+    def __init__(self, line: int, col: int) -> None:
+        message = "Invalid number"
+
+        super().__init__(line, col, message=message)
+
+
+class InvalidDateTimeError(ParseError):
+    """
+    A datetime field was improperly specified.
+    """
+
+    def __init__(self, line: int, col: int) -> None:
+        message = "Invalid datetime"
+
+        super().__init__(line, col, message=message)
+
+
+class InvalidDateError(ParseError):
+    """
+    A date field was improperly specified.
+    """
+
+    def __init__(self, line: int, col: int) -> None:
+        message = "Invalid date"
+
+        super().__init__(line, col, message=message)
+
+
+class InvalidTimeError(ParseError):
+    """
+    A date field was improperly specified.
+    """
+
+    def __init__(self, line: int, col: int) -> None:
+        message = "Invalid time"
+
+        super().__init__(line, col, message=message)
+
+
+class InvalidNumberOrDateError(ParseError):
+    """
+    A numeric or date field was improperly specified.
+    """
+
+    def __init__(self, line: int, col: int) -> None:
+        message = "Invalid number or date format"
+
+        super().__init__(line, col, message=message)
+
+
+class InvalidUnicodeValueError(ParseError):
+    """
+    A unicode code was improperly specified.
+    """
+
+    def __init__(self, line: int, col: int) -> None:
+        message = "Invalid unicode value"
+
+        super().__init__(line, col, message=message)
+
+
+class UnexpectedCharError(ParseError):
+    """
+    An unexpected character was found during parsing.
+    """
+
+    def __init__(self, line: int, col: int, char: str) -> None:
+        message = f"Unexpected character: {char!r}"
+
+        super().__init__(line, col, message=message)
+
+
+class EmptyKeyError(ParseError):
+    """
+    An empty key was found during parsing.
+    """
+
+    def __init__(self, line: int, col: int) -> None:
+        message = "Empty key"
+
+        super().__init__(line, col, message=message)
+
+
+class EmptyTableNameError(ParseError):
+    """
+    An empty table name was found during parsing.
+    """
+
+    def __init__(self, line: int, col: int) -> None:
+        message = "Empty table name"
+
+        super().__init__(line, col, message=message)
+
+
+class InvalidCharInStringError(ParseError):
+    """
+    The string being parsed contains an invalid character.
+    """
+
+    def __init__(self, line: int, col: int, char: str) -> None:
+        message = f"Invalid character {char!r} in string"
+
+        super().__init__(line, col, message=message)
+
+
+class UnexpectedEofError(ParseError):
+    """
+    The TOML being parsed ended before the end of a statement.
+    """
+
+    def __init__(self, line: int, col: int) -> None:
+        message = "Unexpected end of file"
+
+        super().__init__(line, col, message=message)
+
+
+class InternalParserError(ParseError):
+    """
+    An error that indicates a bug in the parser.
+    """
+
+    def __init__(self, line: int, col: int, message: str | None = None) -> None:
+        msg = "Internal parser error"
+        if message:
+            msg += f" ({message})"
+
+        super().__init__(line, col, message=msg)
+
+
+class NonExistentKey(KeyError, TOMLKitError):
+    """
+    A non-existent key was used.
+    """
+
+    def __init__(self, key):
+        message = f'Key "{key}" does not exist.'
+
+        super().__init__(message)
+
+
+class KeyAlreadyPresent(TOMLKitError):
+    """
+    An already present key was used.
+    """
+
+    def __init__(self, key):
+        key = getattr(key, "key", key)
+        message = f'Key "{key}" already exists.'
+
+        super().__init__(message)
+
+
+class InvalidControlChar(ParseError):
+    def __init__(self, line: int, col: int, char: int, type: str) -> None:
+        display_code = "\\u00"
+
+        if char < 16:
+            display_code += "0"
+
+        display_code += hex(char)[2:]
+
+        message = (
+            "Control characters (codes less than 0x1f and 0x7f)"
+            f" are not allowed in {type}, "
+            f"use {display_code} instead"
+        )
+
+        super().__init__(line, col, message=message)
+
+
+class InvalidStringError(ValueError, TOMLKitError):
+    def __init__(self, value: str, invalid_sequences: Collection[str], delimiter: str):
+        repr_ = repr(value)[1:-1]
+        super().__init__(
+            f"Invalid string: {delimiter}{repr_}{delimiter}. "
+            f"The character sequences {invalid_sequences} are invalid."
+        )
+
+
+class ConvertError(TypeError, ValueError, TOMLKitError):
+    """Raised when item() fails to convert a value.
+    It should be a TypeError, but due to historical reasons
+    it needs to subclass ValueError as well.
+    """
diff --git a/venv/lib/python3.9/site-packages/tomlkit/items.py b/venv/lib/python3.9/site-packages/tomlkit/items.py
new file mode 100644
index 000000000..b46679b36
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit/items.py
@@ -0,0 +1,1960 @@
+from __future__ import annotations
+
+import abc
+import copy
+import dataclasses
+import math
+import re
+import string
+import sys
+
+from datetime import date
+from datetime import datetime
+from datetime import time
+from datetime import tzinfo
+from enum import Enum
+from typing import TYPE_CHECKING
+from typing import Any
+from typing import Callable
+from typing import Collection
+from typing import Iterable
+from typing import Iterator
+from typing import Sequence
+from typing import TypeVar
+from typing import cast
+from typing import overload
+
+from tomlkit._compat import PY38
+from tomlkit._compat import decode
+from tomlkit._types import _CustomDict
+from tomlkit._types import _CustomFloat
+from tomlkit._types import _CustomInt
+from tomlkit._types import _CustomList
+from tomlkit._types import wrap_method
+from tomlkit._utils import CONTROL_CHARS
+from tomlkit._utils import escape_string
+from tomlkit.exceptions import ConvertError
+from tomlkit.exceptions import InvalidStringError
+
+
+if TYPE_CHECKING:
+    from tomlkit import container
+
+
+ItemT = TypeVar("ItemT", bound="Item")
+Encoder = Callable[[Any], "Item"]
+CUSTOM_ENCODERS: list[Encoder] = []
+AT = TypeVar("AT", bound="AbstractTable")
+
+
+@overload
+def item(value: bool, _parent: Item | None = ..., _sort_keys: bool = ...) -> Bool: ...
+
+
+@overload
+def item(value: int, _parent: Item | None = ..., _sort_keys: bool = ...) -> Integer: ...
+
+
+@overload
+def item(value: float, _parent: Item | None = ..., _sort_keys: bool = ...) -> Float: ...
+
+
+@overload
+def item(value: str, _parent: Item | None = ..., _sort_keys: bool = ...) -> String: ...
+
+
+@overload
+def item(
+    value: datetime, _parent: Item | None = ..., _sort_keys: bool = ...
+) -> DateTime: ...
+
+
+@overload
+def item(value: date, _parent: Item | None = ..., _sort_keys: bool = ...) -> Date: ...
+
+
+@overload
+def item(value: time, _parent: Item | None = ..., _sort_keys: bool = ...) -> Time: ...
+
+
+@overload
+def item(
+    value: Sequence[dict], _parent: Item | None = ..., _sort_keys: bool = ...
+) -> AoT: ...
+
+
+@overload
+def item(
+    value: Sequence, _parent: Item | None = ..., _sort_keys: bool = ...
+) -> Array: ...
+
+
+@overload
+def item(value: dict, _parent: Array = ..., _sort_keys: bool = ...) -> InlineTable: ...
+
+
+@overload
+def item(value: dict, _parent: Item | None = ..., _sort_keys: bool = ...) -> Table: ...
+
+
+@overload
+def item(value: ItemT, _parent: Item | None = ..., _sort_keys: bool = ...) -> ItemT: ...
+
+
+def item(value: Any, _parent: Item | None = None, _sort_keys: bool = False) -> Item:
+    """Create a TOML item from a Python object.
+
+    :Example:
+
+    >>> item(42)
+    42
+    >>> item([1, 2, 3])
+    [1, 2, 3]
+    >>> item({'a': 1, 'b': 2})
+    a = 1
+    b = 2
+    """
+
+    from tomlkit.container import Container
+
+    if isinstance(value, Item):
+        return value
+
+    if isinstance(value, bool):
+        return Bool(value, Trivia())
+    elif isinstance(value, int):
+        return Integer(value, Trivia(), str(value))
+    elif isinstance(value, float):
+        return Float(value, Trivia(), str(value))
+    elif isinstance(value, dict):
+        table_constructor = (
+            InlineTable if isinstance(_parent, (Array, InlineTable)) else Table
+        )
+        val = table_constructor(Container(), Trivia(), False)
+        for k, v in sorted(
+            value.items(),
+            key=lambda i: (isinstance(i[1], dict), i[0]) if _sort_keys else 1,
+        ):
+            val[k] = item(v, _parent=val, _sort_keys=_sort_keys)
+
+        return val
+    elif isinstance(value, (list, tuple)):
+        if (
+            value
+            and all(isinstance(v, dict) for v in value)
+            and (_parent is None or isinstance(_parent, Table))
+        ):
+            a = AoT([])
+            table_constructor = Table
+        else:
+            a = Array([], Trivia())
+            table_constructor = InlineTable
+
+        for v in value:
+            if isinstance(v, dict):
+                table = table_constructor(Container(), Trivia(), True)
+
+                for k, _v in sorted(
+                    v.items(),
+                    key=lambda i: (isinstance(i[1], dict), i[0] if _sort_keys else 1),
+                ):
+                    i = item(_v, _parent=table, _sort_keys=_sort_keys)
+                    if isinstance(table, InlineTable):
+                        i.trivia.trail = ""
+
+                    table[k] = i
+
+                v = table
+
+            a.append(v)
+
+        return a
+    elif isinstance(value, str):
+        return String.from_raw(value)
+    elif isinstance(value, datetime):
+        return DateTime(
+            value.year,
+            value.month,
+            value.day,
+            value.hour,
+            value.minute,
+            value.second,
+            value.microsecond,
+            value.tzinfo,
+            Trivia(),
+            value.isoformat().replace("+00:00", "Z"),
+        )
+    elif isinstance(value, date):
+        return Date(value.year, value.month, value.day, Trivia(), value.isoformat())
+    elif isinstance(value, time):
+        return Time(
+            value.hour,
+            value.minute,
+            value.second,
+            value.microsecond,
+            value.tzinfo,
+            Trivia(),
+            value.isoformat(),
+        )
+    else:
+        for encoder in CUSTOM_ENCODERS:
+            try:
+                rv = encoder(value)
+            except ConvertError:
+                pass
+            else:
+                if not isinstance(rv, Item):
+                    raise ConvertError(
+                        f"Custom encoder is expected to return an instance of Item, got {type(rv)}"
+                    )
+                return rv
+
+    raise ConvertError(f"Unable to convert an object of {type(value)} to a TOML item")
+
+
+class StringType(Enum):
+    # Single Line Basic
+    SLB = '"'
+    # Multi Line Basic
+    MLB = '"""'
+    # Single Line Literal
+    SLL = "'"
+    # Multi Line Literal
+    MLL = "'''"
+
+    @classmethod
+    def select(cls, literal=False, multiline=False) -> StringType:
+        return {
+            (False, False): cls.SLB,
+            (False, True): cls.MLB,
+            (True, False): cls.SLL,
+            (True, True): cls.MLL,
+        }[(literal, multiline)]
+
+    @property
+    def escaped_sequences(self) -> Collection[str]:
+        # https://toml.io/en/v1.0.0#string
+        escaped_in_basic = CONTROL_CHARS | {"\\"}
+        allowed_in_multiline = {"\n", "\r"}
+        return {
+            StringType.SLB: escaped_in_basic | {'"'},
+            StringType.MLB: (escaped_in_basic | {'"""'}) - allowed_in_multiline,
+            StringType.SLL: (),
+            StringType.MLL: (),
+        }[self]
+
+    @property
+    def invalid_sequences(self) -> Collection[str]:
+        # https://toml.io/en/v1.0.0#string
+        forbidden_in_literal = CONTROL_CHARS - {"\t"}
+        allowed_in_multiline = {"\n", "\r"}
+        return {
+            StringType.SLB: (),
+            StringType.MLB: (),
+            StringType.SLL: forbidden_in_literal | {"'"},
+            StringType.MLL: (forbidden_in_literal | {"'''"}) - allowed_in_multiline,
+        }[self]
+
+    @property
+    def unit(self) -> str:
+        return self.value[0]
+
+    def is_basic(self) -> bool:
+        return self in {StringType.SLB, StringType.MLB}
+
+    def is_literal(self) -> bool:
+        return self in {StringType.SLL, StringType.MLL}
+
+    def is_singleline(self) -> bool:
+        return self in {StringType.SLB, StringType.SLL}
+
+    def is_multiline(self) -> bool:
+        return self in {StringType.MLB, StringType.MLL}
+
+    def toggle(self) -> StringType:
+        return {
+            StringType.SLB: StringType.MLB,
+            StringType.MLB: StringType.SLB,
+            StringType.SLL: StringType.MLL,
+            StringType.MLL: StringType.SLL,
+        }[self]
+
+
+class BoolType(Enum):
+    TRUE = "true"
+    FALSE = "false"
+
+    def __bool__(self):
+        return {BoolType.TRUE: True, BoolType.FALSE: False}[self]
+
+    def __iter__(self):
+        return iter(self.value)
+
+    def __len__(self):
+        return len(self.value)
+
+
+@dataclasses.dataclass
+class Trivia:
+    """
+    Trivia information (aka metadata).
+    """
+
+    # Whitespace before a value.
+    indent: str = ""
+    # Whitespace after a value, but before a comment.
+    comment_ws: str = ""
+    # Comment, starting with # character, or empty string if no comment.
+    comment: str = ""
+    # Trailing newline.
+    trail: str = "\n"
+
+    def copy(self) -> Trivia:
+        return dataclasses.replace(self)
+
+
+class KeyType(Enum):
+    """
+    The type of a Key.
+
+    Keys can be bare (unquoted), or quoted using basic ("), or literal (')
+    quotes following the same escaping rules as single-line StringType.
+    """
+
+    Bare = ""
+    Basic = '"'
+    Literal = "'"
+
+
+class Key(abc.ABC):
+    """Base class for a key"""
+
+    sep: str
+    _original: str
+    _keys: list[SingleKey]
+    _dotted: bool
+    key: str
+
+    @abc.abstractmethod
+    def __hash__(self) -> int:
+        pass
+
+    @abc.abstractmethod
+    def __eq__(self, __o: object) -> bool:
+        pass
+
+    def is_dotted(self) -> bool:
+        """If the key is followed by other keys"""
+        return self._dotted
+
+    def __iter__(self) -> Iterator[SingleKey]:
+        return iter(self._keys)
+
+    def concat(self, other: Key) -> DottedKey:
+        """Concatenate keys into a dotted key"""
+        keys = self._keys + other._keys
+        return DottedKey(keys, sep=self.sep)
+
+    def is_multi(self) -> bool:
+        """Check if the key contains multiple keys"""
+        return len(self._keys) > 1
+
+    def as_string(self) -> str:
+        """The TOML representation"""
+        return self._original
+
+    def __str__(self) -> str:
+        return self.as_string()
+
+    def __repr__(self) -> str:
+        return f"<Key {self.as_string()}>"
+
+
+class SingleKey(Key):
+    """A single key"""
+
+    def __init__(
+        self,
+        k: str,
+        t: KeyType | None = None,
+        sep: str | None = None,
+        original: str | None = None,
+    ) -> None:
+        if t is None:
+            if not k or any(
+                c not in string.ascii_letters + string.digits + "-" + "_" for c in k
+            ):
+                t = KeyType.Basic
+            else:
+                t = KeyType.Bare
+
+        self.t = t
+        if sep is None:
+            sep = " = "
+
+        self.sep = sep
+        self.key = k
+        if original is None:
+            key_str = escape_string(k) if t == KeyType.Basic else k
+            original = f"{t.value}{key_str}{t.value}"
+
+        self._original = original
+        self._keys = [self]
+        self._dotted = False
+
+    @property
+    def delimiter(self) -> str:
+        """The delimiter: double quote/single quote/none"""
+        return self.t.value
+
+    def is_bare(self) -> bool:
+        """Check if the key is bare"""
+        return self.t == KeyType.Bare
+
+    def __hash__(self) -> int:
+        return hash(self.key)
+
+    def __eq__(self, other: Any) -> bool:
+        if isinstance(other, Key):
+            return isinstance(other, SingleKey) and self.key == other.key
+
+        return self.key == other
+
+
+class DottedKey(Key):
+    def __init__(
+        self,
+        keys: Iterable[SingleKey],
+        sep: str | None = None,
+        original: str | None = None,
+    ) -> None:
+        self._keys = list(keys)
+        if original is None:
+            original = ".".join(k.as_string() for k in self._keys)
+
+        self.sep = " = " if sep is None else sep
+        self._original = original
+        self._dotted = False
+        self.key = ".".join(k.key for k in self._keys)
+
+    def __hash__(self) -> int:
+        return hash(tuple(self._keys))
+
+    def __eq__(self, __o: object) -> bool:
+        return isinstance(__o, DottedKey) and self._keys == __o._keys
+
+
+class Item:
+    """
+    An item within a TOML document.
+    """
+
+    def __init__(self, trivia: Trivia) -> None:
+        self._trivia = trivia
+
+    @property
+    def trivia(self) -> Trivia:
+        """The trivia element associated with this item"""
+        return self._trivia
+
+    @property
+    def discriminant(self) -> int:
+        raise NotImplementedError()
+
+    def as_string(self) -> str:
+        """The TOML representation"""
+        raise NotImplementedError()
+
+    @property
+    def value(self) -> Any:
+        return self
+
+    def unwrap(self) -> Any:
+        """Returns as pure python object (ppo)"""
+        raise NotImplementedError()
+
+    # Helpers
+
+    def comment(self, comment: str) -> Item:
+        """Attach a comment to this item"""
+        if not comment.strip().startswith("#"):
+            comment = "# " + comment
+
+        self._trivia.comment_ws = " "
+        self._trivia.comment = comment
+
+        return self
+
+    def indent(self, indent: int) -> Item:
+        """Indent this item with given number of spaces"""
+        if self._trivia.indent.startswith("\n"):
+            self._trivia.indent = "\n" + " " * indent
+        else:
+            self._trivia.indent = " " * indent
+
+        return self
+
+    def is_boolean(self) -> bool:
+        return isinstance(self, Bool)
+
+    def is_table(self) -> bool:
+        return isinstance(self, Table)
+
+    def is_inline_table(self) -> bool:
+        return isinstance(self, InlineTable)
+
+    def is_aot(self) -> bool:
+        return isinstance(self, AoT)
+
+    def _getstate(self, protocol=3):
+        return (self._trivia,)
+
+    def __reduce__(self):
+        return self.__reduce_ex__(2)
+
+    def __reduce_ex__(self, protocol):
+        return self.__class__, self._getstate(protocol)
+
+
+class Whitespace(Item):
+    """
+    A whitespace literal.
+    """
+
+    def __init__(self, s: str, fixed: bool = False) -> None:
+        self._s = s
+        self._fixed = fixed
+
+    @property
+    def s(self) -> str:
+        return self._s
+
+    @property
+    def value(self) -> str:
+        """The wrapped string of the whitespace"""
+        return self._s
+
+    @property
+    def trivia(self) -> Trivia:
+        raise RuntimeError("Called trivia on a Whitespace variant.")
+
+    @property
+    def discriminant(self) -> int:
+        return 0
+
+    def is_fixed(self) -> bool:
+        """If the whitespace is fixed, it can't be merged or discarded from the output."""
+        return self._fixed
+
+    def as_string(self) -> str:
+        return self._s
+
+    def __repr__(self) -> str:
+        return f"<{self.__class__.__name__} {self._s!r}>"
+
+    def _getstate(self, protocol=3):
+        return self._s, self._fixed
+
+
+class Comment(Item):
+    """
+    A comment literal.
+    """
+
+    @property
+    def discriminant(self) -> int:
+        return 1
+
+    def as_string(self) -> str:
+        return (
+            f"{self._trivia.indent}{decode(self._trivia.comment)}{self._trivia.trail}"
+        )
+
+    def __str__(self) -> str:
+        return f"{self._trivia.indent}{decode(self._trivia.comment)}"
+
+
+class Integer(Item, _CustomInt):
+    """
+    An integer literal.
+    """
+
+    def __new__(cls, value: int, trivia: Trivia, raw: str) -> Integer:
+        return int.__new__(cls, value)
+
+    def __init__(self, value: int, trivia: Trivia, raw: str) -> None:
+        super().__init__(trivia)
+        self._original = value
+        self._raw = raw
+        self._sign = False
+
+        if re.match(r"^[+\-]\d+$", raw):
+            self._sign = True
+
+    def unwrap(self) -> int:
+        return self._original
+
+    __int__ = unwrap
+
+    def __hash__(self) -> int:
+        return hash(self.unwrap())
+
+    @property
+    def discriminant(self) -> int:
+        return 2
+
+    @property
+    def value(self) -> int:
+        """The wrapped integer value"""
+        return self
+
+    def as_string(self) -> str:
+        return self._raw
+
+    def _new(self, result):
+        raw = str(result)
+        if self._sign and result >= 0:
+            raw = f"+{raw}"
+
+        return Integer(result, self._trivia, raw)
+
+    def _getstate(self, protocol=3):
+        return int(self), self._trivia, self._raw
+
+    # int methods
+    __abs__ = wrap_method(int.__abs__)
+    __add__ = wrap_method(int.__add__)
+    __and__ = wrap_method(int.__and__)
+    __ceil__ = wrap_method(int.__ceil__)
+    __eq__ = int.__eq__
+    __floor__ = wrap_method(int.__floor__)
+    __floordiv__ = wrap_method(int.__floordiv__)
+    __invert__ = wrap_method(int.__invert__)
+    __le__ = int.__le__
+    __lshift__ = wrap_method(int.__lshift__)
+    __lt__ = int.__lt__
+    __mod__ = wrap_method(int.__mod__)
+    __mul__ = wrap_method(int.__mul__)
+    __neg__ = wrap_method(int.__neg__)
+    __or__ = wrap_method(int.__or__)
+    __pos__ = wrap_method(int.__pos__)
+    __pow__ = wrap_method(int.__pow__)
+    __radd__ = wrap_method(int.__radd__)
+    __rand__ = wrap_method(int.__rand__)
+    __rfloordiv__ = wrap_method(int.__rfloordiv__)
+    __rlshift__ = wrap_method(int.__rlshift__)
+    __rmod__ = wrap_method(int.__rmod__)
+    __rmul__ = wrap_method(int.__rmul__)
+    __ror__ = wrap_method(int.__ror__)
+    __round__ = wrap_method(int.__round__)
+    __rpow__ = wrap_method(int.__rpow__)
+    __rrshift__ = wrap_method(int.__rrshift__)
+    __rshift__ = wrap_method(int.__rshift__)
+    __rxor__ = wrap_method(int.__rxor__)
+    __trunc__ = wrap_method(int.__trunc__)
+    __xor__ = wrap_method(int.__xor__)
+
+    def __rtruediv__(self, other):
+        result = int.__rtruediv__(self, other)
+        if result is NotImplemented:
+            return result
+        return Float._new(self, result)
+
+    def __truediv__(self, other):
+        result = int.__truediv__(self, other)
+        if result is NotImplemented:
+            return result
+        return Float._new(self, result)
+
+
+class Float(Item, _CustomFloat):
+    """
+    A float literal.
+    """
+
+    def __new__(cls, value: float, trivia: Trivia, raw: str) -> Float:
+        return float.__new__(cls, value)
+
+    def __init__(self, value: float, trivia: Trivia, raw: str) -> None:
+        super().__init__(trivia)
+        self._original = value
+        self._raw = raw
+        self._sign = False
+
+        if re.match(r"^[+\-].+$", raw):
+            self._sign = True
+
+    def unwrap(self) -> float:
+        return self._original
+
+    __float__ = unwrap
+
+    def __hash__(self) -> int:
+        return hash(self.unwrap())
+
+    @property
+    def discriminant(self) -> int:
+        return 3
+
+    @property
+    def value(self) -> float:
+        """The wrapped float value"""
+        return self
+
+    def as_string(self) -> str:
+        return self._raw
+
+    def _new(self, result):
+        raw = str(result)
+
+        if self._sign and result >= 0:
+            raw = f"+{raw}"
+
+        return Float(result, self._trivia, raw)
+
+    def _getstate(self, protocol=3):
+        return float(self), self._trivia, self._raw
+
+    # float methods
+    __abs__ = wrap_method(float.__abs__)
+    __add__ = wrap_method(float.__add__)
+    __eq__ = float.__eq__
+    __floordiv__ = wrap_method(float.__floordiv__)
+    __le__ = float.__le__
+    __lt__ = float.__lt__
+    __mod__ = wrap_method(float.__mod__)
+    __mul__ = wrap_method(float.__mul__)
+    __neg__ = wrap_method(float.__neg__)
+    __pos__ = wrap_method(float.__pos__)
+    __pow__ = wrap_method(float.__pow__)
+    __radd__ = wrap_method(float.__radd__)
+    __rfloordiv__ = wrap_method(float.__rfloordiv__)
+    __rmod__ = wrap_method(float.__rmod__)
+    __rmul__ = wrap_method(float.__rmul__)
+    __round__ = wrap_method(float.__round__)
+    __rpow__ = wrap_method(float.__rpow__)
+    __rtruediv__ = wrap_method(float.__rtruediv__)
+    __truediv__ = wrap_method(float.__truediv__)
+    __trunc__ = float.__trunc__
+
+    if sys.version_info >= (3, 9):
+        __ceil__ = float.__ceil__
+        __floor__ = float.__floor__
+    else:
+        __ceil__ = math.ceil
+        __floor__ = math.floor
+
+
+class Bool(Item):
+    """
+    A boolean literal.
+    """
+
+    def __init__(self, t: int, trivia: Trivia) -> None:
+        super().__init__(trivia)
+
+        self._value = bool(t)
+
+    def unwrap(self) -> bool:
+        return bool(self)
+
+    @property
+    def discriminant(self) -> int:
+        return 4
+
+    @property
+    def value(self) -> bool:
+        """The wrapped boolean value"""
+        return self._value
+
+    def as_string(self) -> str:
+        return str(self._value).lower()
+
+    def _getstate(self, protocol=3):
+        return self._value, self._trivia
+
+    def __bool__(self):
+        return self._value
+
+    __nonzero__ = __bool__
+
+    def __eq__(self, other):
+        if not isinstance(other, bool):
+            return NotImplemented
+
+        return other == self._value
+
+    def __hash__(self):
+        return hash(self._value)
+
+    def __repr__(self):
+        return repr(self._value)
+
+
+class DateTime(Item, datetime):
+    """
+    A datetime literal.
+    """
+
+    def __new__(
+        cls,
+        year: int,
+        month: int,
+        day: int,
+        hour: int,
+        minute: int,
+        second: int,
+        microsecond: int,
+        tzinfo: tzinfo | None,
+        *_: Any,
+        **kwargs: Any,
+    ) -> datetime:
+        return datetime.__new__(
+            cls,
+            year,
+            month,
+            day,
+            hour,
+            minute,
+            second,
+            microsecond,
+            tzinfo=tzinfo,
+            **kwargs,
+        )
+
+    def __init__(
+        self,
+        year: int,
+        month: int,
+        day: int,
+        hour: int,
+        minute: int,
+        second: int,
+        microsecond: int,
+        tzinfo: tzinfo | None,
+        trivia: Trivia | None = None,
+        raw: str | None = None,
+        **kwargs: Any,
+    ) -> None:
+        super().__init__(trivia or Trivia())
+
+        self._raw = raw or self.isoformat()
+
+    def unwrap(self) -> datetime:
+        (
+            year,
+            month,
+            day,
+            hour,
+            minute,
+            second,
+            microsecond,
+            tzinfo,
+            _,
+            _,
+        ) = self._getstate()
+        return datetime(year, month, day, hour, minute, second, microsecond, tzinfo)
+
+    @property
+    def discriminant(self) -> int:
+        return 5
+
+    @property
+    def value(self) -> datetime:
+        return self
+
+    def as_string(self) -> str:
+        return self._raw
+
+    def __add__(self, other):
+        if PY38:
+            result = datetime(
+                self.year,
+                self.month,
+                self.day,
+                self.hour,
+                self.minute,
+                self.second,
+                self.microsecond,
+                self.tzinfo,
+            ).__add__(other)
+        else:
+            result = super().__add__(other)
+
+        return self._new(result)
+
+    def __sub__(self, other):
+        if PY38:
+            result = datetime(
+                self.year,
+                self.month,
+                self.day,
+                self.hour,
+                self.minute,
+                self.second,
+                self.microsecond,
+                self.tzinfo,
+            ).__sub__(other)
+        else:
+            result = super().__sub__(other)
+
+        if isinstance(result, datetime):
+            result = self._new(result)
+
+        return result
+
+    def replace(self, *args: Any, **kwargs: Any) -> datetime:
+        return self._new(super().replace(*args, **kwargs))
+
+    def astimezone(self, tz: tzinfo) -> datetime:
+        result = super().astimezone(tz)
+        if PY38:
+            return result
+        return self._new(result)
+
+    def _new(self, result) -> DateTime:
+        raw = result.isoformat()
+
+        return DateTime(
+            result.year,
+            result.month,
+            result.day,
+            result.hour,
+            result.minute,
+            result.second,
+            result.microsecond,
+            result.tzinfo,
+            self._trivia,
+            raw,
+        )
+
+    def _getstate(self, protocol=3):
+        return (
+            self.year,
+            self.month,
+            self.day,
+            self.hour,
+            self.minute,
+            self.second,
+            self.microsecond,
+            self.tzinfo,
+            self._trivia,
+            self._raw,
+        )
+
+
+class Date(Item, date):
+    """
+    A date literal.
+    """
+
+    def __new__(cls, year: int, month: int, day: int, *_: Any) -> date:
+        return date.__new__(cls, year, month, day)
+
+    def __init__(
+        self,
+        year: int,
+        month: int,
+        day: int,
+        trivia: Trivia | None = None,
+        raw: str = "",
+    ) -> None:
+        super().__init__(trivia or Trivia())
+
+        self._raw = raw
+
+    def unwrap(self) -> date:
+        (year, month, day, _, _) = self._getstate()
+        return date(year, month, day)
+
+    @property
+    def discriminant(self) -> int:
+        return 6
+
+    @property
+    def value(self) -> date:
+        return self
+
+    def as_string(self) -> str:
+        return self._raw
+
+    def __add__(self, other):
+        if PY38:
+            result = date(self.year, self.month, self.day).__add__(other)
+        else:
+            result = super().__add__(other)
+
+        return self._new(result)
+
+    def __sub__(self, other):
+        if PY38:
+            result = date(self.year, self.month, self.day).__sub__(other)
+        else:
+            result = super().__sub__(other)
+
+        if isinstance(result, date):
+            result = self._new(result)
+
+        return result
+
+    def replace(self, *args: Any, **kwargs: Any) -> date:
+        return self._new(super().replace(*args, **kwargs))
+
+    def _new(self, result):
+        raw = result.isoformat()
+
+        return Date(result.year, result.month, result.day, self._trivia, raw)
+
+    def _getstate(self, protocol=3):
+        return (self.year, self.month, self.day, self._trivia, self._raw)
+
+
+class Time(Item, time):
+    """
+    A time literal.
+    """
+
+    def __new__(
+        cls,
+        hour: int,
+        minute: int,
+        second: int,
+        microsecond: int,
+        tzinfo: tzinfo | None,
+        *_: Any,
+    ) -> time:
+        return time.__new__(cls, hour, minute, second, microsecond, tzinfo)
+
+    def __init__(
+        self,
+        hour: int,
+        minute: int,
+        second: int,
+        microsecond: int,
+        tzinfo: tzinfo | None,
+        trivia: Trivia | None = None,
+        raw: str = "",
+    ) -> None:
+        super().__init__(trivia or Trivia())
+
+        self._raw = raw
+
+    def unwrap(self) -> time:
+        (hour, minute, second, microsecond, tzinfo, _, _) = self._getstate()
+        return time(hour, minute, second, microsecond, tzinfo)
+
+    @property
+    def discriminant(self) -> int:
+        return 7
+
+    @property
+    def value(self) -> time:
+        return self
+
+    def as_string(self) -> str:
+        return self._raw
+
+    def replace(self, *args: Any, **kwargs: Any) -> time:
+        return self._new(super().replace(*args, **kwargs))
+
+    def _new(self, result):
+        raw = result.isoformat()
+
+        return Time(
+            result.hour,
+            result.minute,
+            result.second,
+            result.microsecond,
+            result.tzinfo,
+            self._trivia,
+            raw,
+        )
+
+    def _getstate(self, protocol: int = 3) -> tuple:
+        return (
+            self.hour,
+            self.minute,
+            self.second,
+            self.microsecond,
+            self.tzinfo,
+            self._trivia,
+            self._raw,
+        )
+
+
+class _ArrayItemGroup:
+    __slots__ = ("value", "indent", "comma", "comment")
+
+    def __init__(
+        self,
+        value: Item | None = None,
+        indent: Whitespace | None = None,
+        comma: Whitespace | None = None,
+        comment: Comment | None = None,
+    ) -> None:
+        self.value = value
+        self.indent = indent
+        self.comma = comma
+        self.comment = comment
+
+    def __iter__(self) -> Iterator[Item]:
+        return filter(
+            lambda x: x is not None, (self.indent, self.value, self.comma, self.comment)
+        )
+
+    def __repr__(self) -> str:
+        return repr(tuple(self))
+
+    def is_whitespace(self) -> bool:
+        return self.value is None and self.comment is None
+
+    def __bool__(self) -> bool:
+        try:
+            next(iter(self))
+        except StopIteration:
+            return False
+        return True
+
+
+class Array(Item, _CustomList):
+    """
+    An array literal
+    """
+
+    def __init__(
+        self, value: list[Item], trivia: Trivia, multiline: bool = False
+    ) -> None:
+        super().__init__(trivia)
+        list.__init__(
+            self,
+            [v for v in value if not isinstance(v, (Whitespace, Comment, Null))],
+        )
+        self._index_map: dict[int, int] = {}
+        self._value = self._group_values(value)
+        self._multiline = multiline
+        self._reindex()
+
+    def _group_values(self, value: list[Item]) -> list[_ArrayItemGroup]:
+        """Group the values into (indent, value, comma, comment) tuples"""
+        groups = []
+        this_group = _ArrayItemGroup()
+        for item in value:
+            if isinstance(item, Whitespace):
+                if "," not in item.s:
+                    groups.append(this_group)
+                    this_group = _ArrayItemGroup(indent=item)
+                else:
+                    if this_group.value is None:
+                        # when comma is met and no value is provided, add a dummy Null
+                        this_group.value = Null()
+                    this_group.comma = item
+            elif isinstance(item, Comment):
+                if this_group.value is None:
+                    this_group.value = Null()
+                this_group.comment = item
+            elif this_group.value is None:
+                this_group.value = item
+            else:
+                groups.append(this_group)
+                this_group = _ArrayItemGroup(value=item)
+        groups.append(this_group)
+        return [group for group in groups if group]
+
+    def unwrap(self) -> list[Any]:
+        unwrapped = []
+        for v in self:
+            if hasattr(v, "unwrap"):
+                unwrapped.append(v.unwrap())
+            else:
+                unwrapped.append(v)
+        return unwrapped
+
+    @property
+    def discriminant(self) -> int:
+        return 8
+
+    @property
+    def value(self) -> list:
+        return self
+
+    def _iter_items(self) -> Iterator[Item]:
+        for v in self._value:
+            yield from v
+
+    def multiline(self, multiline: bool) -> Array:
+        """Change the array to display in multiline or not.
+
+        :Example:
+
+        >>> a = item([1, 2, 3])
+        >>> print(a.as_string())
+        [1, 2, 3]
+        >>> print(a.multiline(True).as_string())
+        [
+            1,
+            2,
+            3,
+        ]
+        """
+        self._multiline = multiline
+
+        return self
+
+    def as_string(self) -> str:
+        if not self._multiline or not self._value:
+            return f'[{"".join(v.as_string() for v in self._iter_items())}]'
+
+        s = "[\n"
+        s += "".join(
+            self.trivia.indent
+            + " " * 4
+            + v.value.as_string()
+            + ("," if not isinstance(v.value, Null) else "")
+            + (v.comment.as_string() if v.comment is not None else "")
+            + "\n"
+            for v in self._value
+            if v.value is not None
+        )
+        s += self.trivia.indent + "]"
+
+        return s
+
+    def _reindex(self) -> None:
+        self._index_map.clear()
+        index = 0
+        for i, v in enumerate(self._value):
+            if v.value is None or isinstance(v.value, Null):
+                continue
+            self._index_map[index] = i
+            index += 1
+
+    def add_line(
+        self,
+        *items: Any,
+        indent: str = "    ",
+        comment: str | None = None,
+        add_comma: bool = True,
+        newline: bool = True,
+    ) -> None:
+        """Add multiple items in a line to control the format precisely.
+        When add_comma is True, only accept actual values and
+        ", " will be added between values automatically.
+
+        :Example:
+
+        >>> a = array()
+        >>> a.add_line(1, 2, 3)
+        >>> a.add_line(4, 5, 6)
+        >>> a.add_line(indent="")
+        >>> print(a.as_string())
+        [
+            1, 2, 3,
+            4, 5, 6,
+        ]
+        """
+        new_values: list[Item] = []
+        first_indent = f"\n{indent}" if newline else indent
+        if first_indent:
+            new_values.append(Whitespace(first_indent))
+        whitespace = ""
+        data_values = []
+        for i, el in enumerate(items):
+            it = item(el, _parent=self)
+            if isinstance(it, Comment) or add_comma and isinstance(el, Whitespace):
+                raise ValueError(f"item type {type(it)} is not allowed in add_line")
+            if not isinstance(it, Whitespace):
+                if whitespace:
+                    new_values.append(Whitespace(whitespace))
+                    whitespace = ""
+                new_values.append(it)
+                data_values.append(it.value)
+                if add_comma:
+                    new_values.append(Whitespace(","))
+                    if i != len(items) - 1:
+                        new_values.append(Whitespace(" "))
+            elif "," not in it.s:
+                whitespace += it.s
+            else:
+                new_values.append(it)
+        if whitespace:
+            new_values.append(Whitespace(whitespace))
+        if comment:
+            indent = " " if items else ""
+            new_values.append(
+                Comment(Trivia(indent=indent, comment=f"# {comment}", trail=""))
+            )
+        list.extend(self, data_values)
+        if len(self._value) > 0:
+            last_item = self._value[-1]
+            last_value_item = next(
+                (
+                    v
+                    for v in self._value[::-1]
+                    if v.value is not None and not isinstance(v.value, Null)
+                ),
+                None,
+            )
+            if last_value_item is not None:
+                last_value_item.comma = Whitespace(",")
+            if last_item.is_whitespace():
+                self._value[-1:-1] = self._group_values(new_values)
+            else:
+                self._value.extend(self._group_values(new_values))
+        else:
+            self._value.extend(self._group_values(new_values))
+        self._reindex()
+
+    def clear(self) -> None:
+        """Clear the array."""
+        list.clear(self)
+        self._index_map.clear()
+        self._value.clear()
+
+    def __len__(self) -> int:
+        return list.__len__(self)
+
+    def __getitem__(self, key: int | slice) -> Any:
+        rv = cast(Item, list.__getitem__(self, key))
+        if rv.is_boolean():
+            return bool(rv)
+        return rv
+
+    def __setitem__(self, key: int | slice, value: Any) -> Any:
+        it = item(value, _parent=self)
+        list.__setitem__(self, key, it)
+        if isinstance(key, slice):
+            raise ValueError("slice assignment is not supported")
+        if key < 0:
+            key += len(self)
+        self._value[self._index_map[key]].value = it
+
+    def insert(self, pos: int, value: Any) -> None:
+        it = item(value, _parent=self)
+        length = len(self)
+        if not isinstance(it, (Comment, Whitespace)):
+            list.insert(self, pos, it)
+        if pos < 0:
+            pos += length
+            if pos < 0:
+                pos = 0
+
+        idx = 0  # insert position of the self._value list
+        default_indent = " "
+        if pos < length:
+            try:
+                idx = self._index_map[pos]
+            except KeyError as e:
+                raise IndexError("list index out of range") from e
+        else:
+            idx = len(self._value)
+            if idx >= 1 and self._value[idx - 1].is_whitespace():
+                # The last item is a pure whitespace(\n ), insert before it
+                idx -= 1
+                if (
+                    self._value[idx].indent is not None
+                    and "\n" in self._value[idx].indent.s
+                ):
+                    default_indent = "\n    "
+        indent: Item | None = None
+        comma: Item | None = Whitespace(",") if pos < length else None
+        if idx < len(self._value) and not self._value[idx].is_whitespace():
+            # Prefer to copy the indentation from the item after
+            indent = self._value[idx].indent
+        if idx > 0:
+            last_item = self._value[idx - 1]
+            if indent is None:
+                indent = last_item.indent
+            if not isinstance(last_item.value, Null) and "\n" in default_indent:
+                # Copy the comma from the last item if 1) it contains a value and
+                # 2) the array is multiline
+                comma = last_item.comma
+            if last_item.comma is None and not isinstance(last_item.value, Null):
+                # Add comma to the last item to separate it from the following items.
+                last_item.comma = Whitespace(",")
+        if indent is None and (idx > 0 or "\n" in default_indent):
+            # apply default indent if it isn't the first item or the array is multiline.
+            indent = Whitespace(default_indent)
+        new_item = _ArrayItemGroup(value=it, indent=indent, comma=comma)
+        self._value.insert(idx, new_item)
+        self._reindex()
+
+    def __delitem__(self, key: int | slice):
+        length = len(self)
+        list.__delitem__(self, key)
+
+        if isinstance(key, slice):
+            indices_to_remove = list(
+                range(key.start or 0, key.stop or length, key.step or 1)
+            )
+        else:
+            indices_to_remove = [length + key if key < 0 else key]
+        for i in sorted(indices_to_remove, reverse=True):
+            try:
+                idx = self._index_map[i]
+            except KeyError as e:
+                if not isinstance(key, slice):
+                    raise IndexError("list index out of range") from e
+            else:
+                del self._value[idx]
+                if (
+                    idx == 0
+                    and len(self._value) > 0
+                    and self._value[idx].indent
+                    and "\n" not in self._value[idx].indent.s
+                ):
+                    # Remove the indentation of the first item if not newline
+                    self._value[idx].indent = None
+        if len(self._value) > 0:
+            v = self._value[-1]
+            if not v.is_whitespace():
+                # remove the comma of the last item
+                v.comma = None
+
+        self._reindex()
+
+    def _getstate(self, protocol=3):
+        return list(self._iter_items()), self._trivia, self._multiline
+
+
+class AbstractTable(Item, _CustomDict):
+    """Common behaviour of both :class:`Table` and :class:`InlineTable`"""
+
+    def __init__(self, value: container.Container, trivia: Trivia):
+        Item.__init__(self, trivia)
+
+        self._value = value
+
+        for k, v in self._value.body:
+            if k is not None:
+                dict.__setitem__(self, k.key, v)
+
+    def unwrap(self) -> dict[str, Any]:
+        unwrapped = {}
+        for k, v in self.items():
+            if isinstance(k, Key):
+                k = k.key
+            if hasattr(v, "unwrap"):
+                v = v.unwrap()
+            unwrapped[k] = v
+
+        return unwrapped
+
+    @property
+    def value(self) -> container.Container:
+        return self._value
+
+    @overload
+    def append(self: AT, key: None, value: Comment | Whitespace) -> AT: ...
+
+    @overload
+    def append(self: AT, key: Key | str, value: Any) -> AT: ...
+
+    def append(self, key, value):
+        raise NotImplementedError
+
+    @overload
+    def add(self: AT, key: Comment | Whitespace) -> AT: ...
+
+    @overload
+    def add(self: AT, key: Key | str, value: Any = ...) -> AT: ...
+
+    def add(self, key, value=None):
+        if value is None:
+            if not isinstance(key, (Comment, Whitespace)):
+                msg = "Non comment/whitespace items must have an associated key"
+                raise ValueError(msg)
+
+            key, value = None, key
+
+        return self.append(key, value)
+
+    def remove(self: AT, key: Key | str) -> AT:
+        self._value.remove(key)
+
+        if isinstance(key, Key):
+            key = key.key
+
+        if key is not None:
+            dict.__delitem__(self, key)
+
+        return self
+
+    def setdefault(self, key: Key | str, default: Any) -> Any:
+        super().setdefault(key, default)
+        return self[key]
+
+    def __str__(self):
+        return str(self.value)
+
+    def copy(self: AT) -> AT:
+        return copy.copy(self)
+
+    def __repr__(self) -> str:
+        return repr(self.value)
+
+    def __iter__(self) -> Iterator[str]:
+        return iter(self._value)
+
+    def __len__(self) -> int:
+        return len(self._value)
+
+    def __delitem__(self, key: Key | str) -> None:
+        self.remove(key)
+
+    def __getitem__(self, key: Key | str) -> Item:
+        return cast(Item, self._value[key])
+
+    def __setitem__(self, key: Key | str, value: Any) -> None:
+        if not isinstance(value, Item):
+            value = item(value, _parent=self)
+
+        is_replace = key in self
+        self._value[key] = value
+
+        if key is not None:
+            dict.__setitem__(self, key, value)
+
+        if is_replace:
+            return
+        m = re.match("(?s)^[^ ]*([ ]+).*$", self._trivia.indent)
+        if not m:
+            return
+
+        indent = m.group(1)
+
+        if not isinstance(value, Whitespace):
+            m = re.match("(?s)^([^ ]*)(.*)$", value.trivia.indent)
+            if not m:
+                value.trivia.indent = indent
+            else:
+                value.trivia.indent = m.group(1) + indent + m.group(2)
+
+
+class Table(AbstractTable):
+    """
+    A table literal.
+    """
+
+    def __init__(
+        self,
+        value: container.Container,
+        trivia: Trivia,
+        is_aot_element: bool,
+        is_super_table: bool | None = None,
+        name: str | None = None,
+        display_name: str | None = None,
+    ) -> None:
+        super().__init__(value, trivia)
+
+        self.name = name
+        self.display_name = display_name
+        self._is_aot_element = is_aot_element
+        self._is_super_table = is_super_table
+
+    @property
+    def discriminant(self) -> int:
+        return 9
+
+    def __copy__(self) -> Table:
+        return type(self)(
+            self._value.copy(),
+            self._trivia.copy(),
+            self._is_aot_element,
+            self._is_super_table,
+            self.name,
+            self.display_name,
+        )
+
+    def append(self, key: Key | str | None, _item: Any) -> Table:
+        """
+        Appends a (key, item) to the table.
+        """
+        if not isinstance(_item, Item):
+            _item = item(_item, _parent=self)
+
+        self._value.append(key, _item)
+
+        if isinstance(key, Key):
+            key = next(iter(key)).key
+            _item = self._value[key]
+
+        if key is not None:
+            dict.__setitem__(self, key, _item)
+
+        m = re.match(r"(?s)^[^ ]*([ ]+).*$", self._trivia.indent)
+        if not m:
+            return self
+
+        indent = m.group(1)
+
+        if not isinstance(_item, Whitespace):
+            m = re.match("(?s)^([^ ]*)(.*)$", _item.trivia.indent)
+            if not m:
+                _item.trivia.indent = indent
+            else:
+                _item.trivia.indent = m.group(1) + indent + m.group(2)
+
+        return self
+
+    def raw_append(self, key: Key | str | None, _item: Any) -> Table:
+        """Similar to :meth:`append` but does not copy indentation."""
+        if not isinstance(_item, Item):
+            _item = item(_item)
+
+        self._value.append(key, _item, validate=False)
+
+        if isinstance(key, Key):
+            key = next(iter(key)).key
+            _item = self._value[key]
+
+        if key is not None:
+            dict.__setitem__(self, key, _item)
+
+        return self
+
+    def is_aot_element(self) -> bool:
+        """True if the table is the direct child of an AOT element."""
+        return self._is_aot_element
+
+    def is_super_table(self) -> bool:
+        """A super table is the intermediate parent of a nested table as in [a.b.c].
+        If true, it won't appear in the TOML representation."""
+        if self._is_super_table is not None:
+            return self._is_super_table
+        if not self:
+            return False
+        # If the table has children and all children are tables, then it is a super table.
+        for k, child in self.items():
+            if not isinstance(k, Key):
+                k = SingleKey(k)
+            index = self.value._map[k]
+            if isinstance(index, tuple):
+                return False
+            real_key = self.value.body[index][0]
+            if (
+                not isinstance(child, (Table, AoT))
+                or real_key is None
+                or real_key.is_dotted()
+            ):
+                return False
+        return True
+
+    def as_string(self) -> str:
+        return self._value.as_string()
+
+    # Helpers
+
+    def indent(self, indent: int) -> Table:
+        """Indent the table with given number of spaces."""
+        super().indent(indent)
+
+        m = re.match("(?s)^[^ ]*([ ]+).*$", self._trivia.indent)
+        if not m:
+            indent_str = ""
+        else:
+            indent_str = m.group(1)
+
+        for _, item in self._value.body:
+            if not isinstance(item, Whitespace):
+                item.trivia.indent = indent_str + item.trivia.indent
+
+        return self
+
+    def invalidate_display_name(self):
+        """Call ``invalidate_display_name`` on the contained tables"""
+        self.display_name = None
+
+        for child in self.values():
+            if hasattr(child, "invalidate_display_name"):
+                child.invalidate_display_name()
+
+    def _getstate(self, protocol: int = 3) -> tuple:
+        return (
+            self._value,
+            self._trivia,
+            self._is_aot_element,
+            self._is_super_table,
+            self.name,
+            self.display_name,
+        )
+
+
+class InlineTable(AbstractTable):
+    """
+    An inline table literal.
+    """
+
+    def __init__(
+        self, value: container.Container, trivia: Trivia, new: bool = False
+    ) -> None:
+        super().__init__(value, trivia)
+
+        self._new = new
+
+    @property
+    def discriminant(self) -> int:
+        return 10
+
+    def append(self, key: Key | str | None, _item: Any) -> InlineTable:
+        """
+        Appends a (key, item) to the table.
+        """
+        if not isinstance(_item, Item):
+            _item = item(_item, _parent=self)
+
+        if not isinstance(_item, (Whitespace, Comment)):
+            if not _item.trivia.indent and len(self._value) > 0 and not self._new:
+                _item.trivia.indent = " "
+            if _item.trivia.comment:
+                _item.trivia.comment = ""
+
+        self._value.append(key, _item)
+
+        if isinstance(key, Key):
+            key = key.key
+
+        if key is not None:
+            dict.__setitem__(self, key, _item)
+
+        return self
+
+    def as_string(self) -> str:
+        buf = "{"
+        last_item_idx = next(
+            (
+                i
+                for i in range(len(self._value.body) - 1, -1, -1)
+                if self._value.body[i][0] is not None
+            ),
+            None,
+        )
+        for i, (k, v) in enumerate(self._value.body):
+            if k is None:
+                if i == len(self._value.body) - 1:
+                    if self._new:
+                        buf = buf.rstrip(", ")
+                    else:
+                        buf = buf.rstrip(",")
+
+                buf += v.as_string()
+
+                continue
+
+            v_trivia_trail = v.trivia.trail.replace("\n", "")
+            buf += (
+                f"{v.trivia.indent}"
+                f'{k.as_string() + ("." if k.is_dotted() else "")}'
+                f"{k.sep}"
+                f"{v.as_string()}"
+                f"{v.trivia.comment}"
+                f"{v_trivia_trail}"
+            )
+
+            if last_item_idx is not None and i < last_item_idx:
+                buf += ","
+                if self._new:
+                    buf += " "
+
+        buf += "}"
+
+        return buf
+
+    def __setitem__(self, key: Key | str, value: Any) -> None:
+        if hasattr(value, "trivia") and value.trivia.comment:
+            value.trivia.comment = ""
+        super().__setitem__(key, value)
+
+    def __copy__(self) -> InlineTable:
+        return type(self)(self._value.copy(), self._trivia.copy(), self._new)
+
+    def _getstate(self, protocol: int = 3) -> tuple:
+        return (self._value, self._trivia)
+
+
+class String(str, Item):
+    """
+    A string literal.
+    """
+
+    def __new__(cls, t, value, original, trivia):
+        return super().__new__(cls, value)
+
+    def __init__(self, t: StringType, _: str, original: str, trivia: Trivia) -> None:
+        super().__init__(trivia)
+
+        self._t = t
+        self._original = original
+
+    def unwrap(self) -> str:
+        return str(self)
+
+    @property
+    def discriminant(self) -> int:
+        return 11
+
+    @property
+    def value(self) -> str:
+        return self
+
+    def as_string(self) -> str:
+        return f"{self._t.value}{decode(self._original)}{self._t.value}"
+
+    def __add__(self: ItemT, other: str) -> ItemT:
+        if not isinstance(other, str):
+            return NotImplemented
+        result = super().__add__(other)
+        original = self._original + getattr(other, "_original", other)
+
+        return self._new(result, original)
+
+    def _new(self, result: str, original: str) -> String:
+        return String(self._t, result, original, self._trivia)
+
+    def _getstate(self, protocol=3):
+        return self._t, str(self), self._original, self._trivia
+
+    @classmethod
+    def from_raw(cls, value: str, type_=StringType.SLB, escape=True) -> String:
+        value = decode(value)
+
+        invalid = type_.invalid_sequences
+        if any(c in value for c in invalid):
+            raise InvalidStringError(value, invalid, type_.value)
+
+        escaped = type_.escaped_sequences
+        string_value = escape_string(value, escaped) if escape and escaped else value
+
+        return cls(type_, decode(value), string_value, Trivia())
+
+
+class AoT(Item, _CustomList):
+    """
+    An array of table literal
+    """
+
+    def __init__(
+        self, body: list[Table], name: str | None = None, parsed: bool = False
+    ) -> None:
+        self.name = name
+        self._body: list[Table] = []
+        self._parsed = parsed
+
+        super().__init__(Trivia(trail=""))
+
+        for table in body:
+            self.append(table)
+
+    def unwrap(self) -> list[dict[str, Any]]:
+        unwrapped = []
+        for t in self._body:
+            if hasattr(t, "unwrap"):
+                unwrapped.append(t.unwrap())
+            else:
+                unwrapped.append(t)
+        return unwrapped
+
+    @property
+    def body(self) -> list[Table]:
+        return self._body
+
+    @property
+    def discriminant(self) -> int:
+        return 12
+
+    @property
+    def value(self) -> list[dict[Any, Any]]:
+        return [v.value for v in self._body]
+
+    def __len__(self) -> int:
+        return len(self._body)
+
+    @overload
+    def __getitem__(self, key: slice) -> list[Table]: ...
+
+    @overload
+    def __getitem__(self, key: int) -> Table: ...
+
+    def __getitem__(self, key):
+        return self._body[key]
+
+    def __setitem__(self, key: slice | int, value: Any) -> None:
+        raise NotImplementedError
+
+    def __delitem__(self, key: slice | int) -> None:
+        del self._body[key]
+        list.__delitem__(self, key)
+
+    def insert(self, index: int, value: dict) -> None:
+        value = item(value, _parent=self)
+        if not isinstance(value, Table):
+            raise ValueError(f"Unsupported insert value type: {type(value)}")
+        length = len(self)
+        if index < 0:
+            index += length
+        if index < 0:
+            index = 0
+        elif index >= length:
+            index = length
+        m = re.match("(?s)^[^ ]*([ ]+).*$", self._trivia.indent)
+        if m:
+            indent = m.group(1)
+
+            m = re.match("(?s)^([^ ]*)(.*)$", value.trivia.indent)
+            if not m:
+                value.trivia.indent = indent
+            else:
+                value.trivia.indent = m.group(1) + indent + m.group(2)
+        prev_table = self._body[index - 1] if 0 < index and length else None
+        next_table = self._body[index + 1] if index < length - 1 else None
+        if not self._parsed:
+            if prev_table and "\n" not in value.trivia.indent:
+                value.trivia.indent = "\n" + value.trivia.indent
+            if next_table and "\n" not in next_table.trivia.indent:
+                next_table.trivia.indent = "\n" + next_table.trivia.indent
+        self._body.insert(index, value)
+        list.insert(self, index, value)
+
+    def invalidate_display_name(self):
+        """Call ``invalidate_display_name`` on the contained tables"""
+        for child in self:
+            if hasattr(child, "invalidate_display_name"):
+                child.invalidate_display_name()
+
+    def as_string(self) -> str:
+        b = ""
+        for table in self._body:
+            b += table.as_string()
+
+        return b
+
+    def __repr__(self) -> str:
+        return f"<AoT {self.value}>"
+
+    def _getstate(self, protocol=3):
+        return self._body, self.name, self._parsed
+
+
+class Null(Item):
+    """
+    A null item.
+    """
+
+    def __init__(self) -> None:
+        super().__init__(Trivia(trail=""))
+
+    def unwrap(self) -> None:
+        return None
+
+    @property
+    def discriminant(self) -> int:
+        return -1
+
+    @property
+    def value(self) -> None:
+        return None
+
+    def as_string(self) -> str:
+        return ""
+
+    def _getstate(self, protocol=3) -> tuple:
+        return ()
diff --git a/venv/lib/python3.9/site-packages/tomlkit/parser.py b/venv/lib/python3.9/site-packages/tomlkit/parser.py
new file mode 100644
index 000000000..b73f277a7
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit/parser.py
@@ -0,0 +1,1141 @@
+from __future__ import annotations
+
+import datetime
+import re
+import string
+
+from tomlkit._compat import decode
+from tomlkit._utils import RFC_3339_LOOSE
+from tomlkit._utils import _escaped
+from tomlkit._utils import parse_rfc3339
+from tomlkit.container import Container
+from tomlkit.exceptions import EmptyKeyError
+from tomlkit.exceptions import EmptyTableNameError
+from tomlkit.exceptions import InternalParserError
+from tomlkit.exceptions import InvalidCharInStringError
+from tomlkit.exceptions import InvalidControlChar
+from tomlkit.exceptions import InvalidDateError
+from tomlkit.exceptions import InvalidDateTimeError
+from tomlkit.exceptions import InvalidNumberError
+from tomlkit.exceptions import InvalidTimeError
+from tomlkit.exceptions import InvalidUnicodeValueError
+from tomlkit.exceptions import ParseError
+from tomlkit.exceptions import UnexpectedCharError
+from tomlkit.exceptions import UnexpectedEofError
+from tomlkit.items import AoT
+from tomlkit.items import Array
+from tomlkit.items import Bool
+from tomlkit.items import BoolType
+from tomlkit.items import Comment
+from tomlkit.items import Date
+from tomlkit.items import DateTime
+from tomlkit.items import Float
+from tomlkit.items import InlineTable
+from tomlkit.items import Integer
+from tomlkit.items import Item
+from tomlkit.items import Key
+from tomlkit.items import KeyType
+from tomlkit.items import Null
+from tomlkit.items import SingleKey
+from tomlkit.items import String
+from tomlkit.items import StringType
+from tomlkit.items import Table
+from tomlkit.items import Time
+from tomlkit.items import Trivia
+from tomlkit.items import Whitespace
+from tomlkit.source import Source
+from tomlkit.toml_char import TOMLChar
+from tomlkit.toml_document import TOMLDocument
+
+
+CTRL_I = 0x09  # Tab
+CTRL_J = 0x0A  # Line feed
+CTRL_M = 0x0D  # Carriage return
+CTRL_CHAR_LIMIT = 0x1F
+CHR_DEL = 0x7F
+
+
+class Parser:
+    """
+    Parser for TOML documents.
+    """
+
+    def __init__(self, string: str | bytes) -> None:
+        # Input to parse
+        self._src = Source(decode(string))
+
+        self._aot_stack: list[Key] = []
+
+    @property
+    def _state(self):
+        return self._src.state
+
+    @property
+    def _idx(self):
+        return self._src.idx
+
+    @property
+    def _current(self):
+        return self._src.current
+
+    @property
+    def _marker(self):
+        return self._src.marker
+
+    def extract(self) -> str:
+        """
+        Extracts the value between marker and index
+        """
+        return self._src.extract()
+
+    def inc(self, exception: type[ParseError] | None = None) -> bool:
+        """
+        Increments the parser if the end of the input has not been reached.
+        Returns whether or not it was able to advance.
+        """
+        return self._src.inc(exception=exception)
+
+    def inc_n(self, n: int, exception: type[ParseError] | None = None) -> bool:
+        """
+        Increments the parser by n characters
+        if the end of the input has not been reached.
+        """
+        return self._src.inc_n(n=n, exception=exception)
+
+    def consume(self, chars, min=0, max=-1):
+        """
+        Consume chars until min/max is satisfied is valid.
+        """
+        return self._src.consume(chars=chars, min=min, max=max)
+
+    def end(self) -> bool:
+        """
+        Returns True if the parser has reached the end of the input.
+        """
+        return self._src.end()
+
+    def mark(self) -> None:
+        """
+        Sets the marker to the index's current position
+        """
+        self._src.mark()
+
+    def parse_error(self, exception=ParseError, *args, **kwargs):
+        """
+        Creates a generic "parse error" at the current position.
+        """
+        return self._src.parse_error(exception, *args, **kwargs)
+
+    def parse(self) -> TOMLDocument:
+        body = TOMLDocument(True)
+
+        # Take all keyvals outside of tables/AoT's.
+        while not self.end():
+            # Break out if a table is found
+            if self._current == "[":
+                break
+
+            # Otherwise, take and append one KV
+            item = self._parse_item()
+            if not item:
+                break
+
+            key, value = item
+            if (key is not None and key.is_multi()) or not self._merge_ws(value, body):
+                # We actually have a table
+                try:
+                    body.append(key, value)
+                except Exception as e:
+                    raise self.parse_error(ParseError, str(e)) from e
+
+            self.mark()
+
+        while not self.end():
+            key, value = self._parse_table()
+            if isinstance(value, Table) and value.is_aot_element():
+                # This is just the first table in an AoT. Parse the rest of the array
+                # along with it.
+                value = self._parse_aot(value, key)
+
+            try:
+                body.append(key, value)
+            except Exception as e:
+                raise self.parse_error(ParseError, str(e)) from e
+
+        body.parsing(False)
+
+        return body
+
+    def _merge_ws(self, item: Item, container: Container) -> bool:
+        """
+        Merges the given Item with the last one currently in the given Container if
+        both are whitespace items.
+
+        Returns True if the items were merged.
+        """
+        last = container.last_item()
+        if not last:
+            return False
+
+        if not isinstance(item, Whitespace) or not isinstance(last, Whitespace):
+            return False
+
+        start = self._idx - (len(last.s) + len(item.s))
+        container.body[-1] = (
+            container.body[-1][0],
+            Whitespace(self._src[start : self._idx]),
+        )
+
+        return True
+
+    def _is_child(self, parent: Key, child: Key) -> bool:
+        """
+        Returns whether a key is strictly a child of another key.
+        AoT siblings are not considered children of one another.
+        """
+        parent_parts = tuple(parent)
+        child_parts = tuple(child)
+
+        if parent_parts == child_parts:
+            return False
+
+        return parent_parts == child_parts[: len(parent_parts)]
+
+    def _parse_item(self) -> tuple[Key | None, Item] | None:
+        """
+        Attempts to parse the next item and returns it, along with its key
+        if the item is value-like.
+        """
+        self.mark()
+        with self._state as state:
+            while True:
+                c = self._current
+                if c == "\n":
+                    # Found a newline; Return all whitespace found up to this point.
+                    self.inc()
+
+                    return None, Whitespace(self.extract())
+                elif c in " \t\r":
+                    # Skip whitespace.
+                    if not self.inc():
+                        return None, Whitespace(self.extract())
+                elif c == "#":
+                    # Found a comment, parse it
+                    indent = self.extract()
+                    cws, comment, trail = self._parse_comment_trail()
+
+                    return None, Comment(Trivia(indent, cws, comment, trail))
+                elif c == "[":
+                    # Found a table, delegate to the calling function.
+                    return
+                else:
+                    # Beginning of a KV pair.
+                    # Return to beginning of whitespace so it gets included
+                    # as indentation for the KV about to be parsed.
+                    state.restore = True
+                    break
+
+        return self._parse_key_value(True)
+
+    def _parse_comment_trail(self, parse_trail: bool = True) -> tuple[str, str, str]:
+        """
+        Returns (comment_ws, comment, trail)
+        If there is no comment, comment_ws and comment will
+        simply be empty.
+        """
+        if self.end():
+            return "", "", ""
+
+        comment = ""
+        comment_ws = ""
+        self.mark()
+
+        while True:
+            c = self._current
+
+            if c == "\n":
+                break
+            elif c == "#":
+                comment_ws = self.extract()
+
+                self.mark()
+                self.inc()  # Skip #
+
+                # The comment itself
+                while not self.end() and not self._current.is_nl():
+                    code = ord(self._current)
+                    if code == CHR_DEL or code <= CTRL_CHAR_LIMIT and code != CTRL_I:
+                        raise self.parse_error(InvalidControlChar, code, "comments")
+
+                    if not self.inc():
+                        break
+
+                comment = self.extract()
+                self.mark()
+
+                break
+            elif c in " \t\r":
+                self.inc()
+            else:
+                raise self.parse_error(UnexpectedCharError, c)
+
+            if self.end():
+                break
+
+        trail = ""
+        if parse_trail:
+            while self._current.is_spaces() and self.inc():
+                pass
+
+            if self._current == "\r":
+                self.inc()
+
+            if self._current == "\n":
+                self.inc()
+
+            if self._idx != self._marker or self._current.is_ws():
+                trail = self.extract()
+
+        return comment_ws, comment, trail
+
+    def _parse_key_value(self, parse_comment: bool = False) -> tuple[Key, Item]:
+        # Leading indent
+        self.mark()
+
+        while self._current.is_spaces() and self.inc():
+            pass
+
+        indent = self.extract()
+
+        # Key
+        key = self._parse_key()
+
+        self.mark()
+
+        found_equals = self._current == "="
+        while self._current.is_kv_sep() and self.inc():
+            if self._current == "=":
+                if found_equals:
+                    raise self.parse_error(UnexpectedCharError, "=")
+                else:
+                    found_equals = True
+        if not found_equals:
+            raise self.parse_error(UnexpectedCharError, self._current)
+
+        if not key.sep:
+            key.sep = self.extract()
+        else:
+            key.sep += self.extract()
+
+        # Value
+        val = self._parse_value()
+        # Comment
+        if parse_comment:
+            cws, comment, trail = self._parse_comment_trail()
+            meta = val.trivia
+            if not meta.comment_ws:
+                meta.comment_ws = cws
+
+            meta.comment = comment
+            meta.trail = trail
+        else:
+            val.trivia.trail = ""
+
+        val.trivia.indent = indent
+
+        return key, val
+
+    def _parse_key(self) -> Key:
+        """
+        Parses a Key at the current position;
+        WS before the key must be exhausted first at the callsite.
+        """
+        self.mark()
+        while self._current.is_spaces() and self.inc():
+            # Skip any leading whitespace
+            pass
+        if self._current in "\"'":
+            return self._parse_quoted_key()
+        else:
+            return self._parse_bare_key()
+
+    def _parse_quoted_key(self) -> Key:
+        """
+        Parses a key enclosed in either single or double quotes.
+        """
+        # Extract the leading whitespace
+        original = self.extract()
+        quote_style = self._current
+        key_type = next((t for t in KeyType if t.value == quote_style), None)
+
+        if key_type is None:
+            raise RuntimeError("Should not have entered _parse_quoted_key()")
+
+        key_str = self._parse_string(
+            StringType.SLB if key_type == KeyType.Basic else StringType.SLL
+        )
+        if key_str._t.is_multiline():
+            raise self.parse_error(UnexpectedCharError, key_str._t.value)
+        original += key_str.as_string()
+        self.mark()
+        while self._current.is_spaces() and self.inc():
+            pass
+        original += self.extract()
+        key = SingleKey(str(key_str), t=key_type, sep="", original=original)
+        if self._current == ".":
+            self.inc()
+            key = key.concat(self._parse_key())
+
+        return key
+
+    def _parse_bare_key(self) -> Key:
+        """
+        Parses a bare key.
+        """
+        while (
+            self._current.is_bare_key_char() or self._current.is_spaces()
+        ) and self.inc():
+            pass
+
+        original = self.extract()
+        key = original.strip()
+        if not key:
+            # Empty key
+            raise self.parse_error(EmptyKeyError)
+
+        if " " in key:
+            # Bare key with spaces in it
+            raise self.parse_error(ParseError, f'Invalid key "{key}"')
+
+        key = SingleKey(key, KeyType.Bare, "", original)
+
+        if self._current == ".":
+            self.inc()
+            key = key.concat(self._parse_key())
+
+        return key
+
+    def _parse_value(self) -> Item:
+        """
+        Attempts to parse a value at the current position.
+        """
+        self.mark()
+        c = self._current
+        trivia = Trivia()
+
+        if c == StringType.SLB.value:
+            return self._parse_basic_string()
+        elif c == StringType.SLL.value:
+            return self._parse_literal_string()
+        elif c == BoolType.TRUE.value[0]:
+            return self._parse_true()
+        elif c == BoolType.FALSE.value[0]:
+            return self._parse_false()
+        elif c == "[":
+            return self._parse_array()
+        elif c == "{":
+            return self._parse_inline_table()
+        elif c in "+-" or self._peek(4) in {
+            "+inf",
+            "-inf",
+            "inf",
+            "+nan",
+            "-nan",
+            "nan",
+        }:
+            # Number
+            while self._current not in " \t\n\r#,]}" and self.inc():
+                pass
+
+            raw = self.extract()
+
+            item = self._parse_number(raw, trivia)
+            if item is not None:
+                return item
+
+            raise self.parse_error(InvalidNumberError)
+        elif c in string.digits:
+            # Integer, Float, Date, Time or DateTime
+            while self._current not in " \t\n\r#,]}" and self.inc():
+                pass
+
+            raw = self.extract()
+
+            m = RFC_3339_LOOSE.match(raw)
+            if m:
+                if m.group(1) and m.group(5):
+                    # datetime
+                    try:
+                        dt = parse_rfc3339(raw)
+                        assert isinstance(dt, datetime.datetime)
+                        return DateTime(
+                            dt.year,
+                            dt.month,
+                            dt.day,
+                            dt.hour,
+                            dt.minute,
+                            dt.second,
+                            dt.microsecond,
+                            dt.tzinfo,
+                            trivia,
+                            raw,
+                        )
+                    except ValueError:
+                        raise self.parse_error(InvalidDateTimeError) from None
+
+                if m.group(1):
+                    try:
+                        dt = parse_rfc3339(raw)
+                        assert isinstance(dt, datetime.date)
+                        date = Date(dt.year, dt.month, dt.day, trivia, raw)
+                        self.mark()
+                        while self._current not in "\t\n\r#,]}" and self.inc():
+                            pass
+
+                        time_raw = self.extract()
+                        time_part = time_raw.rstrip()
+                        trivia.comment_ws = time_raw[len(time_part) :]
+                        if not time_part:
+                            return date
+
+                        dt = parse_rfc3339(raw + time_part)
+                        assert isinstance(dt, datetime.datetime)
+                        return DateTime(
+                            dt.year,
+                            dt.month,
+                            dt.day,
+                            dt.hour,
+                            dt.minute,
+                            dt.second,
+                            dt.microsecond,
+                            dt.tzinfo,
+                            trivia,
+                            raw + time_part,
+                        )
+                    except ValueError:
+                        raise self.parse_error(InvalidDateError) from None
+
+                if m.group(5):
+                    try:
+                        t = parse_rfc3339(raw)
+                        assert isinstance(t, datetime.time)
+                        return Time(
+                            t.hour,
+                            t.minute,
+                            t.second,
+                            t.microsecond,
+                            t.tzinfo,
+                            trivia,
+                            raw,
+                        )
+                    except ValueError:
+                        raise self.parse_error(InvalidTimeError) from None
+
+            item = self._parse_number(raw, trivia)
+            if item is not None:
+                return item
+
+            raise self.parse_error(InvalidNumberError)
+        else:
+            raise self.parse_error(UnexpectedCharError, c)
+
+    def _parse_true(self):
+        return self._parse_bool(BoolType.TRUE)
+
+    def _parse_false(self):
+        return self._parse_bool(BoolType.FALSE)
+
+    def _parse_bool(self, style: BoolType) -> Bool:
+        with self._state:
+            style = BoolType(style)
+
+            # only keep parsing for bool if the characters match the style
+            # try consuming rest of chars in style
+            for c in style:
+                self.consume(c, min=1, max=1)
+
+            return Bool(style, Trivia())
+
+    def _parse_array(self) -> Array:
+        # Consume opening bracket, EOF here is an issue (middle of array)
+        self.inc(exception=UnexpectedEofError)
+
+        elems: list[Item] = []
+        prev_value = None
+        while True:
+            # consume whitespace
+            mark = self._idx
+            self.consume(TOMLChar.SPACES + TOMLChar.NL)
+            indent = self._src[mark : self._idx]
+            newline = set(TOMLChar.NL) & set(indent)
+            if newline:
+                elems.append(Whitespace(indent))
+                continue
+
+            # consume comment
+            if self._current == "#":
+                cws, comment, trail = self._parse_comment_trail(parse_trail=False)
+                elems.append(Comment(Trivia(indent, cws, comment, trail)))
+                continue
+
+            # consume indent
+            if indent:
+                elems.append(Whitespace(indent))
+                continue
+
+            # consume value
+            if not prev_value:
+                try:
+                    elems.append(self._parse_value())
+                    prev_value = True
+                    continue
+                except UnexpectedCharError:
+                    pass
+
+            # consume comma
+            if prev_value and self._current == ",":
+                self.inc(exception=UnexpectedEofError)
+                elems.append(Whitespace(","))
+                prev_value = False
+                continue
+
+            # consume closing bracket
+            if self._current == "]":
+                # consume closing bracket, EOF here doesn't matter
+                self.inc()
+                break
+
+            raise self.parse_error(UnexpectedCharError, self._current)
+
+        try:
+            res = Array(elems, Trivia())
+        except ValueError:
+            pass
+        else:
+            return res
+
+    def _parse_inline_table(self) -> InlineTable:
+        # consume opening bracket, EOF here is an issue (middle of array)
+        self.inc(exception=UnexpectedEofError)
+
+        elems = Container(True)
+        trailing_comma = None
+        while True:
+            # consume leading whitespace
+            mark = self._idx
+            self.consume(TOMLChar.SPACES)
+            raw = self._src[mark : self._idx]
+            if raw:
+                elems.add(Whitespace(raw))
+
+            if not trailing_comma:
+                # None: empty inline table
+                # False: previous key-value pair was not followed by a comma
+                if self._current == "}":
+                    # consume closing bracket, EOF here doesn't matter
+                    self.inc()
+                    break
+
+                if (
+                    trailing_comma is False
+                    or trailing_comma is None
+                    and self._current == ","
+                ):
+                    # Either the previous key-value pair was not followed by a comma
+                    # or the table has an unexpected leading comma.
+                    raise self.parse_error(UnexpectedCharError, self._current)
+            else:
+                # True: previous key-value pair was followed by a comma
+                if self._current == "}" or self._current == ",":
+                    raise self.parse_error(UnexpectedCharError, self._current)
+
+            key, val = self._parse_key_value(False)
+            elems.add(key, val)
+
+            # consume trailing whitespace
+            mark = self._idx
+            self.consume(TOMLChar.SPACES)
+            raw = self._src[mark : self._idx]
+            if raw:
+                elems.add(Whitespace(raw))
+
+            # consume trailing comma
+            trailing_comma = self._current == ","
+            if trailing_comma:
+                # consume closing bracket, EOF here is an issue (middle of inline table)
+                self.inc(exception=UnexpectedEofError)
+
+        return InlineTable(elems, Trivia())
+
+    def _parse_number(self, raw: str, trivia: Trivia) -> Item | None:
+        # Leading zeros are not allowed
+        sign = ""
+        if raw.startswith(("+", "-")):
+            sign = raw[0]
+            raw = raw[1:]
+
+        if len(raw) > 1 and (
+            raw.startswith("0")
+            and not raw.startswith(("0.", "0o", "0x", "0b", "0e"))
+            or sign
+            and raw.startswith(".")
+        ):
+            return None
+
+        if raw.startswith(("0o", "0x", "0b")) and sign:
+            return None
+
+        digits = "[0-9]"
+        base = 10
+        if raw.startswith("0b"):
+            digits = "[01]"
+            base = 2
+        elif raw.startswith("0o"):
+            digits = "[0-7]"
+            base = 8
+        elif raw.startswith("0x"):
+            digits = "[0-9a-f]"
+            base = 16
+
+        # Underscores should be surrounded by digits
+        clean = re.sub(f"(?i)(?<={digits})_(?={digits})", "", raw).lower()
+
+        if "_" in clean:
+            return None
+
+        if (
+            clean.endswith(".")
+            or not clean.startswith("0x")
+            and clean.split("e", 1)[0].endswith(".")
+        ):
+            return None
+
+        try:
+            return Integer(int(sign + clean, base), trivia, sign + raw)
+        except ValueError:
+            try:
+                return Float(float(sign + clean), trivia, sign + raw)
+            except ValueError:
+                return None
+
+    def _parse_literal_string(self) -> String:
+        with self._state:
+            return self._parse_string(StringType.SLL)
+
+    def _parse_basic_string(self) -> String:
+        with self._state:
+            return self._parse_string(StringType.SLB)
+
+    def _parse_escaped_char(self, multiline):
+        if multiline and self._current.is_ws():
+            # When the last non-whitespace character on a line is
+            # a \, it will be trimmed along with all whitespace
+            # (including newlines) up to the next non-whitespace
+            # character or closing delimiter.
+            # """\
+            #     hello \
+            #     world"""
+            tmp = ""
+            while self._current.is_ws():
+                tmp += self._current
+                # consume the whitespace, EOF here is an issue
+                # (middle of string)
+                self.inc(exception=UnexpectedEofError)
+                continue
+
+            # the escape followed by whitespace must have a newline
+            # before any other chars
+            if "\n" not in tmp:
+                raise self.parse_error(InvalidCharInStringError, self._current)
+
+            return ""
+
+        if self._current in _escaped:
+            c = _escaped[self._current]
+
+            # consume this char, EOF here is an issue (middle of string)
+            self.inc(exception=UnexpectedEofError)
+
+            return c
+
+        if self._current in {"u", "U"}:
+            # this needs to be a unicode
+            u, ue = self._peek_unicode(self._current == "U")
+            if u is not None:
+                # consume the U char and the unicode value
+                self.inc_n(len(ue) + 1)
+
+                return u
+
+            raise self.parse_error(InvalidUnicodeValueError)
+
+        raise self.parse_error(InvalidCharInStringError, self._current)
+
+    def _parse_string(self, delim: StringType) -> String:
+        # only keep parsing for string if the current character matches the delim
+        if self._current != delim.unit:
+            raise self.parse_error(
+                InternalParserError,
+                f"Invalid character for string type {delim}",
+            )
+
+        # consume the opening/first delim, EOF here is an issue
+        # (middle of string or middle of delim)
+        self.inc(exception=UnexpectedEofError)
+
+        if self._current == delim.unit:
+            # consume the closing/second delim, we do not care if EOF occurs as
+            # that would simply imply an empty single line string
+            if not self.inc() or self._current != delim.unit:
+                # Empty string
+                return String(delim, "", "", Trivia())
+
+            # consume the third delim, EOF here is an issue (middle of string)
+            self.inc(exception=UnexpectedEofError)
+
+            delim = delim.toggle()  # convert delim to multi delim
+
+        self.mark()  # to extract the original string with whitespace and all
+        value = ""
+
+        # A newline immediately following the opening delimiter will be trimmed.
+        if delim.is_multiline():
+            if self._current == "\n":
+                # consume the newline, EOF here is an issue (middle of string)
+                self.inc(exception=UnexpectedEofError)
+            else:
+                cur = self._current
+                with self._state(restore=True):
+                    if self.inc():
+                        cur += self._current
+                if cur == "\r\n":
+                    self.inc_n(2, exception=UnexpectedEofError)
+
+        escaped = False  # whether the previous key was ESCAPE
+        while True:
+            code = ord(self._current)
+            if (
+                delim.is_singleline()
+                and not escaped
+                and (code == CHR_DEL or code <= CTRL_CHAR_LIMIT and code != CTRL_I)
+            ) or (
+                delim.is_multiline()
+                and not escaped
+                and (
+                    code == CHR_DEL
+                    or code <= CTRL_CHAR_LIMIT
+                    and code not in [CTRL_I, CTRL_J, CTRL_M]
+                )
+            ):
+                raise self.parse_error(InvalidControlChar, code, "strings")
+            elif not escaped and self._current == delim.unit:
+                # try to process current as a closing delim
+                original = self.extract()
+
+                close = ""
+                if delim.is_multiline():
+                    # Consume the delimiters to see if we are at the end of the string
+                    close = ""
+                    while self._current == delim.unit:
+                        close += self._current
+                        self.inc()
+
+                    if len(close) < 3:
+                        # Not a triple quote, leave in result as-is.
+                        # Adding back the characters we already consumed
+                        value += close
+                        continue
+
+                    if len(close) == 3:
+                        # We are at the end of the string
+                        return String(delim, value, original, Trivia())
+
+                    if len(close) >= 6:
+                        raise self.parse_error(InvalidCharInStringError, self._current)
+
+                    value += close[:-3]
+                    original += close[:-3]
+
+                    return String(delim, value, original, Trivia())
+                else:
+                    # consume the closing delim, we do not care if EOF occurs as
+                    # that would simply imply the end of self._src
+                    self.inc()
+
+                return String(delim, value, original, Trivia())
+            elif delim.is_basic() and escaped:
+                # attempt to parse the current char as an escaped value, an exception
+                # is raised if this fails
+                value += self._parse_escaped_char(delim.is_multiline())
+
+                # no longer escaped
+                escaped = False
+            elif delim.is_basic() and self._current == "\\":
+                # the next char is being escaped
+                escaped = True
+
+                # consume this char, EOF here is an issue (middle of string)
+                self.inc(exception=UnexpectedEofError)
+            else:
+                # this is either a literal string where we keep everything as is,
+                # or this is not a special escaped char in a basic string
+                value += self._current
+
+                # consume this char, EOF here is an issue (middle of string)
+                self.inc(exception=UnexpectedEofError)
+
+    def _parse_table(
+        self, parent_name: Key | None = None, parent: Table | None = None
+    ) -> tuple[Key, Table | AoT]:
+        """
+        Parses a table element.
+        """
+        if self._current != "[":
+            raise self.parse_error(
+                InternalParserError, "_parse_table() called on non-bracket character."
+            )
+
+        indent = self.extract()
+        self.inc()  # Skip opening bracket
+
+        if self.end():
+            raise self.parse_error(UnexpectedEofError)
+
+        is_aot = False
+        if self._current == "[":
+            if not self.inc():
+                raise self.parse_error(UnexpectedEofError)
+
+            is_aot = True
+        try:
+            key = self._parse_key()
+        except EmptyKeyError:
+            raise self.parse_error(EmptyTableNameError) from None
+        if self.end():
+            raise self.parse_error(UnexpectedEofError)
+        elif self._current != "]":
+            raise self.parse_error(UnexpectedCharError, self._current)
+
+        key.sep = ""
+        full_key = key
+        name_parts = tuple(key)
+        if any(" " in part.key.strip() and part.is_bare() for part in name_parts):
+            raise self.parse_error(
+                ParseError, f'Invalid table name "{full_key.as_string()}"'
+            )
+
+        missing_table = False
+        if parent_name:
+            parent_name_parts = tuple(parent_name)
+        else:
+            parent_name_parts = ()
+
+        if len(name_parts) > len(parent_name_parts) + 1:
+            missing_table = True
+
+        name_parts = name_parts[len(parent_name_parts) :]
+
+        values = Container(True)
+
+        self.inc()  # Skip closing bracket
+        if is_aot:
+            # TODO: Verify close bracket
+            self.inc()
+
+        cws, comment, trail = self._parse_comment_trail()
+
+        result = Null()
+        table = Table(
+            values,
+            Trivia(indent, cws, comment, trail),
+            is_aot,
+            name=name_parts[0].key if name_parts else key.key,
+            display_name=full_key.as_string(),
+            is_super_table=False,
+        )
+
+        if len(name_parts) > 1:
+            if missing_table:
+                # Missing super table
+                # i.e. a table initialized like this: [foo.bar]
+                # without initializing [foo]
+                #
+                # So we have to create the parent tables
+                table = Table(
+                    Container(True),
+                    Trivia("", cws, comment, trail),
+                    is_aot and name_parts[0] in self._aot_stack,
+                    is_super_table=True,
+                    name=name_parts[0].key,
+                )
+
+            result = table
+            key = name_parts[0]
+
+            for i, _name in enumerate(name_parts[1:]):
+                child = table.get(
+                    _name,
+                    Table(
+                        Container(True),
+                        Trivia(indent, cws, comment, trail),
+                        is_aot and i == len(name_parts) - 2,
+                        is_super_table=i < len(name_parts) - 2,
+                        name=_name.key,
+                        display_name=(
+                            full_key.as_string() if i == len(name_parts) - 2 else None
+                        ),
+                    ),
+                )
+
+                if is_aot and i == len(name_parts) - 2:
+                    table.raw_append(_name, AoT([child], name=table.name, parsed=True))
+                else:
+                    table.raw_append(_name, child)
+
+                table = child
+                values = table.value
+        else:
+            if name_parts:
+                key = name_parts[0]
+
+        while not self.end():
+            item = self._parse_item()
+            if item:
+                _key, item = item
+                if not self._merge_ws(item, values):
+                    table.raw_append(_key, item)
+            else:
+                if self._current == "[":
+                    _, key_next = self._peek_table()
+
+                    if self._is_child(full_key, key_next):
+                        key_next, table_next = self._parse_table(full_key, table)
+
+                        table.raw_append(key_next, table_next)
+
+                        # Picking up any sibling
+                        while not self.end():
+                            _, key_next = self._peek_table()
+
+                            if not self._is_child(full_key, key_next):
+                                break
+
+                            key_next, table_next = self._parse_table(full_key, table)
+
+                            table.raw_append(key_next, table_next)
+
+                    break
+                else:
+                    raise self.parse_error(
+                        InternalParserError,
+                        "_parse_item() returned None on a non-bracket character.",
+                    )
+        table.value._validate_out_of_order_table()
+        if isinstance(result, Null):
+            result = table
+
+            if is_aot and (not self._aot_stack or full_key != self._aot_stack[-1]):
+                result = self._parse_aot(result, full_key)
+
+        return key, result
+
+    def _peek_table(self) -> tuple[bool, Key]:
+        """
+        Peeks ahead non-intrusively by cloning then restoring the
+        initial state of the parser.
+
+        Returns the name of the table about to be parsed,
+        as well as whether it is part of an AoT.
+        """
+        # we always want to restore after exiting this scope
+        with self._state(save_marker=True, restore=True):
+            if self._current != "[":
+                raise self.parse_error(
+                    InternalParserError,
+                    "_peek_table() entered on non-bracket character",
+                )
+
+            # AoT
+            self.inc()
+            is_aot = False
+            if self._current == "[":
+                self.inc()
+                is_aot = True
+            try:
+                return is_aot, self._parse_key()
+            except EmptyKeyError:
+                raise self.parse_error(EmptyTableNameError) from None
+
+    def _parse_aot(self, first: Table, name_first: Key) -> AoT:
+        """
+        Parses all siblings of the provided table first and bundles them into
+        an AoT.
+        """
+        payload = [first]
+        self._aot_stack.append(name_first)
+        while not self.end():
+            is_aot_next, name_next = self._peek_table()
+            if is_aot_next and name_next == name_first:
+                _, table = self._parse_table(name_first)
+                payload.append(table)
+            else:
+                break
+
+        self._aot_stack.pop()
+
+        return AoT(payload, parsed=True)
+
+    def _peek(self, n: int) -> str:
+        """
+        Peeks ahead n characters.
+
+        n is the max number of characters that will be peeked.
+        """
+        # we always want to restore after exiting this scope
+        with self._state(restore=True):
+            buf = ""
+            for _ in range(n):
+                if self._current not in " \t\n\r#,]}" + self._src.EOF:
+                    buf += self._current
+                    self.inc()
+                    continue
+
+                break
+            return buf
+
+    def _peek_unicode(self, is_long: bool) -> tuple[str | None, str | None]:
+        """
+        Peeks ahead non-intrusively by cloning then restoring the
+        initial state of the parser.
+
+        Returns the unicode value is it's a valid one else None.
+        """
+        # we always want to restore after exiting this scope
+        with self._state(save_marker=True, restore=True):
+            if self._current not in {"u", "U"}:
+                raise self.parse_error(
+                    InternalParserError, "_peek_unicode() entered on non-unicode value"
+                )
+
+            self.inc()  # Dropping prefix
+            self.mark()
+
+            if is_long:
+                chars = 8
+            else:
+                chars = 4
+
+            if not self.inc_n(chars):
+                value, extracted = None, None
+            else:
+                extracted = self.extract()
+
+                if extracted[0].lower() == "d" and extracted[1].strip("01234567"):
+                    return None, None
+
+                try:
+                    value = chr(int(extracted, 16))
+                except (ValueError, OverflowError):
+                    value = None
+
+            return value, extracted
diff --git a/venv/lib/python3.9/site-packages/tomlkit/py.typed b/venv/lib/python3.9/site-packages/tomlkit/py.typed
new file mode 100644
index 000000000..e69de29bb
diff --git a/venv/lib/python3.9/site-packages/tomlkit/source.py b/venv/lib/python3.9/site-packages/tomlkit/source.py
new file mode 100644
index 000000000..8a8b2c3d9
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit/source.py
@@ -0,0 +1,180 @@
+from __future__ import annotations
+
+from copy import copy
+from typing import Any
+
+from tomlkit.exceptions import ParseError
+from tomlkit.exceptions import UnexpectedCharError
+from tomlkit.toml_char import TOMLChar
+
+
+class _State:
+    def __init__(
+        self,
+        source: Source,
+        save_marker: bool | None = False,
+        restore: bool | None = False,
+    ) -> None:
+        self._source = source
+        self._save_marker = save_marker
+        self.restore = restore
+
+    def __enter__(self) -> _State:
+        # Entering this context manager - save the state
+        self._chars = copy(self._source._chars)
+        self._idx = self._source._idx
+        self._current = self._source._current
+        self._marker = self._source._marker
+
+        return self
+
+    def __exit__(self, exception_type, exception_val, trace):
+        # Exiting this context manager - restore the prior state
+        if self.restore or exception_type:
+            self._source._chars = self._chars
+            self._source._idx = self._idx
+            self._source._current = self._current
+            if self._save_marker:
+                self._source._marker = self._marker
+
+
+class _StateHandler:
+    """
+    State preserver for the Parser.
+    """
+
+    def __init__(self, source: Source) -> None:
+        self._source = source
+        self._states = []
+
+    def __call__(self, *args, **kwargs):
+        return _State(self._source, *args, **kwargs)
+
+    def __enter__(self) -> _State:
+        state = self()
+        self._states.append(state)
+        return state.__enter__()
+
+    def __exit__(self, exception_type, exception_val, trace):
+        state = self._states.pop()
+        return state.__exit__(exception_type, exception_val, trace)
+
+
+class Source(str):
+    EOF = TOMLChar("\0")
+
+    def __init__(self, _: str) -> None:
+        super().__init__()
+
+        # Collection of TOMLChars
+        self._chars = iter([(i, TOMLChar(c)) for i, c in enumerate(self)])
+
+        self._idx = 0
+        self._marker = 0
+        self._current = TOMLChar("")
+
+        self._state = _StateHandler(self)
+
+        self.inc()
+
+    def reset(self):
+        # initialize both idx and current
+        self.inc()
+
+        # reset marker
+        self.mark()
+
+    @property
+    def state(self) -> _StateHandler:
+        return self._state
+
+    @property
+    def idx(self) -> int:
+        return self._idx
+
+    @property
+    def current(self) -> TOMLChar:
+        return self._current
+
+    @property
+    def marker(self) -> int:
+        return self._marker
+
+    def extract(self) -> str:
+        """
+        Extracts the value between marker and index
+        """
+        return self[self._marker : self._idx]
+
+    def inc(self, exception: type[ParseError] | None = None) -> bool:
+        """
+        Increments the parser if the end of the input has not been reached.
+        Returns whether or not it was able to advance.
+        """
+        try:
+            self._idx, self._current = next(self._chars)
+
+            return True
+        except StopIteration:
+            self._idx = len(self)
+            self._current = self.EOF
+            if exception:
+                raise self.parse_error(exception) from None
+
+            return False
+
+    def inc_n(self, n: int, exception: type[ParseError] | None = None) -> bool:
+        """
+        Increments the parser by n characters
+        if the end of the input has not been reached.
+        """
+        return all(self.inc(exception=exception) for _ in range(n))
+
+    def consume(self, chars, min=0, max=-1):
+        """
+        Consume chars until min/max is satisfied is valid.
+        """
+        while self.current in chars and max != 0:
+            min -= 1
+            max -= 1
+            if not self.inc():
+                break
+
+        # failed to consume minimum number of characters
+        if min > 0:
+            raise self.parse_error(UnexpectedCharError, self.current)
+
+    def end(self) -> bool:
+        """
+        Returns True if the parser has reached the end of the input.
+        """
+        return self._current is self.EOF
+
+    def mark(self) -> None:
+        """
+        Sets the marker to the index's current position
+        """
+        self._marker = self._idx
+
+    def parse_error(
+        self,
+        exception: type[ParseError] = ParseError,
+        *args: Any,
+        **kwargs: Any,
+    ) -> ParseError:
+        """
+        Creates a generic "parse error" at the current position.
+        """
+        line, col = self._to_linecol()
+
+        return exception(line, col, *args, **kwargs)
+
+    def _to_linecol(self) -> tuple[int, int]:
+        cur = 0
+        for i, line in enumerate(self.splitlines()):
+            if cur + len(line) + 1 > self.idx:
+                return (i + 1, self.idx - cur)
+
+            cur += len(line) + 1
+
+        return len(self.splitlines()), 0
diff --git a/venv/lib/python3.9/site-packages/tomlkit/toml_char.py b/venv/lib/python3.9/site-packages/tomlkit/toml_char.py
new file mode 100644
index 000000000..b4bb4110c
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit/toml_char.py
@@ -0,0 +1,52 @@
+import string
+
+
+class TOMLChar(str):
+    def __init__(self, c):
+        super().__init__()
+
+        if len(self) > 1:
+            raise ValueError("A TOML character must be of length 1")
+
+    BARE = string.ascii_letters + string.digits + "-_"
+    KV = "= \t"
+    NUMBER = string.digits + "+-_.e"
+    SPACES = " \t"
+    NL = "\n\r"
+    WS = SPACES + NL
+
+    def is_bare_key_char(self) -> bool:
+        """
+        Whether the character is a valid bare key name or not.
+        """
+        return self in self.BARE
+
+    def is_kv_sep(self) -> bool:
+        """
+        Whether the character is a valid key/value separator or not.
+        """
+        return self in self.KV
+
+    def is_int_float_char(self) -> bool:
+        """
+        Whether the character if a valid integer or float value character or not.
+        """
+        return self in self.NUMBER
+
+    def is_ws(self) -> bool:
+        """
+        Whether the character is a whitespace character or not.
+        """
+        return self in self.WS
+
+    def is_nl(self) -> bool:
+        """
+        Whether the character is a new line character or not.
+        """
+        return self in self.NL
+
+    def is_spaces(self) -> bool:
+        """
+        Whether the character is a space or not
+        """
+        return self in self.SPACES
diff --git a/venv/lib/python3.9/site-packages/tomlkit/toml_document.py b/venv/lib/python3.9/site-packages/tomlkit/toml_document.py
new file mode 100644
index 000000000..71fac2e10
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit/toml_document.py
@@ -0,0 +1,7 @@
+from tomlkit.container import Container
+
+
+class TOMLDocument(Container):
+    """
+    A TOML document.
+    """
diff --git a/venv/lib/python3.9/site-packages/tomlkit/toml_file.py b/venv/lib/python3.9/site-packages/tomlkit/toml_file.py
new file mode 100644
index 000000000..745913080
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/tomlkit/toml_file.py
@@ -0,0 +1,58 @@
+import os
+import re
+
+from typing import TYPE_CHECKING
+
+from tomlkit.api import loads
+from tomlkit.toml_document import TOMLDocument
+
+
+if TYPE_CHECKING:
+    from _typeshed import StrPath as _StrPath
+else:
+    from typing import Union
+
+    _StrPath = Union[str, os.PathLike]
+
+
+class TOMLFile:
+    """
+    Represents a TOML file.
+
+    :param path: path to the TOML file
+    """
+
+    def __init__(self, path: _StrPath) -> None:
+        self._path = path
+        self._linesep = os.linesep
+
+    def read(self) -> TOMLDocument:
+        """Read the file content as a :class:`tomlkit.toml_document.TOMLDocument`."""
+        with open(self._path, encoding="utf-8", newline="") as f:
+            content = f.read()
+
+            # check if consistent line endings
+            num_newline = content.count("\n")
+            if num_newline > 0:
+                num_win_eol = content.count("\r\n")
+                if num_win_eol == num_newline:
+                    self._linesep = "\r\n"
+                elif num_win_eol == 0:
+                    self._linesep = "\n"
+                else:
+                    self._linesep = "mixed"
+
+            return loads(content)
+
+    def write(self, data: TOMLDocument) -> None:
+        """Write the TOMLDocument to the file."""
+        content = data.as_string()
+
+        # apply linesep
+        if self._linesep == "\n":
+            content = content.replace("\r\n", "\n")
+        elif self._linesep == "\r\n":
+            content = re.sub(r"(?<!\r)\n", "\r\n", content)
+
+        with open(self._path, "w", encoding="utf-8", newline="") as f:
+            f.write(content)
diff --git a/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/INSTALLER b/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/INSTALLER
new file mode 100644
index 000000000..a1b589e38
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/INSTALLER
@@ -0,0 +1 @@
+pip
diff --git a/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/LICENSE b/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/LICENSE
new file mode 100644
index 000000000..f26bcf4d2
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/LICENSE
@@ -0,0 +1,279 @@
+A. HISTORY OF THE SOFTWARE
+==========================
+
+Python was created in the early 1990s by Guido van Rossum at Stichting
+Mathematisch Centrum (CWI, see https://www.cwi.nl) in the Netherlands
+as a successor of a language called ABC.  Guido remains Python's
+principal author, although it includes many contributions from others.
+
+In 1995, Guido continued his work on Python at the Corporation for
+National Research Initiatives (CNRI, see https://www.cnri.reston.va.us)
+in Reston, Virginia where he released several versions of the
+software.
+
+In May 2000, Guido and the Python core development team moved to
+BeOpen.com to form the BeOpen PythonLabs team.  In October of the same
+year, the PythonLabs team moved to Digital Creations, which became
+Zope Corporation.  In 2001, the Python Software Foundation (PSF, see
+https://www.python.org/psf/) was formed, a non-profit organization
+created specifically to own Python-related Intellectual Property.
+Zope Corporation was a sponsoring member of the PSF.
+
+All Python releases are Open Source (see https://opensource.org for
+the Open Source Definition).  Historically, most, but not all, Python
+releases have also been GPL-compatible; the table below summarizes
+the various releases.
+
+    Release         Derived     Year        Owner       GPL-
+                    from                                compatible? (1)
+
+    0.9.0 thru 1.2              1991-1995   CWI         yes
+    1.3 thru 1.5.2  1.2         1995-1999   CNRI        yes
+    1.6             1.5.2       2000        CNRI        no
+    2.0             1.6         2000        BeOpen.com  no
+    1.6.1           1.6         2001        CNRI        yes (2)
+    2.1             2.0+1.6.1   2001        PSF         no
+    2.0.1           2.0+1.6.1   2001        PSF         yes
+    2.1.1           2.1+2.0.1   2001        PSF         yes
+    2.1.2           2.1.1       2002        PSF         yes
+    2.1.3           2.1.2       2002        PSF         yes
+    2.2 and above   2.1.1       2001-now    PSF         yes
+
+Footnotes:
+
+(1) GPL-compatible doesn't mean that we're distributing Python under
+    the GPL.  All Python licenses, unlike the GPL, let you distribute
+    a modified version without making your changes open source.  The
+    GPL-compatible licenses make it possible to combine Python with
+    other software that is released under the GPL; the others don't.
+
+(2) According to Richard Stallman, 1.6.1 is not GPL-compatible,
+    because its license has a choice of law clause.  According to
+    CNRI, however, Stallman's lawyer has told CNRI's lawyer that 1.6.1
+    is "not incompatible" with the GPL.
+
+Thanks to the many outside volunteers who have worked under Guido's
+direction to make these releases possible.
+
+
+B. TERMS AND CONDITIONS FOR ACCESSING OR OTHERWISE USING PYTHON
+===============================================================
+
+Python software and documentation are licensed under the
+Python Software Foundation License Version 2.
+
+Starting with Python 3.8.6, examples, recipes, and other code in
+the documentation are dual licensed under the PSF License Version 2
+and the Zero-Clause BSD license.
+
+Some software incorporated into Python is under different licenses.
+The licenses are listed with code falling under that license.
+
+
+PYTHON SOFTWARE FOUNDATION LICENSE VERSION 2
+--------------------------------------------
+
+1. This LICENSE AGREEMENT is between the Python Software Foundation
+("PSF"), and the Individual or Organization ("Licensee") accessing and
+otherwise using this software ("Python") in source or binary form and
+its associated documentation.
+
+2. Subject to the terms and conditions of this License Agreement, PSF hereby
+grants Licensee a nonexclusive, royalty-free, world-wide license to reproduce,
+analyze, test, perform and/or display publicly, prepare derivative works,
+distribute, and otherwise use Python alone or in any derivative version,
+provided, however, that PSF's License Agreement and PSF's notice of copyright,
+i.e., "Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,
+2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023 Python Software Foundation;
+All Rights Reserved" are retained in Python alone or in any derivative version
+prepared by Licensee.
+
+3. In the event Licensee prepares a derivative work that is based on
+or incorporates Python or any part thereof, and wants to make
+the derivative work available to others as provided herein, then
+Licensee hereby agrees to include in any such work a brief summary of
+the changes made to Python.
+
+4. PSF is making Python available to Licensee on an "AS IS"
+basis.  PSF MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR
+IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, PSF MAKES NO AND
+DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS
+FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON WILL NOT
+INFRINGE ANY THIRD PARTY RIGHTS.
+
+5. PSF SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON
+FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS
+A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON,
+OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
+
+6. This License Agreement will automatically terminate upon a material
+breach of its terms and conditions.
+
+7. Nothing in this License Agreement shall be deemed to create any
+relationship of agency, partnership, or joint venture between PSF and
+Licensee.  This License Agreement does not grant permission to use PSF
+trademarks or trade name in a trademark sense to endorse or promote
+products or services of Licensee, or any third party.
+
+8. By copying, installing or otherwise using Python, Licensee
+agrees to be bound by the terms and conditions of this License
+Agreement.
+
+
+BEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0
+-------------------------------------------
+
+BEOPEN PYTHON OPEN SOURCE LICENSE AGREEMENT VERSION 1
+
+1. This LICENSE AGREEMENT is between BeOpen.com ("BeOpen"), having an
+office at 160 Saratoga Avenue, Santa Clara, CA 95051, and the
+Individual or Organization ("Licensee") accessing and otherwise using
+this software in source or binary form and its associated
+documentation ("the Software").
+
+2. Subject to the terms and conditions of this BeOpen Python License
+Agreement, BeOpen hereby grants Licensee a non-exclusive,
+royalty-free, world-wide license to reproduce, analyze, test, perform
+and/or display publicly, prepare derivative works, distribute, and
+otherwise use the Software alone or in any derivative version,
+provided, however, that the BeOpen Python License is retained in the
+Software, alone or in any derivative version prepared by Licensee.
+
+3. BeOpen is making the Software available to Licensee on an "AS IS"
+basis.  BEOPEN MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR
+IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, BEOPEN MAKES NO AND
+DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS
+FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF THE SOFTWARE WILL NOT
+INFRINGE ANY THIRD PARTY RIGHTS.
+
+4. BEOPEN SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE
+SOFTWARE FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS
+AS A RESULT OF USING, MODIFYING OR DISTRIBUTING THE SOFTWARE, OR ANY
+DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
+
+5. This License Agreement will automatically terminate upon a material
+breach of its terms and conditions.
+
+6. This License Agreement shall be governed by and interpreted in all
+respects by the law of the State of California, excluding conflict of
+law provisions.  Nothing in this License Agreement shall be deemed to
+create any relationship of agency, partnership, or joint venture
+between BeOpen and Licensee.  This License Agreement does not grant
+permission to use BeOpen trademarks or trade names in a trademark
+sense to endorse or promote products or services of Licensee, or any
+third party.  As an exception, the "BeOpen Python" logos available at
+http://www.pythonlabs.com/logos.html may be used according to the
+permissions granted on that web page.
+
+7. By copying, installing or otherwise using the software, Licensee
+agrees to be bound by the terms and conditions of this License
+Agreement.
+
+
+CNRI LICENSE AGREEMENT FOR PYTHON 1.6.1
+---------------------------------------
+
+1. This LICENSE AGREEMENT is between the Corporation for National
+Research Initiatives, having an office at 1895 Preston White Drive,
+Reston, VA 20191 ("CNRI"), and the Individual or Organization
+("Licensee") accessing and otherwise using Python 1.6.1 software in
+source or binary form and its associated documentation.
+
+2. Subject to the terms and conditions of this License Agreement, CNRI
+hereby grants Licensee a nonexclusive, royalty-free, world-wide
+license to reproduce, analyze, test, perform and/or display publicly,
+prepare derivative works, distribute, and otherwise use Python 1.6.1
+alone or in any derivative version, provided, however, that CNRI's
+License Agreement and CNRI's notice of copyright, i.e., "Copyright (c)
+1995-2001 Corporation for National Research Initiatives; All Rights
+Reserved" are retained in Python 1.6.1 alone or in any derivative
+version prepared by Licensee.  Alternately, in lieu of CNRI's License
+Agreement, Licensee may substitute the following text (omitting the
+quotes): "Python 1.6.1 is made available subject to the terms and
+conditions in CNRI's License Agreement.  This Agreement together with
+Python 1.6.1 may be located on the internet using the following
+unique, persistent identifier (known as a handle): 1895.22/1013.  This
+Agreement may also be obtained from a proxy server on the internet
+using the following URL: http://hdl.handle.net/1895.22/1013".
+
+3. In the event Licensee prepares a derivative work that is based on
+or incorporates Python 1.6.1 or any part thereof, and wants to make
+the derivative work available to others as provided herein, then
+Licensee hereby agrees to include in any such work a brief summary of
+the changes made to Python 1.6.1.
+
+4. CNRI is making Python 1.6.1 available to Licensee on an "AS IS"
+basis.  CNRI MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR
+IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, CNRI MAKES NO AND
+DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS
+FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON 1.6.1 WILL NOT
+INFRINGE ANY THIRD PARTY RIGHTS.
+
+5. CNRI SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON
+1.6.1 FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS
+A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON 1.6.1,
+OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
+
+6. This License Agreement will automatically terminate upon a material
+breach of its terms and conditions.
+
+7. This License Agreement shall be governed by the federal
+intellectual property law of the United States, including without
+limitation the federal copyright law, and, to the extent such
+U.S. federal law does not apply, by the law of the Commonwealth of
+Virginia, excluding Virginia's conflict of law provisions.
+Notwithstanding the foregoing, with regard to derivative works based
+on Python 1.6.1 that incorporate non-separable material that was
+previously distributed under the GNU General Public License (GPL), the
+law of the Commonwealth of Virginia shall govern this License
+Agreement only as to issues arising under or with respect to
+Paragraphs 4, 5, and 7 of this License Agreement.  Nothing in this
+License Agreement shall be deemed to create any relationship of
+agency, partnership, or joint venture between CNRI and Licensee.  This
+License Agreement does not grant permission to use CNRI trademarks or
+trade name in a trademark sense to endorse or promote products or
+services of Licensee, or any third party.
+
+8. By clicking on the "ACCEPT" button where indicated, or by copying,
+installing or otherwise using Python 1.6.1, Licensee agrees to be
+bound by the terms and conditions of this License Agreement.
+
+        ACCEPT
+
+
+CWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2
+--------------------------------------------------
+
+Copyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam,
+The Netherlands.  All rights reserved.
+
+Permission to use, copy, modify, and distribute this software and its
+documentation for any purpose and without fee is hereby granted,
+provided that the above copyright notice appear in all copies and that
+both that copyright notice and this permission notice appear in
+supporting documentation, and that the name of Stichting Mathematisch
+Centrum or CWI not be used in advertising or publicity pertaining to
+distribution of the software without specific, written prior
+permission.
+
+STICHTING MATHEMATISCH CENTRUM DISCLAIMS ALL WARRANTIES WITH REGARD TO
+THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND
+FITNESS, IN NO EVENT SHALL STICHTING MATHEMATISCH CENTRUM BE LIABLE
+FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
+OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+
+ZERO-CLAUSE BSD LICENSE FOR CODE IN THE PYTHON DOCUMENTATION
+----------------------------------------------------------------------
+
+Permission to use, copy, modify, and/or distribute this software for any
+purpose with or without fee is hereby granted.
+
+THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
+REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
+AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
+INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
+LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
+OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
+PERFORMANCE OF THIS SOFTWARE.
diff --git a/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/METADATA b/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/METADATA
new file mode 100644
index 000000000..f15e2b387
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/METADATA
@@ -0,0 +1,67 @@
+Metadata-Version: 2.1
+Name: typing_extensions
+Version: 4.12.2
+Summary: Backported and Experimental Type Hints for Python 3.8+
+Keywords: annotations,backport,checker,checking,function,hinting,hints,type,typechecking,typehinting,typehints,typing
+Author-email: "Guido van Rossum, Jukka Lehtosalo, Łukasz Langa, Michael Lee" <levkivskyi@gmail.com>
+Requires-Python: >=3.8
+Description-Content-Type: text/markdown
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Environment :: Console
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: Python Software Foundation License
+Classifier: Operating System :: OS Independent
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3 :: Only
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: Programming Language :: Python :: 3.12
+Classifier: Programming Language :: Python :: 3.13
+Classifier: Topic :: Software Development
+Project-URL: Bug Tracker, https://github.com/python/typing_extensions/issues
+Project-URL: Changes, https://github.com/python/typing_extensions/blob/main/CHANGELOG.md
+Project-URL: Documentation, https://typing-extensions.readthedocs.io/
+Project-URL: Home, https://github.com/python/typing_extensions
+Project-URL: Q & A, https://github.com/python/typing/discussions
+Project-URL: Repository, https://github.com/python/typing_extensions
+
+# Typing Extensions
+
+[![Chat at https://gitter.im/python/typing](https://badges.gitter.im/python/typing.svg)](https://gitter.im/python/typing)
+
+[Documentation](https://typing-extensions.readthedocs.io/en/latest/#) –
+[PyPI](https://pypi.org/project/typing-extensions/)
+
+## Overview
+
+The `typing_extensions` module serves two related purposes:
+
+- Enable use of new type system features on older Python versions. For example,
+  `typing.TypeGuard` is new in Python 3.10, but `typing_extensions` allows
+  users on previous Python versions to use it too.
+- Enable experimentation with new type system PEPs before they are accepted and
+  added to the `typing` module.
+
+`typing_extensions` is treated specially by static type checkers such as
+mypy and pyright. Objects defined in `typing_extensions` are treated the same
+way as equivalent forms in `typing`.
+
+`typing_extensions` uses
+[Semantic Versioning](https://semver.org/). The
+major version will be incremented only for backwards-incompatible changes.
+Therefore, it's safe to depend
+on `typing_extensions` like this: `typing_extensions >=x.y, <(x+1)`,
+where `x.y` is the first version that includes all features you need.
+
+## Included items
+
+See [the documentation](https://typing-extensions.readthedocs.io/en/latest/#) for a
+complete listing of module contents.
+
+## Contributing
+
+See [CONTRIBUTING.md](https://github.com/python/typing_extensions/blob/main/CONTRIBUTING.md)
+for how to contribute to `typing_extensions`.
+
diff --git a/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/RECORD b/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/RECORD
new file mode 100644
index 000000000..b1f35826d
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/RECORD
@@ -0,0 +1,7 @@
+__pycache__/typing_extensions.cpython-39.pyc,,
+typing_extensions-4.12.2.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
+typing_extensions-4.12.2.dist-info/LICENSE,sha256=Oy-B_iHRgcSZxZolbI4ZaEVdZonSaaqFNzv7avQdo78,13936
+typing_extensions-4.12.2.dist-info/METADATA,sha256=BeUQIa8cnYbrjWx-N8TOznM9UGW5Gm2DicVpDtRA8W0,3018
+typing_extensions-4.12.2.dist-info/RECORD,,
+typing_extensions-4.12.2.dist-info/WHEEL,sha256=EZbGkh7Ie4PoZfRQ8I0ZuP9VklN_TvcZ6DSE5Uar4z4,81
+typing_extensions.py,sha256=gwekpyG9DVG3lxWKX4ni8u7nk3We5slG98mA9F3DJQw,134451
diff --git a/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/WHEEL b/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/WHEEL
new file mode 100644
index 000000000..3b5e64b5e
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/typing_extensions-4.12.2.dist-info/WHEEL
@@ -0,0 +1,4 @@
+Wheel-Version: 1.0
+Generator: flit 3.9.0
+Root-Is-Purelib: true
+Tag: py3-none-any
diff --git a/venv/lib/python3.9/site-packages/typing_extensions.py b/venv/lib/python3.9/site-packages/typing_extensions.py
new file mode 100644
index 000000000..dec429ca8
--- /dev/null
+++ b/venv/lib/python3.9/site-packages/typing_extensions.py
@@ -0,0 +1,3641 @@
+import abc
+import collections
+import collections.abc
+import contextlib
+import functools
+import inspect
+import operator
+import sys
+import types as _types
+import typing
+import warnings
+
+__all__ = [
+    # Super-special typing primitives.
+    'Any',
+    'ClassVar',
+    'Concatenate',
+    'Final',
+    'LiteralString',
+    'ParamSpec',
+    'ParamSpecArgs',
+    'ParamSpecKwargs',
+    'Self',
+    'Type',
+    'TypeVar',
+    'TypeVarTuple',
+    'Unpack',
+
+    # ABCs (from collections.abc).
+    'Awaitable',
+    'AsyncIterator',
+    'AsyncIterable',
+    'Coroutine',
+    'AsyncGenerator',
+    'AsyncContextManager',
+    'Buffer',
+    'ChainMap',
+
+    # Concrete collection types.
+    'ContextManager',
+    'Counter',
+    'Deque',
+    'DefaultDict',
+    'NamedTuple',
+    'OrderedDict',
+    'TypedDict',
+
+    # Structural checks, a.k.a. protocols.
+    'SupportsAbs',
+    'SupportsBytes',
+    'SupportsComplex',
+    'SupportsFloat',
+    'SupportsIndex',
+    'SupportsInt',
+    'SupportsRound',
+
+    # One-off things.
+    'Annotated',
+    'assert_never',
+    'assert_type',
+    'clear_overloads',
+    'dataclass_transform',
+    'deprecated',
+    'Doc',
+    'get_overloads',
+    'final',
+    'get_args',
+    'get_origin',
+    'get_original_bases',
+    'get_protocol_members',
+    'get_type_hints',
+    'IntVar',
+    'is_protocol',
+    'is_typeddict',
+    'Literal',
+    'NewType',
+    'overload',
+    'override',
+    'Protocol',
+    'reveal_type',
+    'runtime',
+    'runtime_checkable',
+    'Text',
+    'TypeAlias',
+    'TypeAliasType',
+    'TypeGuard',
+    'TypeIs',
+    'TYPE_CHECKING',
+    'Never',
+    'NoReturn',
+    'ReadOnly',
+    'Required',
+    'NotRequired',
+
+    # Pure aliases, have always been in typing
+    'AbstractSet',
+    'AnyStr',
+    'BinaryIO',
+    'Callable',
+    'Collection',
+    'Container',
+    'Dict',
+    'ForwardRef',
+    'FrozenSet',
+    'Generator',
+    'Generic',
+    'Hashable',
+    'IO',
+    'ItemsView',
+    'Iterable',
+    'Iterator',
+    'KeysView',
+    'List',
+    'Mapping',
+    'MappingView',
+    'Match',
+    'MutableMapping',
+    'MutableSequence',
+    'MutableSet',
+    'NoDefault',
+    'Optional',
+    'Pattern',
+    'Reversible',
+    'Sequence',
+    'Set',
+    'Sized',
+    'TextIO',
+    'Tuple',
+    'Union',
+    'ValuesView',
+    'cast',
+    'no_type_check',
+    'no_type_check_decorator',
+]
+
+# for backward compatibility
+PEP_560 = True
+GenericMeta = type
+_PEP_696_IMPLEMENTED = sys.version_info >= (3, 13, 0, "beta")
+
+# The functions below are modified copies of typing internal helpers.
+# They are needed by _ProtocolMeta and they provide support for PEP 646.
+
+
+class _Sentinel:
+    def __repr__(self):
+        return "<sentinel>"
+
+
+_marker = _Sentinel()
+
+
+if sys.version_info >= (3, 10):
+    def _should_collect_from_parameters(t):
+        return isinstance(
+            t, (typing._GenericAlias, _types.GenericAlias, _types.UnionType)
+        )
+elif sys.version_info >= (3, 9):
+    def _should_collect_from_parameters(t):
+        return isinstance(t, (typing._GenericAlias, _types.GenericAlias))
+else:
+    def _should_collect_from_parameters(t):
+        return isinstance(t, typing._GenericAlias) and not t._special
+
+
+NoReturn = typing.NoReturn
+
+# Some unconstrained type variables.  These are used by the container types.
+# (These are not for export.)
+T = typing.TypeVar('T')  # Any type.
+KT = typing.TypeVar('KT')  # Key type.
+VT = typing.TypeVar('VT')  # Value type.
+T_co = typing.TypeVar('T_co', covariant=True)  # Any type covariant containers.
+T_contra = typing.TypeVar('T_contra', contravariant=True)  # Ditto contravariant.
+
+
+if sys.version_info >= (3, 11):
+    from typing import Any
+else:
+
+    class _AnyMeta(type):
+        def __instancecheck__(self, obj):
+            if self is Any:
+                raise TypeError("typing_extensions.Any cannot be used with isinstance()")
+            return super().__instancecheck__(obj)
+
+        def __repr__(self):
+            if self is Any:
+                return "typing_extensions.Any"
+            return super().__repr__()
+
+    class Any(metaclass=_AnyMeta):
+        """Special type indicating an unconstrained type.
+        - Any is compatible with every type.
+        - Any assumed to have all methods.
+        - All values assumed to be instances of Any.
+        Note that all the above statements are true from the point of view of
+        static type checkers. At runtime, Any should not be used with instance
+        checks.
+        """
+        def __new__(cls, *args, **kwargs):
+            if cls is Any:
+                raise TypeError("Any cannot be instantiated")
+            return super().__new__(cls, *args, **kwargs)
+
+
+ClassVar = typing.ClassVar
+
+
+class _ExtensionsSpecialForm(typing._SpecialForm, _root=True):
+    def __repr__(self):
+        return 'typing_extensions.' + self._name
+
+
+Final = typing.Final
+
+if sys.version_info >= (3, 11):
+    final = typing.final
+else:
+    # @final exists in 3.8+, but we backport it for all versions
+    # before 3.11 to keep support for the __final__ attribute.
+    # See https://bugs.python.org/issue46342
+    def final(f):
+        """This decorator can be used to indicate to type checkers that
+        the decorated method cannot be overridden, and decorated class
+        cannot be subclassed. For example:
+
+            class Base:
+                @final
+                def done(self) -> None:
+                    ...
+            class Sub(Base):
+                def done(self) -> None:  # Error reported by type checker
+                    ...
+            @final
+            class Leaf:
+                ...
+            class Other(Leaf):  # Error reported by type checker
+                ...
+
+        There is no runtime checking of these properties. The decorator
+        sets the ``__final__`` attribute to ``True`` on the decorated object
+        to allow runtime introspection.
+        """
+        try:
+            f.__final__ = True
+        except (AttributeError, TypeError):
+            # Skip the attribute silently if it is not writable.
+            # AttributeError happens if the object has __slots__ or a
+            # read-only property, TypeError if it's a builtin class.
+            pass
+        return f
+
+
+def IntVar(name):
+    return typing.TypeVar(name)
+
+
+# A Literal bug was fixed in 3.11.0, 3.10.1 and 3.9.8
+if sys.version_info >= (3, 10, 1):
+    Literal = typing.Literal
+else:
+    def _flatten_literal_params(parameters):
+        """An internal helper for Literal creation: flatten Literals among parameters"""
+        params = []
+        for p in parameters:
+            if isinstance(p, _LiteralGenericAlias):
+                params.extend(p.__args__)
+            else:
+                params.append(p)
+        return tuple(params)
+
+    def _value_and_type_iter(params):
+        for p in params:
+            yield p, type(p)
+
+    class _LiteralGenericAlias(typing._GenericAlias, _root=True):
+        def __eq__(self, other):
+            if not isinstance(other, _LiteralGenericAlias):
+                return NotImplemented
+            these_args_deduped = set(_value_and_type_iter(self.__args__))
+            other_args_deduped = set(_value_and_type_iter(other.__args__))
+            return these_args_deduped == other_args_deduped
+
+        def __hash__(self):
+            return hash(frozenset(_value_and_type_iter(self.__args__)))
+
+    class _LiteralForm(_ExtensionsSpecialForm, _root=True):
+        def __init__(self, doc: str):
+            self._name = 'Literal'
+            self._doc = self.__doc__ = doc
+
+        def __getitem__(self, parameters):
+            if not isinstance(parameters, tuple):
+                parameters = (parameters,)
+
+            parameters = _flatten_literal_params(parameters)
+
+            val_type_pairs = list(_value_and_type_iter(parameters))
+            try:
+                deduped_pairs = set(val_type_pairs)
+            except TypeError:
+                # unhashable parameters
+                pass
+            else:
+                # similar logic to typing._deduplicate on Python 3.9+
+                if len(deduped_pairs) < len(val_type_pairs):
+                    new_parameters = []
+                    for pair in val_type_pairs:
+                        if pair in deduped_pairs:
+                            new_parameters.append(pair[0])
+                            deduped_pairs.remove(pair)
+                    assert not deduped_pairs, deduped_pairs
+                    parameters = tuple(new_parameters)
+
+            return _LiteralGenericAlias(self, parameters)
+
+    Literal = _LiteralForm(doc="""\
+                           A type that can be used to indicate to type checkers
+                           that the corresponding value has a value literally equivalent
+                           to the provided parameter. For example:
+
+                               var: Literal[4] = 4
+
+                           The type checker understands that 'var' is literally equal to
+                           the value 4 and no other value.
+
+                           Literal[...] cannot be subclassed. There is no runtime
+                           checking verifying that the parameter is actually a value
+                           instead of a type.""")
+
+
+_overload_dummy = typing._overload_dummy
+
+
+if hasattr(typing, "get_overloads"):  # 3.11+
+    overload = typing.overload
+    get_overloads = typing.get_overloads
+    clear_overloads = typing.clear_overloads
+else:
+    # {module: {qualname: {firstlineno: func}}}
+    _overload_registry = collections.defaultdict(
+        functools.partial(collections.defaultdict, dict)
+    )
+
+    def overload(func):
+        """Decorator for overloaded functions/methods.
+
+        In a stub file, place two or more stub definitions for the same
+        function in a row, each decorated with @overload.  For example:
+
+        @overload
+        def utf8(value: None) -> None: ...
+        @overload
+        def utf8(value: bytes) -> bytes: ...
+        @overload
+        def utf8(value: str) -> bytes: ...
+
+        In a non-stub file (i.e. a regular .py file), do the same but
+        follow it with an implementation.  The implementation should *not*
+        be decorated with @overload.  For example:
+
+        @overload
+        def utf8(value: None) -> None: ...
+        @overload
+        def utf8(value: bytes) -> bytes: ...
+        @overload
+        def utf8(value: str) -> bytes: ...
+        def utf8(value):
+            # implementation goes here
+
+        The overloads for a function can be retrieved at runtime using the
+        get_overloads() function.
+        """
+        # classmethod and staticmethod
+        f = getattr(func, "__func__", func)
+        try:
+            _overload_registry[f.__module__][f.__qualname__][
+                f.__code__.co_firstlineno
+            ] = func
+        except AttributeError:
+            # Not a normal function; ignore.
+            pass
+        return _overload_dummy
+
+    def get_overloads(func):
+        """Return all defined overloads for *func* as a sequence."""
+        # classmethod and staticmethod
+        f = getattr(func, "__func__", func)
+        if f.__module__ not in _overload_registry:
+            return []
+        mod_dict = _overload_registry[f.__module__]
+        if f.__qualname__ not in mod_dict:
+            return []
+        return list(mod_dict[f.__qualname__].values())
+
+    def clear_overloads():
+        """Clear all overloads in the registry."""
+        _overload_registry.clear()
+
+
+# This is not a real generic class.  Don't use outside annotations.
+Type = typing.Type
+
+# Various ABCs mimicking those in collections.abc.
+# A few are simply re-exported for completeness.
+Awaitable = typing.Awaitable
+Coroutine = typing.Coroutine
+AsyncIterable = typing.AsyncIterable
+AsyncIterator = typing.AsyncIterator
+Deque = typing.Deque
+DefaultDict = typing.DefaultDict
+OrderedDict = typing.OrderedDict
+Counter = typing.Counter
+ChainMap = typing.ChainMap
+Text = typing.Text
+TYPE_CHECKING = typing.TYPE_CHECKING
+
+
+if sys.version_info >= (3, 13, 0, "beta"):
+    from typing import AsyncContextManager, AsyncGenerator, ContextManager, Generator
+else:
+    def _is_dunder(attr):
+        return attr.startswith('__') and attr.endswith('__')
+
+    # Python <3.9 doesn't have typing._SpecialGenericAlias
+    _special_generic_alias_base = getattr(
+        typing, "_SpecialGenericAlias", typing._GenericAlias
+    )
+
+    class _SpecialGenericAlias(_special_generic_alias_base, _root=True):
+        def __init__(self, origin, nparams, *, inst=True, name=None, defaults=()):
+            if _special_generic_alias_base is typing._GenericAlias:
+                # Python <3.9
+                self.__origin__ = origin
+                self._nparams = nparams
+                super().__init__(origin, nparams, special=True, inst=inst, name=name)
+            else:
+                # Python >= 3.9
+                super().__init__(origin, nparams, inst=inst, name=name)
+            self._defaults = defaults
+
+        def __setattr__(self, attr, val):
+            allowed_attrs = {'_name', '_inst', '_nparams', '_defaults'}
+            if _special_generic_alias_base is typing._GenericAlias:
+                # Python <3.9
+                allowed_attrs.add("__origin__")
+            if _is_dunder(attr) or attr in allowed_attrs:
+                object.__setattr__(self, attr, val)
+            else:
+                setattr(self.__origin__, attr, val)
+
+        @typing._tp_cache
+        def __getitem__(self, params):
+            if not isinstance(params, tuple):
+                params = (params,)
+            msg = "Parameters to generic types must be types."
+            params = tuple(typing._type_check(p, msg) for p in params)
+            if (
+                self._defaults
+                and len(params) < self._nparams
+                and len(params) + len(self._defaults) >= self._nparams
+            ):
+                params = (*params, *self._defaults[len(params) - self._nparams:])
+            actual_len = len(params)
+
+            if actual_len != self._nparams:
+                if self._defaults:
+                    expected = f"at least {self._nparams - len(self._defaults)}"
+                else:
+                    expected = str(self._nparams)
+                if not self._nparams:
+                    raise TypeError(f"{self} is not a generic class")
+                raise TypeError(
+                    f"Too {'many' if actual_len > self._nparams else 'few'}"
+                    f" arguments for {self};"
+                    f" actual {actual_len}, expected {expected}"
+                )
+            return self.copy_with(params)
+
+    _NoneType = type(None)
+    Generator = _SpecialGenericAlias(
+        collections.abc.Generator, 3, defaults=(_NoneType, _NoneType)
+    )
+    AsyncGenerator = _SpecialGenericAlias(
+        collections.abc.AsyncGenerator, 2, defaults=(_NoneType,)
+    )
+    ContextManager = _SpecialGenericAlias(
+        contextlib.AbstractContextManager,
+        2,
+        name="ContextManager",
+        defaults=(typing.Optional[bool],)
+    )
+    AsyncContextManager = _SpecialGenericAlias(
+        contextlib.AbstractAsyncContextManager,
+        2,
+        name="AsyncContextManager",
+        defaults=(typing.Optional[bool],)
+    )
+
+
+_PROTO_ALLOWLIST = {
+    'collections.abc': [
+        'Callable', 'Awaitable', 'Iterable', 'Iterator', 'AsyncIterable',
+        'Hashable', 'Sized', 'Container', 'Collection', 'Reversible', 'Buffer',
+    ],
+    'contextlib': ['AbstractContextManager', 'AbstractAsyncContextManager'],
+    'typing_extensions': ['Buffer'],
+}
+
+
+_EXCLUDED_ATTRS = frozenset(typing.EXCLUDED_ATTRIBUTES) | {
+    "__match_args__", "__protocol_attrs__", "__non_callable_proto_members__",
+    "__final__",
+}
+
+
+def _get_protocol_attrs(cls):
+    attrs = set()
+    for base in cls.__mro__[:-1]:  # without object
+        if base.__name__ in {'Protocol', 'Generic'}:
+            continue
+        annotations = getattr(base, '__annotations__', {})
+        for attr in (*base.__dict__, *annotations):
+            if (not attr.startswith('_abc_') and attr not in _EXCLUDED_ATTRS):
+                attrs.add(attr)
+    return attrs
+
+
+def _caller(depth=2):
+    try:
+        return sys._getframe(depth).f_globals.get('__name__', '__main__')
+    except (AttributeError, ValueError):  # For platforms without _getframe()
+        return None
+
+
+# `__match_args__` attribute was removed from protocol members in 3.13,
+# we want to backport this change to older Python versions.
+if sys.version_info >= (3, 13):
+    Protocol = typing.Protocol
+else:
+    def _allow_reckless_class_checks(depth=3):
+        """Allow instance and class checks for special stdlib modules.
+        The abc and functools modules indiscriminately call isinstance() and
+        issubclass() on the whole MRO of a user class, which may contain protocols.
+        """
+        return _caller(depth) in {'abc', 'functools', None}
+
+    def _no_init(self, *args, **kwargs):
+        if type(self)._is_protocol:
+            raise TypeError('Protocols cannot be instantiated')
+
+    def _type_check_issubclass_arg_1(arg):
+        """Raise TypeError if `arg` is not an instance of `type`
+        in `issubclass(arg, <protocol>)`.
+
+        In most cases, this is verified by type.__subclasscheck__.
+        Checking it again unnecessarily would slow down issubclass() checks,
+        so, we don't perform this check unless we absolutely have to.
+
+        For various error paths, however,
+        we want to ensure that *this* error message is shown to the user
+        where relevant, rather than a typing.py-specific error message.
+        """
+        if not isinstance(arg, type):
+            # Same error message as for issubclass(1, int).
+            raise TypeError('issubclass() arg 1 must be a class')
+
+    # Inheriting from typing._ProtocolMeta isn't actually desirable,
+    # but is necessary to allow typing.Protocol and typing_extensions.Protocol
+    # to mix without getting TypeErrors about "metaclass conflict"
+    class _ProtocolMeta(type(typing.Protocol)):
+        # This metaclass is somewhat unfortunate,
+        # but is necessary for several reasons...
+        #
+        # NOTE: DO NOT call super() in any methods in this class
+        # That would call the methods on typing._ProtocolMeta on Python 3.8-3.11
+        # and those are slow
+        def __new__(mcls, name, bases, namespace, **kwargs):
+            if name == "Protocol" and len(bases) < 2:
+                pass
+            elif {Protocol, typing.Protocol} & set(bases):
+                for base in bases:
+                    if not (
+                        base in {object, typing.Generic, Protocol, typing.Protocol}
+                        or base.__name__ in _PROTO_ALLOWLIST.get(base.__module__, [])
+                        or is_protocol(base)
+                    ):
+                        raise TypeError(
+                            f"Protocols can only inherit from other protocols, "
+                            f"got {base!r}"
+                        )
+            return abc.ABCMeta.__new__(mcls, name, bases, namespace, **kwargs)
+
+        def __init__(cls, *args, **kwargs):
+            abc.ABCMeta.__init__(cls, *args, **kwargs)
+            if getattr(cls, "_is_protocol", False):
+                cls.__protocol_attrs__ = _get_protocol_attrs(cls)
+
+        def __subclasscheck__(cls, other):
+            if cls is Protocol:
+                return type.__subclasscheck__(cls, other)
+            if (
+                getattr(cls, '_is_protocol', False)
+                and not _allow_reckless_class_checks()
+            ):
+                if not getattr(cls, '_is_runtime_protocol', False):
+                    _type_check_issubclass_arg_1(other)
+                    raise TypeError(
+                        "Instance and class checks can only be used with "
+                        "@runtime_checkable protocols"
+                    )
+                if (
+                    # this attribute is set by @runtime_checkable:
+                    cls.__non_callable_proto_members__
+                    and cls.__dict__.get("__subclasshook__") is _proto_hook
+                ):
+                    _type_check_issubclass_arg_1(other)
+                    non_method_attrs = sorted(cls.__non_callable_proto_members__)
+                    raise TypeError(
+                        "Protocols with non-method members don't support issubclass()."
+                        f" Non-method members: {str(non_method_attrs)[1:-1]}."
+                    )
+            return abc.ABCMeta.__subclasscheck__(cls, other)
+
+        def __instancecheck__(cls, instance):
+            # We need this method for situations where attributes are
+            # assigned in __init__.
+            if cls is Protocol:
+                return type.__instancecheck__(cls, instance)
+            if not getattr(cls, "_is_protocol", False):
+                # i.e., it's a concrete subclass of a protocol
+                return abc.ABCMeta.__instancecheck__(cls, instance)
+
+            if (
+                not getattr(cls, '_is_runtime_protocol', False) and
+                not _allow_reckless_class_checks()
+            ):
+                raise TypeError("Instance and class checks can only be used with"
+                                " @runtime_checkable protocols")
+
+            if abc.ABCMeta.__instancecheck__(cls, instance):
+                return True
+
+            for attr in cls.__protocol_attrs__:
+                try:
+                    val = inspect.getattr_static(instance, attr)
+                except AttributeError:
+                    break
+                # this attribute is set by @runtime_checkable:
+                if val is None and attr not in cls.__non_callable_proto_members__:
+                    break
+            else:
+                return True
+
+            return False
+
+        def __eq__(cls, other):
+            # Hack so that typing.Generic.__class_getitem__
+            # treats typing_extensions.Protocol
+            # as equivalent to typing.Protocol
+            if abc.ABCMeta.__eq__(cls, other) is True:
+                return True
+            return cls is Protocol and other is typing.Protocol
+
+        # This has to be defined, or the abc-module cache
+        # complains about classes with this metaclass being unhashable,
+        # if we define only __eq__!
+        def __hash__(cls) -> int:
+            return type.__hash__(cls)
+
+    @classmethod
+    def _proto_hook(cls, other):
+        if not cls.__dict__.get('_is_protocol', False):
+            return NotImplemented
+
+        for attr in cls.__protocol_attrs__:
+            for base in other.__mro__:
+                # Check if the members appears in the class dictionary...
+                if attr in base.__dict__:
+                    if base.__dict__[attr] is None:
+                        return NotImplemented
+                    break
+
+                # ...or in annotations, if it is a sub-protocol.
+                annotations = getattr(base, '__annotations__', {})
+                if (
+                    isinstance(annotations, collections.abc.Mapping)
+                    and attr in annotations
+                    and is_protocol(other)
+                ):
+                    break
+            else:
+                return NotImplemented
+        return True
+
+    class Protocol(typing.Generic, metaclass=_ProtocolMeta):
+        __doc__ = typing.Protocol.__doc__
+        __slots__ = ()
+        _is_protocol = True
+        _is_runtime_protocol = False
+
+        def __init_subclass__(cls, *args, **kwargs):
+            super().__init_subclass__(*args, **kwargs)
+
+            # Determine if this is a protocol or a concrete subclass.
+            if not cls.__dict__.get('_is_protocol', False):
+                cls._is_protocol = any(b is Protocol for b in cls.__bases__)
+
+            # Set (or override) the protocol subclass hook.
+            if '__subclasshook__' not in cls.__dict__:
+                cls.__subclasshook__ = _proto_hook
+
+            # Prohibit instantiation for protocol classes
+            if cls._is_protocol and cls.__init__ is Protocol.__init__:
+                cls.__init__ = _no_init
+
+
+if sys.version_info >= (3, 13):
+    runtime_checkable = typing.runtime_checkable
+else:
+    def runtime_checkable(cls):
+        """Mark a protocol class as a runtime protocol.
+
+        Such protocol can be used with isinstance() and issubclass().
+        Raise TypeError if applied to a non-protocol class.
+        This allows a simple-minded structural check very similar to
+        one trick ponies in collections.abc such as Iterable.
+
+        For example::
+
+            @runtime_checkable
+            class Closable(Protocol):
+                def close(self): ...
+
+            assert isinstance(open('/some/file'), Closable)
+
+        Warning: this will check only the presence of the required methods,
+        not their type signatures!
+        """
+        if not issubclass(cls, typing.Generic) or not getattr(cls, '_is_protocol', False):
+            raise TypeError(f'@runtime_checkable can be only applied to protocol classes,'
+                            f' got {cls!r}')
+        cls._is_runtime_protocol = True
+
+        # typing.Protocol classes on <=3.11 break if we execute this block,
+        # because typing.Protocol classes on <=3.11 don't have a
+        # `__protocol_attrs__` attribute, and this block relies on the
+        # `__protocol_attrs__` attribute. Meanwhile, typing.Protocol classes on 3.12.2+
+        # break if we *don't* execute this block, because *they* assume that all
+        # protocol classes have a `__non_callable_proto_members__` attribute
+        # (which this block sets)
+        if isinstance(cls, _ProtocolMeta) or sys.version_info >= (3, 12, 2):
+            # PEP 544 prohibits using issubclass()
+            # with protocols that have non-method members.
+            # See gh-113320 for why we compute this attribute here,
+            # rather than in `_ProtocolMeta.__init__`
+            cls.__non_callable_proto_members__ = set()
+            for attr in cls.__protocol_attrs__:
+                try:
+                    is_callable = callable(getattr(cls, attr, None))
+                except Exception as e:
+                    raise TypeError(
+                        f"Failed to determine whether protocol member {attr!r} "
+                        "is a method member"
+                    ) from e
+                else:
+                    if not is_callable:
+                        cls.__non_callable_proto_members__.add(attr)
+
+        return cls
+
+
+# The "runtime" alias exists for backwards compatibility.
+runtime = runtime_checkable
+
+
+# Our version of runtime-checkable protocols is faster on Python 3.8-3.11
+if sys.version_info >= (3, 12):
+    SupportsInt = typing.SupportsInt
+    SupportsFloat = typing.SupportsFloat
+    SupportsComplex = typing.SupportsComplex
+    SupportsBytes = typing.SupportsBytes
+    SupportsIndex = typing.SupportsIndex
+    SupportsAbs = typing.SupportsAbs
+    SupportsRound = typing.SupportsRound
+else:
+    @runtime_checkable
+    class SupportsInt(Protocol):
+        """An ABC with one abstract method __int__."""
+        __slots__ = ()
+
+        @abc.abstractmethod
+        def __int__(self) -> int:
+            pass
+
+    @runtime_checkable
+    class SupportsFloat(Protocol):
+        """An ABC with one abstract method __float__."""
+        __slots__ = ()
+
+        @abc.abstractmethod
+        def __float__(self) -> float:
+            pass
+
+    @runtime_checkable
+    class SupportsComplex(Protocol):
+        """An ABC with one abstract method __complex__."""
+        __slots__ = ()
+
+        @abc.abstractmethod
+        def __complex__(self) -> complex:
+            pass
+
+    @runtime_checkable
+    class SupportsBytes(Protocol):
+        """An ABC with one abstract method __bytes__."""
+        __slots__ = ()
+
+        @abc.abstractmethod
+        def __bytes__(self) -> bytes:
+            pass
+
+    @runtime_checkable
+    class SupportsIndex(Protocol):
+        __slots__ = ()
+
+        @abc.abstractmethod
+        def __index__(self) -> int:
+            pass
+
+    @runtime_checkable
+    class SupportsAbs(Protocol[T_co]):
+        """
+        An ABC with one abstract method __abs__ that is covariant in its return type.
+        """
+        __slots__ = ()
+
+        @abc.abstractmethod
+        def __abs__(self) -> T_co:
+            pass
+
+    @runtime_checkable
+    class SupportsRound(Protocol[T_co]):
+        """
+        An ABC with one abstract method __round__ that is covariant in its return type.
+        """
+        __slots__ = ()
+
+        @abc.abstractmethod
+        def __round__(self, ndigits: int = 0) -> T_co:
+            pass
+
+
+def _ensure_subclassable(mro_entries):
+    def inner(func):
+        if sys.implementation.name == "pypy" and sys.version_info < (3, 9):
+            cls_dict = {
+                "__call__": staticmethod(func),
+                "__mro_entries__": staticmethod(mro_entries)
+            }
+            t = type(func.__name__, (), cls_dict)
+            return functools.update_wrapper(t(), func)
+        else:
+            func.__mro_entries__ = mro_entries
+            return func
+    return inner
+
+
+# Update this to something like >=3.13.0b1 if and when
+# PEP 728 is implemented in CPython
+_PEP_728_IMPLEMENTED = False
+
+if _PEP_728_IMPLEMENTED:
+    # The standard library TypedDict in Python 3.8 does not store runtime information
+    # about which (if any) keys are optional.  See https://bugs.python.org/issue38834
+    # The standard library TypedDict in Python 3.9.0/1 does not honour the "total"
+    # keyword with old-style TypedDict().  See https://bugs.python.org/issue42059
+    # The standard library TypedDict below Python 3.11 does not store runtime
+    # information about optional and required keys when using Required or NotRequired.
+    # Generic TypedDicts are also impossible using typing.TypedDict on Python <3.11.
+    # Aaaand on 3.12 we add __orig_bases__ to TypedDict
+    # to enable better runtime introspection.
+    # On 3.13 we deprecate some odd ways of creating TypedDicts.
+    # Also on 3.13, PEP 705 adds the ReadOnly[] qualifier.
+    # PEP 728 (still pending) makes more changes.
+    TypedDict = typing.TypedDict
+    _TypedDictMeta = typing._TypedDictMeta
+    is_typeddict = typing.is_typeddict
+else:
+    # 3.10.0 and later
+    _TAKES_MODULE = "module" in inspect.signature(typing._type_check).parameters
+
+    def _get_typeddict_qualifiers(annotation_type):
+        while True:
+            annotation_origin = get_origin(annotation_type)
+            if annotation_origin is Annotated:
+                annotation_args = get_args(annotation_type)
+                if annotation_args:
+                    annotation_type = annotation_args[0]
+                else:
+                    break
+            elif annotation_origin is Required:
+                yield Required
+                annotation_type, = get_args(annotation_type)
+            elif annotation_origin is NotRequired:
+                yield NotRequired
+                annotation_type, = get_args(annotation_type)
+            elif annotation_origin is ReadOnly:
+                yield ReadOnly
+                annotation_type, = get_args(annotation_type)
+            else:
+                break
+
+    class _TypedDictMeta(type):
+        def __new__(cls, name, bases, ns, *, total=True, closed=False):
+            """Create new typed dict class object.
+
+            This method is called when TypedDict is subclassed,
+            or when TypedDict is instantiated. This way
+            TypedDict supports all three syntax forms described in its docstring.
+            Subclasses and instances of TypedDict return actual dictionaries.
+            """
+            for base in bases:
+                if type(base) is not _TypedDictMeta and base is not typing.Generic:
+                    raise TypeError('cannot inherit from both a TypedDict type '
+                                    'and a non-TypedDict base class')
+
+            if any(issubclass(b, typing.Generic) for b in bases):
+                generic_base = (typing.Generic,)
+            else:
+                generic_base = ()
+
+            # typing.py generally doesn't let you inherit from plain Generic, unless
+            # the name of the class happens to be "Protocol"
+            tp_dict = type.__new__(_TypedDictMeta, "Protocol", (*generic_base, dict), ns)
+            tp_dict.__name__ = name
+            if tp_dict.__qualname__ == "Protocol":
+                tp_dict.__qualname__ = name
+
+            if not hasattr(tp_dict, '__orig_bases__'):
+                tp_dict.__orig_bases__ = bases
+
+            annotations = {}
+            if "__annotations__" in ns:
+                own_annotations = ns["__annotations__"]
+            elif "__annotate__" in ns:
+                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
+                own_annotations = ns["__annotate__"](1)
+            else:
+                own_annotations = {}
+            msg = "TypedDict('Name', {f0: t0, f1: t1, ...}); each t must be a type"
+            if _TAKES_MODULE:
+                own_annotations = {
+                    n: typing._type_check(tp, msg, module=tp_dict.__module__)
+                    for n, tp in own_annotations.items()
+                }
+            else:
+                own_annotations = {
+                    n: typing._type_check(tp, msg)
+                    for n, tp in own_annotations.items()
+                }
+            required_keys = set()
+            optional_keys = set()
+            readonly_keys = set()
+            mutable_keys = set()
+            extra_items_type = None
+
+            for base in bases:
+                base_dict = base.__dict__
+
+                annotations.update(base_dict.get('__annotations__', {}))
+                required_keys.update(base_dict.get('__required_keys__', ()))
+                optional_keys.update(base_dict.get('__optional_keys__', ()))
+                readonly_keys.update(base_dict.get('__readonly_keys__', ()))
+                mutable_keys.update(base_dict.get('__mutable_keys__', ()))
+                base_extra_items_type = base_dict.get('__extra_items__', None)
+                if base_extra_items_type is not None:
+                    extra_items_type = base_extra_items_type
+
+            if closed and extra_items_type is None:
+                extra_items_type = Never
+            if closed and "__extra_items__" in own_annotations:
+                annotation_type = own_annotations.pop("__extra_items__")
+                qualifiers = set(_get_typeddict_qualifiers(annotation_type))
+                if Required in qualifiers:
+                    raise TypeError(
+                        "Special key __extra_items__ does not support "
+                        "Required"
+                    )
+                if NotRequired in qualifiers:
+                    raise TypeError(
+                        "Special key __extra_items__ does not support "
+                        "NotRequired"
+                    )
+                extra_items_type = annotation_type
+
+            annotations.update(own_annotations)
+            for annotation_key, annotation_type in own_annotations.items():
+                qualifiers = set(_get_typeddict_qualifiers(annotation_type))
+
+                if Required in qualifiers:
+                    required_keys.add(annotation_key)
+                elif NotRequired in qualifiers:
+                    optional_keys.add(annotation_key)
+                elif total:
+                    required_keys.add(annotation_key)
+                else:
+                    optional_keys.add(annotation_key)
+                if ReadOnly in qualifiers:
+                    mutable_keys.discard(annotation_key)
+                    readonly_keys.add(annotation_key)
+                else:
+                    mutable_keys.add(annotation_key)
+                    readonly_keys.discard(annotation_key)
+
+            tp_dict.__annotations__ = annotations
+            tp_dict.__required_keys__ = frozenset(required_keys)
+            tp_dict.__optional_keys__ = frozenset(optional_keys)
+            tp_dict.__readonly_keys__ = frozenset(readonly_keys)
+            tp_dict.__mutable_keys__ = frozenset(mutable_keys)
+            if not hasattr(tp_dict, '__total__'):
+                tp_dict.__total__ = total
+            tp_dict.__closed__ = closed
+            tp_dict.__extra_items__ = extra_items_type
+            return tp_dict
+
+        __call__ = dict  # static method
+
+        def __subclasscheck__(cls, other):
+            # Typed dicts are only for static structural subtyping.
+            raise TypeError('TypedDict does not support instance and class checks')
+
+        __instancecheck__ = __subclasscheck__
+
+    _TypedDict = type.__new__(_TypedDictMeta, 'TypedDict', (), {})
+
+    @_ensure_subclassable(lambda bases: (_TypedDict,))
+    def TypedDict(typename, fields=_marker, /, *, total=True, closed=False, **kwargs):
+        """A simple typed namespace. At runtime it is equivalent to a plain dict.
+
+        TypedDict creates a dictionary type such that a type checker will expect all
+        instances to have a certain set of keys, where each key is
+        associated with a value of a consistent type. This expectation
+        is not checked at runtime.
+
+        Usage::
+
+            class Point2D(TypedDict):
+                x: int
+                y: int
+                label: str
+
+            a: Point2D = {'x': 1, 'y': 2, 'label': 'good'}  # OK
+            b: Point2D = {'z': 3, 'label': 'bad'}           # Fails type check
+
+            assert Point2D(x=1, y=2, label='first') == dict(x=1, y=2, label='first')
+
+        The type info can be accessed via the Point2D.__annotations__ dict, and
+        the Point2D.__required_keys__ and Point2D.__optional_keys__ frozensets.
+        TypedDict supports an additional equivalent form::
+
+            Point2D = TypedDict('Point2D', {'x': int, 'y': int, 'label': str})
+
+        By default, all keys must be present in a TypedDict. It is possible
+        to override this by specifying totality::
+
+            class Point2D(TypedDict, total=False):
+                x: int
+                y: int
+
+        This means that a Point2D TypedDict can have any of the keys omitted. A type
+        checker is only expected to support a literal False or True as the value of
+        the total argument. True is the default, and makes all items defined in the
+        class body be required.
+
+        The Required and NotRequired special forms can also be used to mark
+        individual keys as being required or not required::
+
+            class Point2D(TypedDict):
+                x: int  # the "x" key must always be present (Required is the default)
+                y: NotRequired[int]  # the "y" key can be omitted
+
+        See PEP 655 for more details on Required and NotRequired.
+        """
+        if fields is _marker or fields is None:
+            if fields is _marker:
+                deprecated_thing = "Failing to pass a value for the 'fields' parameter"
+            else:
+                deprecated_thing = "Passing `None` as the 'fields' parameter"
+
+            example = f"`{typename} = TypedDict({typename!r}, {{}})`"
+            deprecation_msg = (
+                f"{deprecated_thing} is deprecated and will be disallowed in "
+                "Python 3.15. To create a TypedDict class with 0 fields "
+                "using the functional syntax, pass an empty dictionary, e.g. "
+            ) + example + "."
+            warnings.warn(deprecation_msg, DeprecationWarning, stacklevel=2)
+            if closed is not False and closed is not True:
+                kwargs["closed"] = closed
+                closed = False
+            fields = kwargs
+        elif kwargs:
+            raise TypeError("TypedDict takes either a dict or keyword arguments,"
+                            " but not both")
+        if kwargs:
+            if sys.version_info >= (3, 13):
+                raise TypeError("TypedDict takes no keyword arguments")
+            warnings.warn(
+                "The kwargs-based syntax for TypedDict definitions is deprecated "
+                "in Python 3.11, will be removed in Python 3.13, and may not be "
+                "understood by third-party type checkers.",
+                DeprecationWarning,
+                stacklevel=2,
+            )
+
+        ns = {'__annotations__': dict(fields)}
+        module = _caller()
+        if module is not None:
+            # Setting correct module is necessary to make typed dict classes pickleable.
+            ns['__module__'] = module
+
+        td = _TypedDictMeta(typename, (), ns, total=total, closed=closed)
+        td.__orig_bases__ = (TypedDict,)
+        return td
+
+    if hasattr(typing, "_TypedDictMeta"):
+        _TYPEDDICT_TYPES = (typing._TypedDictMeta, _TypedDictMeta)
+    else:
+        _TYPEDDICT_TYPES = (_TypedDictMeta,)
+
+    def is_typeddict(tp):
+        """Check if an annotation is a TypedDict class
+
+        For example::
+            class Film(TypedDict):
+                title: str
+                year: int
+
+            is_typeddict(Film)  # => True
+            is_typeddict(Union[list, str])  # => False
+        """
+        # On 3.8, this would otherwise return True
+        if hasattr(typing, "TypedDict") and tp is typing.TypedDict:
+            return False
+        return isinstance(tp, _TYPEDDICT_TYPES)
+
+
+if hasattr(typing, "assert_type"):
+    assert_type = typing.assert_type
+
+else:
+    def assert_type(val, typ, /):
+        """Assert (to the type checker) that the value is of the given type.
+
+        When the type checker encounters a call to assert_type(), it
+        emits an error if the value is not of the specified type::
+
+            def greet(name: str) -> None:
+                assert_type(name, str)  # ok
+                assert_type(name, int)  # type checker error
+
+        At runtime this returns the first argument unchanged and otherwise
+        does nothing.
+        """
+        return val
+
+
+if hasattr(typing, "ReadOnly"):  # 3.13+
+    get_type_hints = typing.get_type_hints
+else:  # <=3.13
+    # replaces _strip_annotations()
+    def _strip_extras(t):
+        """Strips Annotated, Required and NotRequired from a given type."""
+        if isinstance(t, _AnnotatedAlias):
+            return _strip_extras(t.__origin__)
+        if hasattr(t, "__origin__") and t.__origin__ in (Required, NotRequired, ReadOnly):
+            return _strip_extras(t.__args__[0])
+        if isinstance(t, typing._GenericAlias):
+            stripped_args = tuple(_strip_extras(a) for a in t.__args__)
+            if stripped_args == t.__args__:
+                return t
+            return t.copy_with(stripped_args)
+        if hasattr(_types, "GenericAlias") and isinstance(t, _types.GenericAlias):
+            stripped_args = tuple(_strip_extras(a) for a in t.__args__)
+            if stripped_args == t.__args__:
+                return t
+            return _types.GenericAlias(t.__origin__, stripped_args)
+        if hasattr(_types, "UnionType") and isinstance(t, _types.UnionType):
+            stripped_args = tuple(_strip_extras(a) for a in t.__args__)
+            if stripped_args == t.__args__:
+                return t
+            return functools.reduce(operator.or_, stripped_args)
+
+        return t
+
+    def get_type_hints(obj, globalns=None, localns=None, include_extras=False):
+        """Return type hints for an object.
+
+        This is often the same as obj.__annotations__, but it handles
+        forward references encoded as string literals, adds Optional[t] if a
+        default value equal to None is set and recursively replaces all
+        'Annotated[T, ...]', 'Required[T]' or 'NotRequired[T]' with 'T'
+        (unless 'include_extras=True').
+
+        The argument may be a module, class, method, or function. The annotations
+        are returned as a dictionary. For classes, annotations include also
+        inherited members.
+
+        TypeError is raised if the argument is not of a type that can contain
+        annotations, and an empty dictionary is returned if no annotations are
+        present.
+
+        BEWARE -- the behavior of globalns and localns is counterintuitive
+        (unless you are familiar with how eval() and exec() work).  The
+        search order is locals first, then globals.
+
+        - If no dict arguments are passed, an attempt is made to use the
+          globals from obj (or the respective module's globals for classes),
+          and these are also used as the locals.  If the object does not appear
+          to have globals, an empty dictionary is used.
+
+        - If one dict argument is passed, it is used for both globals and
+          locals.
+
+        - If two dict arguments are passed, they specify globals and
+          locals, respectively.
+        """
+        if hasattr(typing, "Annotated"):  # 3.9+
+            hint = typing.get_type_hints(
+                obj, globalns=globalns, localns=localns, include_extras=True
+            )
+        else:  # 3.8
+            hint = typing.get_type_hints(obj, globalns=globalns, localns=localns)
+        if include_extras:
+            return hint
+        return {k: _strip_extras(t) for k, t in hint.items()}
+
+
+# Python 3.9+ has PEP 593 (Annotated)
+if hasattr(typing, 'Annotated'):
+    Annotated = typing.Annotated
+    # Not exported and not a public API, but needed for get_origin() and get_args()
+    # to work.
+    _AnnotatedAlias = typing._AnnotatedAlias
+# 3.8
+else:
+    class _AnnotatedAlias(typing._GenericAlias, _root=True):
+        """Runtime representation of an annotated type.
+
+        At its core 'Annotated[t, dec1, dec2, ...]' is an alias for the type 't'
+        with extra annotations. The alias behaves like a normal typing alias,
+        instantiating is the same as instantiating the underlying type, binding
+        it to types is also the same.
+        """
+        def __init__(self, origin, metadata):
+            if isinstance(origin, _AnnotatedAlias):
+                metadata = origin.__metadata__ + metadata
+                origin = origin.__origin__
+            super().__init__(origin, origin)
+            self.__metadata__ = metadata
+
+        def copy_with(self, params):
+            assert len(params) == 1
+            new_type = params[0]
+            return _AnnotatedAlias(new_type, self.__metadata__)
+
+        def __repr__(self):
+            return (f"typing_extensions.Annotated[{typing._type_repr(self.__origin__)}, "
+                    f"{', '.join(repr(a) for a in self.__metadata__)}]")
+
+        def __reduce__(self):
+            return operator.getitem, (
+                Annotated, (self.__origin__, *self.__metadata__)
+            )
+
+        def __eq__(self, other):
+            if not isinstance(other, _AnnotatedAlias):
+                return NotImplemented
+            if self.__origin__ != other.__origin__:
+                return False
+            return self.__metadata__ == other.__metadata__
+
+        def __hash__(self):
+            return hash((self.__origin__, self.__metadata__))
+
+    class Annotated:
+        """Add context specific metadata to a type.
+
+        Example: Annotated[int, runtime_check.Unsigned] indicates to the
+        hypothetical runtime_check module that this type is an unsigned int.
+        Every other consumer of this type can ignore this metadata and treat
+        this type as int.
+
+        The first argument to Annotated must be a valid type (and will be in
+        the __origin__ field), the remaining arguments are kept as a tuple in
+        the __extra__ field.
+
+        Details:
+
+        - It's an error to call `Annotated` with less than two arguments.
+        - Nested Annotated are flattened::
+
+            Annotated[Annotated[T, Ann1, Ann2], Ann3] == Annotated[T, Ann1, Ann2, Ann3]
+
+        - Instantiating an annotated type is equivalent to instantiating the
+        underlying type::
+
+            Annotated[C, Ann1](5) == C(5)
+
+        - Annotated can be used as a generic type alias::
+
+            Optimized = Annotated[T, runtime.Optimize()]
+            Optimized[int] == Annotated[int, runtime.Optimize()]
+
+            OptimizedList = Annotated[List[T], runtime.Optimize()]
+            OptimizedList[int] == Annotated[List[int], runtime.Optimize()]
+        """
+
+        __slots__ = ()
+
+        def __new__(cls, *args, **kwargs):
+            raise TypeError("Type Annotated cannot be instantiated.")
+
+        @typing._tp_cache
+        def __class_getitem__(cls, params):
+            if not isinstance(params, tuple) or len(params) < 2:
+                raise TypeError("Annotated[...] should be used "
+                                "with at least two arguments (a type and an "
+                                "annotation).")
+            allowed_special_forms = (ClassVar, Final)
+            if get_origin(params[0]) in allowed_special_forms:
+                origin = params[0]
+            else:
+                msg = "Annotated[t, ...]: t must be a type."
+                origin = typing._type_check(params[0], msg)
+            metadata = tuple(params[1:])
+            return _AnnotatedAlias(origin, metadata)
+
+        def __init_subclass__(cls, *args, **kwargs):
+            raise TypeError(
+                f"Cannot subclass {cls.__module__}.Annotated"
+            )
+
+# Python 3.8 has get_origin() and get_args() but those implementations aren't
+# Annotated-aware, so we can't use those. Python 3.9's versions don't support
+# ParamSpecArgs and ParamSpecKwargs, so only Python 3.10's versions will do.
+if sys.version_info[:2] >= (3, 10):
+    get_origin = typing.get_origin
+    get_args = typing.get_args
+# 3.8-3.9
+else:
+    try:
+        # 3.9+
+        from typing import _BaseGenericAlias
+    except ImportError:
+        _BaseGenericAlias = typing._GenericAlias
+    try:
+        # 3.9+
+        from typing import GenericAlias as _typing_GenericAlias
+    except ImportError:
+        _typing_GenericAlias = typing._GenericAlias
+
+    def get_origin(tp):
+        """Get the unsubscripted version of a type.
+
+        This supports generic types, Callable, Tuple, Union, Literal, Final, ClassVar
+        and Annotated. Return None for unsupported types. Examples::
+
+            get_origin(Literal[42]) is Literal
+            get_origin(int) is None
+            get_origin(ClassVar[int]) is ClassVar
+            get_origin(Generic) is Generic
+            get_origin(Generic[T]) is Generic
+            get_origin(Union[T, int]) is Union
+            get_origin(List[Tuple[T, T]][int]) == list
+            get_origin(P.args) is P
+        """
+        if isinstance(tp, _AnnotatedAlias):
+            return Annotated
+        if isinstance(tp, (typing._GenericAlias, _typing_GenericAlias, _BaseGenericAlias,
+                           ParamSpecArgs, ParamSpecKwargs)):
+            return tp.__origin__
+        if tp is typing.Generic:
+            return typing.Generic
+        return None
+
+    def get_args(tp):
+        """Get type arguments with all substitutions performed.
+
+        For unions, basic simplifications used by Union constructor are performed.
+        Examples::
+            get_args(Dict[str, int]) == (str, int)
+            get_args(int) == ()
+            get_args(Union[int, Union[T, int], str][int]) == (int, str)
+            get_args(Union[int, Tuple[T, int]][str]) == (int, Tuple[str, int])
+            get_args(Callable[[], T][int]) == ([], int)
+        """
+        if isinstance(tp, _AnnotatedAlias):
+            return (tp.__origin__, *tp.__metadata__)
+        if isinstance(tp, (typing._GenericAlias, _typing_GenericAlias)):
+            if getattr(tp, "_special", False):
+                return ()
+            res = tp.__args__
+            if get_origin(tp) is collections.abc.Callable and res[0] is not Ellipsis:
+                res = (list(res[:-1]), res[-1])
+            return res
+        return ()
+
+
+# 3.10+
+if hasattr(typing, 'TypeAlias'):
+    TypeAlias = typing.TypeAlias
+# 3.9
+elif sys.version_info[:2] >= (3, 9):
+    @_ExtensionsSpecialForm
+    def TypeAlias(self, parameters):
+        """Special marker indicating that an assignment should
+        be recognized as a proper type alias definition by type
+        checkers.
+
+        For example::
+
+            Predicate: TypeAlias = Callable[..., bool]
+
+        It's invalid when used anywhere except as in the example above.
+        """
+        raise TypeError(f"{self} is not subscriptable")
+# 3.8
+else:
+    TypeAlias = _ExtensionsSpecialForm(
+        'TypeAlias',
+        doc="""Special marker indicating that an assignment should
+        be recognized as a proper type alias definition by type
+        checkers.
+
+        For example::
+
+            Predicate: TypeAlias = Callable[..., bool]
+
+        It's invalid when used anywhere except as in the example
+        above."""
+    )
+
+
+if hasattr(typing, "NoDefault"):
+    NoDefault = typing.NoDefault
+else:
+    class NoDefaultTypeMeta(type):
+        def __setattr__(cls, attr, value):
+            # TypeError is consistent with the behavior of NoneType
+            raise TypeError(
+                f"cannot set {attr!r} attribute of immutable type {cls.__name__!r}"
+            )
+
+    class NoDefaultType(metaclass=NoDefaultTypeMeta):
+        """The type of the NoDefault singleton."""
+
+        __slots__ = ()
+
+        def __new__(cls):
+            return globals().get("NoDefault") or object.__new__(cls)
+
+        def __repr__(self):
+            return "typing_extensions.NoDefault"
+
+        def __reduce__(self):
+            return "NoDefault"
+
+    NoDefault = NoDefaultType()
+    del NoDefaultType, NoDefaultTypeMeta
+
+
+def _set_default(type_param, default):
+    type_param.has_default = lambda: default is not NoDefault
+    type_param.__default__ = default
+
+
+def _set_module(typevarlike):
+    # for pickling:
+    def_mod = _caller(depth=3)
+    if def_mod != 'typing_extensions':
+        typevarlike.__module__ = def_mod
+
+
+class _DefaultMixin:
+    """Mixin for TypeVarLike defaults."""
+
+    __slots__ = ()
+    __init__ = _set_default
+
+
+# Classes using this metaclass must provide a _backported_typevarlike ClassVar
+class _TypeVarLikeMeta(type):
+    def __instancecheck__(cls, __instance: Any) -> bool:
+        return isinstance(__instance, cls._backported_typevarlike)
+
+
+if _PEP_696_IMPLEMENTED:
+    from typing import TypeVar
+else:
+    # Add default and infer_variance parameters from PEP 696 and 695
+    class TypeVar(metaclass=_TypeVarLikeMeta):
+        """Type variable."""
+
+        _backported_typevarlike = typing.TypeVar
+
+        def __new__(cls, name, *constraints, bound=None,
+                    covariant=False, contravariant=False,
+                    default=NoDefault, infer_variance=False):
+            if hasattr(typing, "TypeAliasType"):
+                # PEP 695 implemented (3.12+), can pass infer_variance to typing.TypeVar
+                typevar = typing.TypeVar(name, *constraints, bound=bound,
+                                         covariant=covariant, contravariant=contravariant,
+                                         infer_variance=infer_variance)
+            else:
+                typevar = typing.TypeVar(name, *constraints, bound=bound,
+                                         covariant=covariant, contravariant=contravariant)
+                if infer_variance and (covariant or contravariant):
+                    raise ValueError("Variance cannot be specified with infer_variance.")
+                typevar.__infer_variance__ = infer_variance
+
+            _set_default(typevar, default)
+            _set_module(typevar)
+
+            def _tvar_prepare_subst(alias, args):
+                if (
+                    typevar.has_default()
+                    and alias.__parameters__.index(typevar) == len(args)
+                ):
+                    args += (typevar.__default__,)
+                return args
+
+            typevar.__typing_prepare_subst__ = _tvar_prepare_subst
+            return typevar
+
+        def __init_subclass__(cls) -> None:
+            raise TypeError(f"type '{__name__}.TypeVar' is not an acceptable base type")
+
+
+# Python 3.10+ has PEP 612
+if hasattr(typing, 'ParamSpecArgs'):
+    ParamSpecArgs = typing.ParamSpecArgs
+    ParamSpecKwargs = typing.ParamSpecKwargs
+# 3.8-3.9
+else:
+    class _Immutable:
+        """Mixin to indicate that object should not be copied."""
+        __slots__ = ()
+
+        def __copy__(self):
+            return self
+
+        def __deepcopy__(self, memo):
+            return self
+
+    class ParamSpecArgs(_Immutable):
+        """The args for a ParamSpec object.
+
+        Given a ParamSpec object P, P.args is an instance of ParamSpecArgs.
+
+        ParamSpecArgs objects have a reference back to their ParamSpec:
+
+        P.args.__origin__ is P
+
+        This type is meant for runtime introspection and has no special meaning to
+        static type checkers.
+        """
+        def __init__(self, origin):
+            self.__origin__ = origin
+
+        def __repr__(self):
+            return f"{self.__origin__.__name__}.args"
+
+        def __eq__(self, other):
+            if not isinstance(other, ParamSpecArgs):
+                return NotImplemented
+            return self.__origin__ == other.__origin__
+
+    class ParamSpecKwargs(_Immutable):
+        """The kwargs for a ParamSpec object.
+
+        Given a ParamSpec object P, P.kwargs is an instance of ParamSpecKwargs.
+
+        ParamSpecKwargs objects have a reference back to their ParamSpec:
+
+        P.kwargs.__origin__ is P
+
+        This type is meant for runtime introspection and has no special meaning to
+        static type checkers.
+        """
+        def __init__(self, origin):
+            self.__origin__ = origin
+
+        def __repr__(self):
+            return f"{self.__origin__.__name__}.kwargs"
+
+        def __eq__(self, other):
+            if not isinstance(other, ParamSpecKwargs):
+                return NotImplemented
+            return self.__origin__ == other.__origin__
+
+
+if _PEP_696_IMPLEMENTED:
+    from typing import ParamSpec
+
+# 3.10+
+elif hasattr(typing, 'ParamSpec'):
+
+    # Add default parameter - PEP 696
+    class ParamSpec(metaclass=_TypeVarLikeMeta):
+        """Parameter specification."""
+
+        _backported_typevarlike = typing.ParamSpec
+
+        def __new__(cls, name, *, bound=None,
+                    covariant=False, contravariant=False,
+                    infer_variance=False, default=NoDefault):
+            if hasattr(typing, "TypeAliasType"):
+                # PEP 695 implemented, can pass infer_variance to typing.TypeVar
+                paramspec = typing.ParamSpec(name, bound=bound,
+                                             covariant=covariant,
+                                             contravariant=contravariant,
+                                             infer_variance=infer_variance)
+            else:
+                paramspec = typing.ParamSpec(name, bound=bound,
+                                             covariant=covariant,
+                                             contravariant=contravariant)
+                paramspec.__infer_variance__ = infer_variance
+
+            _set_default(paramspec, default)
+            _set_module(paramspec)
+
+            def _paramspec_prepare_subst(alias, args):
+                params = alias.__parameters__
+                i = params.index(paramspec)
+                if i == len(args) and paramspec.has_default():
+                    args = [*args, paramspec.__default__]
+                if i >= len(args):
+                    raise TypeError(f"Too few arguments for {alias}")
+                # Special case where Z[[int, str, bool]] == Z[int, str, bool] in PEP 612.
+                if len(params) == 1 and not typing._is_param_expr(args[0]):
+                    assert i == 0
+                    args = (args,)
+                # Convert lists to tuples to help other libraries cache the results.
+                elif isinstance(args[i], list):
+                    args = (*args[:i], tuple(args[i]), *args[i + 1:])
+                return args
+
+            paramspec.__typing_prepare_subst__ = _paramspec_prepare_subst
+            return paramspec
+
+        def __init_subclass__(cls) -> None:
+            raise TypeError(f"type '{__name__}.ParamSpec' is not an acceptable base type")
+
+# 3.8-3.9
+else:
+
+    # Inherits from list as a workaround for Callable checks in Python < 3.9.2.
+    class ParamSpec(list, _DefaultMixin):
+        """Parameter specification variable.
+
+        Usage::
+
+           P = ParamSpec('P')
+
+        Parameter specification variables exist primarily for the benefit of static
+        type checkers.  They are used to forward the parameter types of one
+        callable to another callable, a pattern commonly found in higher order
+        functions and decorators.  They are only valid when used in ``Concatenate``,
+        or s the first argument to ``Callable``. In Python 3.10 and higher,
+        they are also supported in user-defined Generics at runtime.
+        See class Generic for more information on generic types.  An
+        example for annotating a decorator::
+
+           T = TypeVar('T')
+           P = ParamSpec('P')
+
+           def add_logging(f: Callable[P, T]) -> Callable[P, T]:
+               '''A type-safe decorator to add logging to a function.'''
+               def inner(*args: P.args, **kwargs: P.kwargs) -> T:
+                   logging.info(f'{f.__name__} was called')
+                   return f(*args, **kwargs)
+               return inner
+
+           @add_logging
+           def add_two(x: float, y: float) -> float:
+               '''Add two numbers together.'''
+               return x + y
+
+        Parameter specification variables defined with covariant=True or
+        contravariant=True can be used to declare covariant or contravariant
+        generic types.  These keyword arguments are valid, but their actual semantics
+        are yet to be decided.  See PEP 612 for details.
+
+        Parameter specification variables can be introspected. e.g.:
+
+           P.__name__ == 'T'
+           P.__bound__ == None
+           P.__covariant__ == False
+           P.__contravariant__ == False
+
+        Note that only parameter specification variables defined in global scope can
+        be pickled.
+        """
+
+        # Trick Generic __parameters__.
+        __class__ = typing.TypeVar
+
+        @property
+        def args(self):
+            return ParamSpecArgs(self)
+
+        @property
+        def kwargs(self):
+            return ParamSpecKwargs(self)
+
+        def __init__(self, name, *, bound=None, covariant=False, contravariant=False,
+                     infer_variance=False, default=NoDefault):
+            list.__init__(self, [self])
+            self.__name__ = name
+            self.__covariant__ = bool(covariant)
+            self.__contravariant__ = bool(contravariant)
+            self.__infer_variance__ = bool(infer_variance)
+            if bound:
+                self.__bound__ = typing._type_check(bound, 'Bound must be a type.')
+            else:
+                self.__bound__ = None
+            _DefaultMixin.__init__(self, default)
+
+            # for pickling:
+            def_mod = _caller()
+            if def_mod != 'typing_extensions':
+                self.__module__ = def_mod
+
+        def __repr__(self):
+            if self.__infer_variance__:
+                prefix = ''
+            elif self.__covariant__:
+                prefix = '+'
+            elif self.__contravariant__:
+                prefix = '-'
+            else:
+                prefix = '~'
+            return prefix + self.__name__
+
+        def __hash__(self):
+            return object.__hash__(self)
+
+        def __eq__(self, other):
+            return self is other
+
+        def __reduce__(self):
+            return self.__name__
+
+        # Hack to get typing._type_check to pass.
+        def __call__(self, *args, **kwargs):
+            pass
+
+
+# 3.8-3.9
+if not hasattr(typing, 'Concatenate'):
+    # Inherits from list as a workaround for Callable checks in Python < 3.9.2.
+    class _ConcatenateGenericAlias(list):
+
+        # Trick Generic into looking into this for __parameters__.
+        __class__ = typing._GenericAlias
+
+        # Flag in 3.8.
+        _special = False
+
+        def __init__(self, origin, args):
+            super().__init__(args)
+            self.__origin__ = origin
+            self.__args__ = args
+
+        def __repr__(self):
+            _type_repr = typing._type_repr
+            return (f'{_type_repr(self.__origin__)}'
+                    f'[{", ".join(_type_repr(arg) for arg in self.__args__)}]')
+
+        def __hash__(self):
+            return hash((self.__origin__, self.__args__))
+
+        # Hack to get typing._type_check to pass in Generic.
+        def __call__(self, *args, **kwargs):
+            pass
+
+        @property
+        def __parameters__(self):
+            return tuple(
+                tp for tp in self.__args__ if isinstance(tp, (typing.TypeVar, ParamSpec))
+            )
+
+
+# 3.8-3.9
+@typing._tp_cache
+def _concatenate_getitem(self, parameters):
+    if parameters == ():
+        raise TypeError("Cannot take a Concatenate of no types.")
+    if not isinstance(parameters, tuple):
+        parameters = (parameters,)
+    if not isinstance(parameters[-1], ParamSpec):
+        raise TypeError("The last parameter to Concatenate should be a "
+                        "ParamSpec variable.")
+    msg = "Concatenate[arg, ...]: each arg must be a type."
+    parameters = tuple(typing._type_check(p, msg) for p in parameters)
+    return _ConcatenateGenericAlias(self, parameters)
+
+
+# 3.10+
+if hasattr(typing, 'Concatenate'):
+    Concatenate = typing.Concatenate
+    _ConcatenateGenericAlias = typing._ConcatenateGenericAlias
+# 3.9
+elif sys.version_info[:2] >= (3, 9):
+    @_ExtensionsSpecialForm
+    def Concatenate(self, parameters):
+        """Used in conjunction with ``ParamSpec`` and ``Callable`` to represent a
+        higher order function which adds, removes or transforms parameters of a
+        callable.
+
+        For example::
+
+           Callable[Concatenate[int, P], int]
+
+        See PEP 612 for detailed information.
+        """
+        return _concatenate_getitem(self, parameters)
+# 3.8
+else:
+    class _ConcatenateForm(_ExtensionsSpecialForm, _root=True):
+        def __getitem__(self, parameters):
+            return _concatenate_getitem(self, parameters)
+
+    Concatenate = _ConcatenateForm(
+        'Concatenate',
+        doc="""Used in conjunction with ``ParamSpec`` and ``Callable`` to represent a
+        higher order function which adds, removes or transforms parameters of a
+        callable.
+
+        For example::
+
+           Callable[Concatenate[int, P], int]
+
+        See PEP 612 for detailed information.
+        """)
+
+# 3.10+
+if hasattr(typing, 'TypeGuard'):
+    TypeGuard = typing.TypeGuard
+# 3.9
+elif sys.version_info[:2] >= (3, 9):
+    @_ExtensionsSpecialForm
+    def TypeGuard(self, parameters):
+        """Special typing form used to annotate the return type of a user-defined
+        type guard function.  ``TypeGuard`` only accepts a single type argument.
+        At runtime, functions marked this way should return a boolean.
+
+        ``TypeGuard`` aims to benefit *type narrowing* -- a technique used by static
+        type checkers to determine a more precise type of an expression within a
+        program's code flow.  Usually type narrowing is done by analyzing
+        conditional code flow and applying the narrowing to a block of code.  The
+        conditional expression here is sometimes referred to as a "type guard".
+
+        Sometimes it would be convenient to use a user-defined boolean function
+        as a type guard.  Such a function should use ``TypeGuard[...]`` as its
+        return type to alert static type checkers to this intention.
+
+        Using  ``-> TypeGuard`` tells the static type checker that for a given
+        function:
+
+        1. The return value is a boolean.
+        2. If the return value is ``True``, the type of its argument
+        is the type inside ``TypeGuard``.
+
+        For example::
+
+            def is_str(val: Union[str, float]):
+                # "isinstance" type guard
+                if isinstance(val, str):
+                    # Type of ``val`` is narrowed to ``str``
+                    ...
+                else:
+                    # Else, type of ``val`` is narrowed to ``float``.
+                    ...
+
+        Strict type narrowing is not enforced -- ``TypeB`` need not be a narrower
+        form of ``TypeA`` (it can even be a wider form) and this may lead to
+        type-unsafe results.  The main reason is to allow for things like
+        narrowing ``List[object]`` to ``List[str]`` even though the latter is not
+        a subtype of the former, since ``List`` is invariant.  The responsibility of
+        writing type-safe type guards is left to the user.
+
+        ``TypeGuard`` also works with type variables.  For more information, see
+        PEP 647 (User-Defined Type Guards).
+        """
+        item = typing._type_check(parameters, f'{self} accepts only a single type.')
+        return typing._GenericAlias(self, (item,))
+# 3.8
+else:
+    class _TypeGuardForm(_ExtensionsSpecialForm, _root=True):
+        def __getitem__(self, parameters):
+            item = typing._type_check(parameters,
+                                      f'{self._name} accepts only a single type')
+            return typing._GenericAlias(self, (item,))
+
+    TypeGuard = _TypeGuardForm(
+        'TypeGuard',
+        doc="""Special typing form used to annotate the return type of a user-defined
+        type guard function.  ``TypeGuard`` only accepts a single type argument.
+        At runtime, functions marked this way should return a boolean.
+
+        ``TypeGuard`` aims to benefit *type narrowing* -- a technique used by static
+        type checkers to determine a more precise type of an expression within a
+        program's code flow.  Usually type narrowing is done by analyzing
+        conditional code flow and applying the narrowing to a block of code.  The
+        conditional expression here is sometimes referred to as a "type guard".
+
+        Sometimes it would be convenient to use a user-defined boolean function
+        as a type guard.  Such a function should use ``TypeGuard[...]`` as its
+        return type to alert static type checkers to this intention.
+
+        Using  ``-> TypeGuard`` tells the static type checker that for a given
+        function:
+
+        1. The return value is a boolean.
+        2. If the return value is ``True``, the type of its argument
+        is the type inside ``TypeGuard``.
+
+        For example::
+
+            def is_str(val: Union[str, float]):
+                # "isinstance" type guard
+                if isinstance(val, str):
+                    # Type of ``val`` is narrowed to ``str``
+                    ...
+                else:
+                    # Else, type of ``val`` is narrowed to ``float``.
+                    ...
+
+        Strict type narrowing is not enforced -- ``TypeB`` need not be a narrower
+        form of ``TypeA`` (it can even be a wider form) and this may lead to
+        type-unsafe results.  The main reason is to allow for things like
+        narrowing ``List[object]`` to ``List[str]`` even though the latter is not
+        a subtype of the former, since ``List`` is invariant.  The responsibility of
+        writing type-safe type guards is left to the user.
+
+        ``TypeGuard`` also works with type variables.  For more information, see
+        PEP 647 (User-Defined Type Guards).
+        """)
+
+# 3.13+
+if hasattr(typing, 'TypeIs'):
+    TypeIs = typing.TypeIs
+# 3.9
+elif sys.version_info[:2] >= (3, 9):
+    @_ExtensionsSpecialForm
+    def TypeIs(self, parameters):
+        """Special typing form used to annotate the return type of a user-defined
+        type narrower function.  ``TypeIs`` only accepts a single type argument.
+        At runtime, functions marked this way should return a boolean.
+
+        ``TypeIs`` aims to benefit *type narrowing* -- a technique used by static
+        type checkers to determine a more precise type of an expression within a
+        program's code flow.  Usually type narrowing is done by analyzing
+        conditional code flow and applying the narrowing to a block of code.  The
+        conditional expression here is sometimes referred to as a "type guard".
+
+        Sometimes it would be convenient to use a user-defined boolean function
+        as a type guard.  Such a function should use ``TypeIs[...]`` as its
+        return type to alert static type checkers to this intention.
+
+        Using  ``-> TypeIs`` tells the static type checker that for a given
+        function:
+
+        1. The return value is a boolean.
+        2. If the return value is ``True``, the type of its argument
+        is the intersection of the type inside ``TypeGuard`` and the argument's
+        previously known type.
+
+        For example::
+
+            def is_awaitable(val: object) -> TypeIs[Awaitable[Any]]:
+                return hasattr(val, '__await__')
+
+            def f(val: Union[int, Awaitable[int]]) -> int:
+                if is_awaitable(val):
+                    assert_type(val, Awaitable[int])
+                else:
+                    assert_type(val, int)
+
+        ``TypeIs`` also works with type variables.  For more information, see
+        PEP 742 (Narrowing types with TypeIs).
+        """
+        item = typing._type_check(parameters, f'{self} accepts only a single type.')
+        return typing._GenericAlias(self, (item,))
+# 3.8
+else:
+    class _TypeIsForm(_ExtensionsSpecialForm, _root=True):
+        def __getitem__(self, parameters):
+            item = typing._type_check(parameters,
+                                      f'{self._name} accepts only a single type')
+            return typing._GenericAlias(self, (item,))
+
+    TypeIs = _TypeIsForm(
+        'TypeIs',
+        doc="""Special typing form used to annotate the return type of a user-defined
+        type narrower function.  ``TypeIs`` only accepts a single type argument.
+        At runtime, functions marked this way should return a boolean.
+
+        ``TypeIs`` aims to benefit *type narrowing* -- a technique used by static
+        type checkers to determine a more precise type of an expression within a
+        program's code flow.  Usually type narrowing is done by analyzing
+        conditional code flow and applying the narrowing to a block of code.  The
+        conditional expression here is sometimes referred to as a "type guard".
+
+        Sometimes it would be convenient to use a user-defined boolean function
+        as a type guard.  Such a function should use ``TypeIs[...]`` as its
+        return type to alert static type checkers to this intention.
+
+        Using  ``-> TypeIs`` tells the static type checker that for a given
+        function:
+
+        1. The return value is a boolean.
+        2. If the return value is ``True``, the type of its argument
+        is the intersection of the type inside ``TypeGuard`` and the argument's
+        previously known type.
+
+        For example::
+
+            def is_awaitable(val: object) -> TypeIs[Awaitable[Any]]:
+                return hasattr(val, '__await__')
+
+            def f(val: Union[int, Awaitable[int]]) -> int:
+                if is_awaitable(val):
+                    assert_type(val, Awaitable[int])
+                else:
+                    assert_type(val, int)
+
+        ``TypeIs`` also works with type variables.  For more information, see
+        PEP 742 (Narrowing types with TypeIs).
+        """)
+
+
+# Vendored from cpython typing._SpecialFrom
+class _SpecialForm(typing._Final, _root=True):
+    __slots__ = ('_name', '__doc__', '_getitem')
+
+    def __init__(self, getitem):
+        self._getitem = getitem
+        self._name = getitem.__name__
+        self.__doc__ = getitem.__doc__
+
+    def __getattr__(self, item):
+        if item in {'__name__', '__qualname__'}:
+            return self._name
+
+        raise AttributeError(item)
+
+    def __mro_entries__(self, bases):
+        raise TypeError(f"Cannot subclass {self!r}")
+
+    def __repr__(self):
+        return f'typing_extensions.{self._name}'
+
+    def __reduce__(self):
+        return self._name
+
+    def __call__(self, *args, **kwds):
+        raise TypeError(f"Cannot instantiate {self!r}")
+
+    def __or__(self, other):
+        return typing.Union[self, other]
+
+    def __ror__(self, other):
+        return typing.Union[other, self]
+
+    def __instancecheck__(self, obj):
+        raise TypeError(f"{self} cannot be used with isinstance()")
+
+    def __subclasscheck__(self, cls):
+        raise TypeError(f"{self} cannot be used with issubclass()")
+
+    @typing._tp_cache
+    def __getitem__(self, parameters):
+        return self._getitem(self, parameters)
+
+
+if hasattr(typing, "LiteralString"):  # 3.11+
+    LiteralString = typing.LiteralString
+else:
+    @_SpecialForm
+    def LiteralString(self, params):
+        """Represents an arbitrary literal string.
+
+        Example::
+
+          from typing_extensions import LiteralString
+
+          def query(sql: LiteralString) -> ...:
+              ...
+
+          query("SELECT * FROM table")  # ok
+          query(f"SELECT * FROM {input()}")  # not ok
+
+        See PEP 675 for details.
+
+        """
+        raise TypeError(f"{self} is not subscriptable")
+
+
+if hasattr(typing, "Self"):  # 3.11+
+    Self = typing.Self
+else:
+    @_SpecialForm
+    def Self(self, params):
+        """Used to spell the type of "self" in classes.
+
+        Example::
+
+          from typing import Self
+
+          class ReturnsSelf:
+              def parse(self, data: bytes) -> Self:
+                  ...
+                  return self
+
+        """
+
+        raise TypeError(f"{self} is not subscriptable")
+
+
+if hasattr(typing, "Never"):  # 3.11+
+    Never = typing.Never
+else:
+    @_SpecialForm
+    def Never(self, params):
+        """The bottom type, a type that has no members.
+
+        This can be used to define a function that should never be
+        called, or a function that never returns::
+
+            from typing_extensions import Never
+
+            def never_call_me(arg: Never) -> None:
+                pass
+
+            def int_or_str(arg: int | str) -> None:
+                never_call_me(arg)  # type checker error
+                match arg:
+                    case int():
+                        print("It's an int")
+                    case str():
+                        print("It's a str")
+                    case _:
+                        never_call_me(arg)  # ok, arg is of type Never
+
+        """
+
+        raise TypeError(f"{self} is not subscriptable")
+
+
+if hasattr(typing, 'Required'):  # 3.11+
+    Required = typing.Required
+    NotRequired = typing.NotRequired
+elif sys.version_info[:2] >= (3, 9):  # 3.9-3.10
+    @_ExtensionsSpecialForm
+    def Required(self, parameters):
+        """A special typing construct to mark a key of a total=False TypedDict
+        as required. For example:
+
+            class Movie(TypedDict, total=False):
+                title: Required[str]
+                year: int
+
+            m = Movie(
+                title='The Matrix',  # typechecker error if key is omitted
+                year=1999,
+            )
+
+        There is no runtime checking that a required key is actually provided
+        when instantiating a related TypedDict.
+        """
+        item = typing._type_check(parameters, f'{self._name} accepts only a single type.')
+        return typing._GenericAlias(self, (item,))
+
+    @_ExtensionsSpecialForm
+    def NotRequired(self, parameters):
+        """A special typing construct to mark a key of a TypedDict as
+        potentially missing. For example:
+
+            class Movie(TypedDict):
+                title: str
+                year: NotRequired[int]
+
+            m = Movie(
+                title='The Matrix',  # typechecker error if key is omitted
+                year=1999,
+            )
+        """
+        item = typing._type_check(parameters, f'{self._name} accepts only a single type.')
+        return typing._GenericAlias(self, (item,))
+
+else:  # 3.8
+    class _RequiredForm(_ExtensionsSpecialForm, _root=True):
+        def __getitem__(self, parameters):
+            item = typing._type_check(parameters,
+                                      f'{self._name} accepts only a single type.')
+            return typing._GenericAlias(self, (item,))
+
+    Required = _RequiredForm(
+        'Required',
+        doc="""A special typing construct to mark a key of a total=False TypedDict
+        as required. For example:
+
+            class Movie(TypedDict, total=False):
+                title: Required[str]
+                year: int
+
+            m = Movie(
+                title='The Matrix',  # typechecker error if key is omitted
+                year=1999,
+            )
+
+        There is no runtime checking that a required key is actually provided
+        when instantiating a related TypedDict.
+        """)
+    NotRequired = _RequiredForm(
+        'NotRequired',
+        doc="""A special typing construct to mark a key of a TypedDict as
+        potentially missing. For example:
+
+            class Movie(TypedDict):
+                title: str
+                year: NotRequired[int]
+
+            m = Movie(
+                title='The Matrix',  # typechecker error if key is omitted
+                year=1999,
+            )
+        """)
+
+
+if hasattr(typing, 'ReadOnly'):
+    ReadOnly = typing.ReadOnly
+elif sys.version_info[:2] >= (3, 9):  # 3.9-3.12
+    @_ExtensionsSpecialForm
+    def ReadOnly(self, parameters):
+        """A special typing construct to mark an item of a TypedDict as read-only.
+
+        For example:
+
+            class Movie(TypedDict):
+                title: ReadOnly[str]
+                year: int
+
+            def mutate_movie(m: Movie) -> None:
+                m["year"] = 1992  # allowed
+                m["title"] = "The Matrix"  # typechecker error
+
+        There is no runtime checking for this property.
+        """
+        item = typing._type_check(parameters, f'{self._name} accepts only a single type.')
+        return typing._GenericAlias(self, (item,))
+
+else:  # 3.8
+    class _ReadOnlyForm(_ExtensionsSpecialForm, _root=True):
+        def __getitem__(self, parameters):
+            item = typing._type_check(parameters,
+                                      f'{self._name} accepts only a single type.')
+            return typing._GenericAlias(self, (item,))
+
+    ReadOnly = _ReadOnlyForm(
+        'ReadOnly',
+        doc="""A special typing construct to mark a key of a TypedDict as read-only.
+
+        For example:
+
+            class Movie(TypedDict):
+                title: ReadOnly[str]
+                year: int
+
+            def mutate_movie(m: Movie) -> None:
+                m["year"] = 1992  # allowed
+                m["title"] = "The Matrix"  # typechecker error
+
+        There is no runtime checking for this propery.
+        """)
+
+
+_UNPACK_DOC = """\
+Type unpack operator.
+
+The type unpack operator takes the child types from some container type,
+such as `tuple[int, str]` or a `TypeVarTuple`, and 'pulls them out'. For
+example:
+
+  # For some generic class `Foo`:
+  Foo[Unpack[tuple[int, str]]]  # Equivalent to Foo[int, str]
+
+  Ts = TypeVarTuple('Ts')
+  # Specifies that `Bar` is generic in an arbitrary number of types.
+  # (Think of `Ts` as a tuple of an arbitrary number of individual
+  #  `TypeVar`s, which the `Unpack` is 'pulling out' directly into the
+  #  `Generic[]`.)
+  class Bar(Generic[Unpack[Ts]]): ...
+  Bar[int]  # Valid
+  Bar[int, str]  # Also valid
+
+From Python 3.11, this can also be done using the `*` operator:
+
+    Foo[*tuple[int, str]]
+    class Bar(Generic[*Ts]): ...
+
+The operator can also be used along with a `TypedDict` to annotate
+`**kwargs` in a function signature. For instance:
+
+  class Movie(TypedDict):
+    name: str
+    year: int
+
+  # This function expects two keyword arguments - *name* of type `str` and
+  # *year* of type `int`.
+  def foo(**kwargs: Unpack[Movie]): ...
+
+Note that there is only some runtime checking of this operator. Not
+everything the runtime allows may be accepted by static type checkers.
+
+For more information, see PEP 646 and PEP 692.
+"""
+
+
+if sys.version_info >= (3, 12):  # PEP 692 changed the repr of Unpack[]
+    Unpack = typing.Unpack
+
+    def _is_unpack(obj):
+        return get_origin(obj) is Unpack
+
+elif sys.version_info[:2] >= (3, 9):  # 3.9+
+    class _UnpackSpecialForm(_ExtensionsSpecialForm, _root=True):
+        def __init__(self, getitem):
+            super().__init__(getitem)
+            self.__doc__ = _UNPACK_DOC
+
+    class _UnpackAlias(typing._GenericAlias, _root=True):
+        __class__ = typing.TypeVar
+
+        @property
+        def __typing_unpacked_tuple_args__(self):
+            assert self.__origin__ is Unpack
+            assert len(self.__args__) == 1
+            arg, = self.__args__
+            if isinstance(arg, (typing._GenericAlias, _types.GenericAlias)):
+                if arg.__origin__ is not tuple:
+                    raise TypeError("Unpack[...] must be used with a tuple type")
+                return arg.__args__
+            return None
+
+    @_UnpackSpecialForm
+    def Unpack(self, parameters):
+        item = typing._type_check(parameters, f'{self._name} accepts only a single type.')
+        return _UnpackAlias(self, (item,))
+
+    def _is_unpack(obj):
+        return isinstance(obj, _UnpackAlias)
+
+else:  # 3.8
+    class _UnpackAlias(typing._GenericAlias, _root=True):
+        __class__ = typing.TypeVar
+
+    class _UnpackForm(_ExtensionsSpecialForm, _root=True):
+        def __getitem__(self, parameters):
+            item = typing._type_check(parameters,
+                                      f'{self._name} accepts only a single type.')
+            return _UnpackAlias(self, (item,))
+
+    Unpack = _UnpackForm('Unpack', doc=_UNPACK_DOC)
+
+    def _is_unpack(obj):
+        return isinstance(obj, _UnpackAlias)
+
+
+if _PEP_696_IMPLEMENTED:
+    from typing import TypeVarTuple
+
+elif hasattr(typing, "TypeVarTuple"):  # 3.11+
+
+    def _unpack_args(*args):
+        newargs = []
+        for arg in args:
+            subargs = getattr(arg, '__typing_unpacked_tuple_args__', None)
+            if subargs is not None and not (subargs and subargs[-1] is ...):
+                newargs.extend(subargs)
+            else:
+                newargs.append(arg)
+        return newargs
+
+    # Add default parameter - PEP 696
+    class TypeVarTuple(metaclass=_TypeVarLikeMeta):
+        """Type variable tuple."""
+
+        _backported_typevarlike = typing.TypeVarTuple
+
+        def __new__(cls, name, *, default=NoDefault):
+            tvt = typing.TypeVarTuple(name)
+            _set_default(tvt, default)
+            _set_module(tvt)
+
+            def _typevartuple_prepare_subst(alias, args):
+                params = alias.__parameters__
+                typevartuple_index = params.index(tvt)
+                for param in params[typevartuple_index + 1:]:
+                    if isinstance(param, TypeVarTuple):
+                        raise TypeError(
+                            f"More than one TypeVarTuple parameter in {alias}"
+                        )
+
+                alen = len(args)
+                plen = len(params)
+                left = typevartuple_index
+                right = plen - typevartuple_index - 1
+                var_tuple_index = None
+                fillarg = None
+                for k, arg in enumerate(args):
+                    if not isinstance(arg, type):
+                        subargs = getattr(arg, '__typing_unpacked_tuple_args__', None)
+                        if subargs and len(subargs) == 2 and subargs[-1] is ...:
+                            if var_tuple_index is not None:
+                                raise TypeError(
+                                    "More than one unpacked "
+                                    "arbitrary-length tuple argument"
+                                )
+                            var_tuple_index = k
+                            fillarg = subargs[0]
+                if var_tuple_index is not None:
+                    left = min(left, var_tuple_index)
+                    right = min(right, alen - var_tuple_index - 1)
+                elif left + right > alen:
+                    raise TypeError(f"Too few arguments for {alias};"
+                                    f" actual {alen}, expected at least {plen - 1}")
+                if left == alen - right and tvt.has_default():
+                    replacement = _unpack_args(tvt.__default__)
+                else:
+                    replacement = args[left: alen - right]
+
+                return (
+                    *args[:left],
+                    *([fillarg] * (typevartuple_index - left)),
+                    replacement,
+                    *([fillarg] * (plen - right - left - typevartuple_index - 1)),
+                    *args[alen - right:],
+                )
+
+            tvt.__typing_prepare_subst__ = _typevartuple_prepare_subst
+            return tvt
+
+        def __init_subclass__(self, *args, **kwds):
+            raise TypeError("Cannot subclass special typing classes")
+
+else:  # <=3.10
+    class TypeVarTuple(_DefaultMixin):
+        """Type variable tuple.
+
+        Usage::
+
+            Ts = TypeVarTuple('Ts')
+
+        In the same way that a normal type variable is a stand-in for a single
+        type such as ``int``, a type variable *tuple* is a stand-in for a *tuple*
+        type such as ``Tuple[int, str]``.
+
+        Type variable tuples can be used in ``Generic`` declarations.
+        Consider the following example::
+
+            class Array(Generic[*Ts]): ...
+
+        The ``Ts`` type variable tuple here behaves like ``tuple[T1, T2]``,
+        where ``T1`` and ``T2`` are type variables. To use these type variables
+        as type parameters of ``Array``, we must *unpack* the type variable tuple using
+        the star operator: ``*Ts``. The signature of ``Array`` then behaves
+        as if we had simply written ``class Array(Generic[T1, T2]): ...``.
+        In contrast to ``Generic[T1, T2]``, however, ``Generic[*Shape]`` allows
+        us to parameterise the class with an *arbitrary* number of type parameters.
+
+        Type variable tuples can be used anywhere a normal ``TypeVar`` can.
+        This includes class definitions, as shown above, as well as function
+        signatures and variable annotations::
+
+            class Array(Generic[*Ts]):
+
+                def __init__(self, shape: Tuple[*Ts]):
+                    self._shape: Tuple[*Ts] = shape
+
+                def get_shape(self) -> Tuple[*Ts]:
+                    return self._shape
+
+            shape = (Height(480), Width(640))
+            x: Array[Height, Width] = Array(shape)
+            y = abs(x)  # Inferred type is Array[Height, Width]
+            z = x + x   #        ...    is Array[Height, Width]
+            x.get_shape()  #     ...    is tuple[Height, Width]
+
+        """
+
+        # Trick Generic __parameters__.
+        __class__ = typing.TypeVar
+
+        def __iter__(self):
+            yield self.__unpacked__
+
+        def __init__(self, name, *, default=NoDefault):
+            self.__name__ = name
+            _DefaultMixin.__init__(self, default)
+
+            # for pickling:
+            def_mod = _caller()
+            if def_mod != 'typing_extensions':
+                self.__module__ = def_mod
+
+            self.__unpacked__ = Unpack[self]
+
+        def __repr__(self):
+            return self.__name__
+
+        def __hash__(self):
+            return object.__hash__(self)
+
+        def __eq__(self, other):
+            return self is other
+
+        def __reduce__(self):
+            return self.__name__
+
+        def __init_subclass__(self, *args, **kwds):
+            if '_root' not in kwds:
+                raise TypeError("Cannot subclass special typing classes")
+
+
+if hasattr(typing, "reveal_type"):  # 3.11+
+    reveal_type = typing.reveal_type
+else:  # <=3.10
+    def reveal_type(obj: T, /) -> T:
+        """Reveal the inferred type of a variable.
+
+        When a static type checker encounters a call to ``reveal_type()``,
+        it will emit the inferred type of the argument::
+
+            x: int = 1
+            reveal_type(x)
+
+        Running a static type checker (e.g., ``mypy``) on this example
+        will produce output similar to 'Revealed type is "builtins.int"'.
+
+        At runtime, the function prints the runtime type of the
+        argument and returns it unchanged.
+
+        """
+        print(f"Runtime type is {type(obj).__name__!r}", file=sys.stderr)
+        return obj
+
+
+if hasattr(typing, "_ASSERT_NEVER_REPR_MAX_LENGTH"):  # 3.11+
+    _ASSERT_NEVER_REPR_MAX_LENGTH = typing._ASSERT_NEVER_REPR_MAX_LENGTH
+else:  # <=3.10
+    _ASSERT_NEVER_REPR_MAX_LENGTH = 100
+
+
+if hasattr(typing, "assert_never"):  # 3.11+
+    assert_never = typing.assert_never
+else:  # <=3.10
+    def assert_never(arg: Never, /) -> Never:
+        """Assert to the type checker that a line of code is unreachable.
+
+        Example::
+
+            def int_or_str(arg: int | str) -> None:
+                match arg:
+                    case int():
+                        print("It's an int")
+                    case str():
+                        print("It's a str")
+                    case _:
+                        assert_never(arg)
+
+        If a type checker finds that a call to assert_never() is
+        reachable, it will emit an error.
+
+        At runtime, this throws an exception when called.
+
+        """
+        value = repr(arg)
+        if len(value) > _ASSERT_NEVER_REPR_MAX_LENGTH:
+            value = value[:_ASSERT_NEVER_REPR_MAX_LENGTH] + '...'
+        raise AssertionError(f"Expected code to be unreachable, but got: {value}")
+
+
+if sys.version_info >= (3, 12):  # 3.12+
+    # dataclass_transform exists in 3.11 but lacks the frozen_default parameter
+    dataclass_transform = typing.dataclass_transform
+else:  # <=3.11
+    def dataclass_transform(
+        *,
+        eq_default: bool = True,
+        order_default: bool = False,
+        kw_only_default: bool = False,
+        frozen_default: bool = False,
+        field_specifiers: typing.Tuple[
+            typing.Union[typing.Type[typing.Any], typing.Callable[..., typing.Any]],
+            ...
+        ] = (),
+        **kwargs: typing.Any,
+    ) -> typing.Callable[[T], T]:
+        """Decorator that marks a function, class, or metaclass as providing
+        dataclass-like behavior.
+
+        Example:
+
+            from typing_extensions import dataclass_transform
+
+            _T = TypeVar("_T")
+
+            # Used on a decorator function
+            @dataclass_transform()
+            def create_model(cls: type[_T]) -> type[_T]:
+                ...
+                return cls
+
+            @create_model
+            class CustomerModel:
+                id: int
+                name: str
+
+            # Used on a base class
+            @dataclass_transform()
+            class ModelBase: ...
+
+            class CustomerModel(ModelBase):
+                id: int
+                name: str
+
+            # Used on a metaclass
+            @dataclass_transform()
+            class ModelMeta(type): ...
+
+            class ModelBase(metaclass=ModelMeta): ...
+
+            class CustomerModel(ModelBase):
+                id: int
+                name: str
+
+        Each of the ``CustomerModel`` classes defined in this example will now
+        behave similarly to a dataclass created with the ``@dataclasses.dataclass``
+        decorator. For example, the type checker will synthesize an ``__init__``
+        method.
+
+        The arguments to this decorator can be used to customize this behavior:
+        - ``eq_default`` indicates whether the ``eq`` parameter is assumed to be
+          True or False if it is omitted by the caller.
+        - ``order_default`` indicates whether the ``order`` parameter is
+          assumed to be True or False if it is omitted by the caller.
+        - ``kw_only_default`` indicates whether the ``kw_only`` parameter is
+          assumed to be True or False if it is omitted by the caller.
+        - ``frozen_default`` indicates whether the ``frozen`` parameter is
+          assumed to be True or False if it is omitted by the caller.
+        - ``field_specifiers`` specifies a static list of supported classes
+          or functions that describe fields, similar to ``dataclasses.field()``.
+
+        At runtime, this decorator records its arguments in the
+        ``__dataclass_transform__`` attribute on the decorated object.
+
+        See PEP 681 for details.
+
+        """
+        def decorator(cls_or_fn):
+            cls_or_fn.__dataclass_transform__ = {
+                "eq_default": eq_default,
+                "order_default": order_default,
+                "kw_only_default": kw_only_default,
+                "frozen_default": frozen_default,
+                "field_specifiers": field_specifiers,
+                "kwargs": kwargs,
+            }
+            return cls_or_fn
+        return decorator
+
+
+if hasattr(typing, "override"):  # 3.12+
+    override = typing.override
+else:  # <=3.11
+    _F = typing.TypeVar("_F", bound=typing.Callable[..., typing.Any])
+
+    def override(arg: _F, /) -> _F:
+        """Indicate that a method is intended to override a method in a base class.
+
+        Usage:
+
+            class Base:
+                def method(self) -> None:
+                    pass
+
+            class Child(Base):
+                @override
+                def method(self) -> None:
+                    super().method()
+
+        When this decorator is applied to a method, the type checker will
+        validate that it overrides a method with the same name on a base class.
+        This helps prevent bugs that may occur when a base class is changed
+        without an equivalent change to a child class.
+
+        There is no runtime checking of these properties. The decorator
+        sets the ``__override__`` attribute to ``True`` on the decorated object
+        to allow runtime introspection.
+
+        See PEP 698 for details.
+
+        """
+        try:
+            arg.__override__ = True
+        except (AttributeError, TypeError):
+            # Skip the attribute silently if it is not writable.
+            # AttributeError happens if the object has __slots__ or a
+            # read-only property, TypeError if it's a builtin class.
+            pass
+        return arg
+
+
+if hasattr(warnings, "deprecated"):
+    deprecated = warnings.deprecated
+else:
+    _T = typing.TypeVar("_T")
+
+    class deprecated:
+        """Indicate that a class, function or overload is deprecated.
+
+        When this decorator is applied to an object, the type checker
+        will generate a diagnostic on usage of the deprecated object.
+
+        Usage:
+
+            @deprecated("Use B instead")
+            class A:
+                pass
+
+            @deprecated("Use g instead")
+            def f():
+                pass
+
+            @overload
+            @deprecated("int support is deprecated")
+            def g(x: int) -> int: ...
+            @overload
+            def g(x: str) -> int: ...
+
+        The warning specified by *category* will be emitted at runtime
+        on use of deprecated objects. For functions, that happens on calls;
+        for classes, on instantiation and on creation of subclasses.
+        If the *category* is ``None``, no warning is emitted at runtime.
+        The *stacklevel* determines where the
+        warning is emitted. If it is ``1`` (the default), the warning
+        is emitted at the direct caller of the deprecated object; if it
+        is higher, it is emitted further up the stack.
+        Static type checker behavior is not affected by the *category*
+        and *stacklevel* arguments.
+
+        The deprecation message passed to the decorator is saved in the
+        ``__deprecated__`` attribute on the decorated object.
+        If applied to an overload, the decorator
+        must be after the ``@overload`` decorator for the attribute to
+        exist on the overload as returned by ``get_overloads()``.
+
+        See PEP 702 for details.
+
+        """
+        def __init__(
+            self,
+            message: str,
+            /,
+            *,
+            category: typing.Optional[typing.Type[Warning]] = DeprecationWarning,
+            stacklevel: int = 1,
+        ) -> None:
+            if not isinstance(message, str):
+                raise TypeError(
+                    "Expected an object of type str for 'message', not "
+                    f"{type(message).__name__!r}"
+                )
+            self.message = message
+            self.category = category
+            self.stacklevel = stacklevel
+
+        def __call__(self, arg: _T, /) -> _T:
+            # Make sure the inner functions created below don't
+            # retain a reference to self.
+            msg = self.message
+            category = self.category
+            stacklevel = self.stacklevel
+            if category is None:
+                arg.__deprecated__ = msg
+                return arg
+            elif isinstance(arg, type):
+                import functools
+                from types import MethodType
+
+                original_new = arg.__new__
+
+                @functools.wraps(original_new)
+                def __new__(cls, *args, **kwargs):
+                    if cls is arg:
+                        warnings.warn(msg, category=category, stacklevel=stacklevel + 1)
+                    if original_new is not object.__new__:
+                        return original_new(cls, *args, **kwargs)
+                    # Mirrors a similar check in object.__new__.
+                    elif cls.__init__ is object.__init__ and (args or kwargs):
+                        raise TypeError(f"{cls.__name__}() takes no arguments")
+                    else:
+                        return original_new(cls)
+
+                arg.__new__ = staticmethod(__new__)
+
+                original_init_subclass = arg.__init_subclass__
+                # We need slightly different behavior if __init_subclass__
+                # is a bound method (likely if it was implemented in Python)
+                if isinstance(original_init_subclass, MethodType):
+                    original_init_subclass = original_init_subclass.__func__
+
+                    @functools.wraps(original_init_subclass)
+                    def __init_subclass__(*args, **kwargs):
+                        warnings.warn(msg, category=category, stacklevel=stacklevel + 1)
+                        return original_init_subclass(*args, **kwargs)
+
+                    arg.__init_subclass__ = classmethod(__init_subclass__)
+                # Or otherwise, which likely means it's a builtin such as
+                # object's implementation of __init_subclass__.
+                else:
+                    @functools.wraps(original_init_subclass)
+                    def __init_subclass__(*args, **kwargs):
+                        warnings.warn(msg, category=category, stacklevel=stacklevel + 1)
+                        return original_init_subclass(*args, **kwargs)
+
+                    arg.__init_subclass__ = __init_subclass__
+
+                arg.__deprecated__ = __new__.__deprecated__ = msg
+                __init_subclass__.__deprecated__ = msg
+                return arg
+            elif callable(arg):
+                import functools
+
+                @functools.wraps(arg)
+                def wrapper(*args, **kwargs):
+                    warnings.warn(msg, category=category, stacklevel=stacklevel + 1)
+                    return arg(*args, **kwargs)
+
+                arg.__deprecated__ = wrapper.__deprecated__ = msg
+                return wrapper
+            else:
+                raise TypeError(
+                    "@deprecated decorator with non-None category must be applied to "
+                    f"a class or callable, not {arg!r}"
+                )
+
+
+# We have to do some monkey patching to deal with the dual nature of
+# Unpack/TypeVarTuple:
+# - We want Unpack to be a kind of TypeVar so it gets accepted in
+#   Generic[Unpack[Ts]]
+# - We want it to *not* be treated as a TypeVar for the purposes of
+#   counting generic parameters, so that when we subscript a generic,
+#   the runtime doesn't try to substitute the Unpack with the subscripted type.
+if not hasattr(typing, "TypeVarTuple"):
+    def _check_generic(cls, parameters, elen=_marker):
+        """Check correct count for parameters of a generic cls (internal helper).
+
+        This gives a nice error message in case of count mismatch.
+        """
+        if not elen:
+            raise TypeError(f"{cls} is not a generic class")
+        if elen is _marker:
+            if not hasattr(cls, "__parameters__") or not cls.__parameters__:
+                raise TypeError(f"{cls} is not a generic class")
+            elen = len(cls.__parameters__)
+        alen = len(parameters)
+        if alen != elen:
+            expect_val = elen
+            if hasattr(cls, "__parameters__"):
+                parameters = [p for p in cls.__parameters__ if not _is_unpack(p)]
+                num_tv_tuples = sum(isinstance(p, TypeVarTuple) for p in parameters)
+                if (num_tv_tuples > 0) and (alen >= elen - num_tv_tuples):
+                    return
+
+                # deal with TypeVarLike defaults
+                # required TypeVarLikes cannot appear after a defaulted one.
+                if alen < elen:
+                    # since we validate TypeVarLike default in _collect_type_vars
+                    # or _collect_parameters we can safely check parameters[alen]
+                    if (
+                        getattr(parameters[alen], '__default__', NoDefault)
+                        is not NoDefault
+                    ):
+                        return
+
+                    num_default_tv = sum(getattr(p, '__default__', NoDefault)
+                                         is not NoDefault for p in parameters)
+
+                    elen -= num_default_tv
+
+                    expect_val = f"at least {elen}"
+
+            things = "arguments" if sys.version_info >= (3, 10) else "parameters"
+            raise TypeError(f"Too {'many' if alen > elen else 'few'} {things}"
+                            f" for {cls}; actual {alen}, expected {expect_val}")
+else:
+    # Python 3.11+
+
+    def _check_generic(cls, parameters, elen):
+        """Check correct count for parameters of a generic cls (internal helper).
+
+        This gives a nice error message in case of count mismatch.
+        """
+        if not elen:
+            raise TypeError(f"{cls} is not a generic class")
+        alen = len(parameters)
+        if alen != elen:
+            expect_val = elen
+            if hasattr(cls, "__parameters__"):
+                parameters = [p for p in cls.__parameters__ if not _is_unpack(p)]
+
+                # deal with TypeVarLike defaults
+                # required TypeVarLikes cannot appear after a defaulted one.
+                if alen < elen:
+                    # since we validate TypeVarLike default in _collect_type_vars
+                    # or _collect_parameters we can safely check parameters[alen]
+                    if (
+                        getattr(parameters[alen], '__default__', NoDefault)
+                        is not NoDefault
+                    ):
+                        return
+
+                    num_default_tv = sum(getattr(p, '__default__', NoDefault)
+                                         is not NoDefault for p in parameters)
+
+                    elen -= num_default_tv
+
+                    expect_val = f"at least {elen}"
+
+            raise TypeError(f"Too {'many' if alen > elen else 'few'} arguments"
+                            f" for {cls}; actual {alen}, expected {expect_val}")
+
+if not _PEP_696_IMPLEMENTED:
+    typing._check_generic = _check_generic
+
+
+def _has_generic_or_protocol_as_origin() -> bool:
+    try:
+        frame = sys._getframe(2)
+    # - Catch AttributeError: not all Python implementations have sys._getframe()
+    # - Catch ValueError: maybe we're called from an unexpected module
+    #   and the call stack isn't deep enough
+    except (AttributeError, ValueError):
+        return False  # err on the side of leniency
+    else:
+        # If we somehow get invoked from outside typing.py,
+        # also err on the side of leniency
+        if frame.f_globals.get("__name__") != "typing":
+            return False
+        origin = frame.f_locals.get("origin")
+        # Cannot use "in" because origin may be an object with a buggy __eq__ that
+        # throws an error.
+        return origin is typing.Generic or origin is Protocol or origin is typing.Protocol
+
+
+_TYPEVARTUPLE_TYPES = {TypeVarTuple, getattr(typing, "TypeVarTuple", None)}
+
+
+def _is_unpacked_typevartuple(x) -> bool:
+    if get_origin(x) is not Unpack:
+        return False
+    args = get_args(x)
+    return (
+        bool(args)
+        and len(args) == 1
+        and type(args[0]) in _TYPEVARTUPLE_TYPES
+    )
+
+
+# Python 3.11+ _collect_type_vars was renamed to _collect_parameters
+if hasattr(typing, '_collect_type_vars'):
+    def _collect_type_vars(types, typevar_types=None):
+        """Collect all type variable contained in types in order of
+        first appearance (lexicographic order). For example::
+
+            _collect_type_vars((T, List[S, T])) == (T, S)
+        """
+        if typevar_types is None:
+            typevar_types = typing.TypeVar
+        tvars = []
+
+        # A required TypeVarLike cannot appear after a TypeVarLike with a default
+        # if it was a direct call to `Generic[]` or `Protocol[]`
+        enforce_default_ordering = _has_generic_or_protocol_as_origin()
+        default_encountered = False
+
+        # Also, a TypeVarLike with a default cannot appear after a TypeVarTuple
+        type_var_tuple_encountered = False
+
+        for t in types:
+            if _is_unpacked_typevartuple(t):
+                type_var_tuple_encountered = True
+            elif isinstance(t, typevar_types) and t not in tvars:
+                if enforce_default_ordering:
+                    has_default = getattr(t, '__default__', NoDefault) is not NoDefault
+                    if has_default:
+                        if type_var_tuple_encountered:
+                            raise TypeError('Type parameter with a default'
+                                            ' follows TypeVarTuple')
+                        default_encountered = True
+                    elif default_encountered:
+                        raise TypeError(f'Type parameter {t!r} without a default'
+                                        ' follows type parameter with a default')
+
+                tvars.append(t)
+            if _should_collect_from_parameters(t):
+                tvars.extend([t for t in t.__parameters__ if t not in tvars])
+        return tuple(tvars)
+
+    typing._collect_type_vars = _collect_type_vars
+else:
+    def _collect_parameters(args):
+        """Collect all type variables and parameter specifications in args
+        in order of first appearance (lexicographic order).
+
+        For example::
+
+            assert _collect_parameters((T, Callable[P, T])) == (T, P)
+        """
+        parameters = []
+
+        # A required TypeVarLike cannot appear after a TypeVarLike with default
+        # if it was a direct call to `Generic[]` or `Protocol[]`
+        enforce_default_ordering = _has_generic_or_protocol_as_origin()
+        default_encountered = False
+
+        # Also, a TypeVarLike with a default cannot appear after a TypeVarTuple
+        type_var_tuple_encountered = False
+
+        for t in args:
+            if isinstance(t, type):
+                # We don't want __parameters__ descriptor of a bare Python class.
+                pass
+            elif isinstance(t, tuple):
+                # `t` might be a tuple, when `ParamSpec` is substituted with
+                # `[T, int]`, or `[int, *Ts]`, etc.
+                for x in t:
+                    for collected in _collect_parameters([x]):
+                        if collected not in parameters:
+                            parameters.append(collected)
+            elif hasattr(t, '__typing_subst__'):
+                if t not in parameters:
+                    if enforce_default_ordering:
+                        has_default = (
+                            getattr(t, '__default__', NoDefault) is not NoDefault
+                        )
+
+                        if type_var_tuple_encountered and has_default:
+                            raise TypeError('Type parameter with a default'
+                                            ' follows TypeVarTuple')
+
+                        if has_default:
+                            default_encountered = True
+                        elif default_encountered:
+                            raise TypeError(f'Type parameter {t!r} without a default'
+                                            ' follows type parameter with a default')
+
+                    parameters.append(t)
+            else:
+                if _is_unpacked_typevartuple(t):
+                    type_var_tuple_encountered = True
+                for x in getattr(t, '__parameters__', ()):
+                    if x not in parameters:
+                        parameters.append(x)
+
+        return tuple(parameters)
+
+    if not _PEP_696_IMPLEMENTED:
+        typing._collect_parameters = _collect_parameters
+
+# Backport typing.NamedTuple as it exists in Python 3.13.
+# In 3.11, the ability to define generic `NamedTuple`s was supported.
+# This was explicitly disallowed in 3.9-3.10, and only half-worked in <=3.8.
+# On 3.12, we added __orig_bases__ to call-based NamedTuples
+# On 3.13, we deprecated kwargs-based NamedTuples
+if sys.version_info >= (3, 13):
+    NamedTuple = typing.NamedTuple
+else:
+    def _make_nmtuple(name, types, module, defaults=()):
+        fields = [n for n, t in types]
+        annotations = {n: typing._type_check(t, f"field {n} annotation must be a type")
+                       for n, t in types}
+        nm_tpl = collections.namedtuple(name, fields,
+                                        defaults=defaults, module=module)
+        nm_tpl.__annotations__ = nm_tpl.__new__.__annotations__ = annotations
+        # The `_field_types` attribute was removed in 3.9;
+        # in earlier versions, it is the same as the `__annotations__` attribute
+        if sys.version_info < (3, 9):
+            nm_tpl._field_types = annotations
+        return nm_tpl
+
+    _prohibited_namedtuple_fields = typing._prohibited
+    _special_namedtuple_fields = frozenset({'__module__', '__name__', '__annotations__'})
+
+    class _NamedTupleMeta(type):
+        def __new__(cls, typename, bases, ns):
+            assert _NamedTuple in bases
+            for base in bases:
+                if base is not _NamedTuple and base is not typing.Generic:
+                    raise TypeError(
+                        'can only inherit from a NamedTuple type and Generic')
+            bases = tuple(tuple if base is _NamedTuple else base for base in bases)
+            if "__annotations__" in ns:
+                types = ns["__annotations__"]
+            elif "__annotate__" in ns:
+                # TODO: Use inspect.VALUE here, and make the annotations lazily evaluated
+                types = ns["__annotate__"](1)
+            else:
+                types = {}
+            default_names = []
+            for field_name in types:
+                if field_name in ns:
+                    default_names.append(field_name)
+                elif default_names:
+                    raise TypeError(f"Non-default namedtuple field {field_name} "
+                                    f"cannot follow default field"
+                                    f"{'s' if len(default_names) > 1 else ''} "
+                                    f"{', '.join(default_names)}")
+            nm_tpl = _make_nmtuple(
+                typename, types.items(),
+                defaults=[ns[n] for n in default_names],
+                module=ns['__module__']
+            )
+            nm_tpl.__bases__ = bases
+            if typing.Generic in bases:
+                if hasattr(typing, '_generic_class_getitem'):  # 3.12+
+                    nm_tpl.__class_getitem__ = classmethod(typing._generic_class_getitem)
+                else:
+                    class_getitem = typing.Generic.__class_getitem__.__func__
+                    nm_tpl.__class_getitem__ = classmethod(class_getitem)
+            # update from user namespace without overriding special namedtuple attributes
+            for key, val in ns.items():
+                if key in _prohibited_namedtuple_fields:
+                    raise AttributeError("Cannot overwrite NamedTuple attribute " + key)
+                elif key not in _special_namedtuple_fields:
+                    if key not in nm_tpl._fields:
+                        setattr(nm_tpl, key, ns[key])
+                    try:
+                        set_name = type(val).__set_name__
+                    except AttributeError:
+                        pass
+                    else:
+                        try:
+                            set_name(val, nm_tpl, key)
+                        except BaseException as e:
+                            msg = (
+                                f"Error calling __set_name__ on {type(val).__name__!r} "
+                                f"instance {key!r} in {typename!r}"
+                            )
+                            # BaseException.add_note() existed on py311,
+                            # but the __set_name__ machinery didn't start
+                            # using add_note() until py312.
+                            # Making sure exceptions are raised in the same way
+                            # as in "normal" classes seems most important here.
+                            if sys.version_info >= (3, 12):
+                                e.add_note(msg)
+                                raise
+                            else:
+                                raise RuntimeError(msg) from e
+
+            if typing.Generic in bases:
+                nm_tpl.__init_subclass__()
+            return nm_tpl
+
+    _NamedTuple = type.__new__(_NamedTupleMeta, 'NamedTuple', (), {})
+
+    def _namedtuple_mro_entries(bases):
+        assert NamedTuple in bases
+        return (_NamedTuple,)
+
+    @_ensure_subclassable(_namedtuple_mro_entries)
+    def NamedTuple(typename, fields=_marker, /, **kwargs):
+        """Typed version of namedtuple.
+
+        Usage::
+
+            class Employee(NamedTuple):
+                name: str
+                id: int
+
+        This is equivalent to::
+
+            Employee = collections.namedtuple('Employee', ['name', 'id'])
+
+        The resulting class has an extra __annotations__ attribute, giving a
+        dict that maps field names to types.  (The field names are also in
+        the _fields attribute, which is part of the namedtuple API.)
+        An alternative equivalent functional syntax is also accepted::
+
+            Employee = NamedTuple('Employee', [('name', str), ('id', int)])
+        """
+        if fields is _marker:
+            if kwargs:
+                deprecated_thing = "Creating NamedTuple classes using keyword arguments"
+                deprecation_msg = (
+                    "{name} is deprecated and will be disallowed in Python {remove}. "
+                    "Use the class-based or functional syntax instead."
+                )
+            else:
+                deprecated_thing = "Failing to pass a value for the 'fields' parameter"
+                example = f"`{typename} = NamedTuple({typename!r}, [])`"
+                deprecation_msg = (
+                    "{name} is deprecated and will be disallowed in Python {remove}. "
+                    "To create a NamedTuple class with 0 fields "
+                    "using the functional syntax, "
+                    "pass an empty list, e.g. "
+                ) + example + "."
+        elif fields is None:
+            if kwargs:
+                raise TypeError(
+                    "Cannot pass `None` as the 'fields' parameter "
+                    "and also specify fields using keyword arguments"
+                )
+            else:
+                deprecated_thing = "Passing `None` as the 'fields' parameter"
+                example = f"`{typename} = NamedTuple({typename!r}, [])`"
+                deprecation_msg = (
+                    "{name} is deprecated and will be disallowed in Python {remove}. "
+                    "To create a NamedTuple class with 0 fields "
+                    "using the functional syntax, "
+                    "pass an empty list, e.g. "
+                ) + example + "."
+        elif kwargs:
+            raise TypeError("Either list of fields or keywords"
+                            " can be provided to NamedTuple, not both")
+        if fields is _marker or fields is None:
+            warnings.warn(
+                deprecation_msg.format(name=deprecated_thing, remove="3.15"),
+                DeprecationWarning,
+                stacklevel=2,
+            )
+            fields = kwargs.items()
+        nt = _make_nmtuple(typename, fields, module=_caller())
+        nt.__orig_bases__ = (NamedTuple,)
+        return nt
+
+
+if hasattr(collections.abc, "Buffer"):
+    Buffer = collections.abc.Buffer
+else:
+    class Buffer(abc.ABC):  # noqa: B024
+        """Base class for classes that implement the buffer protocol.
+
+        The buffer protocol allows Python objects to expose a low-level
+        memory buffer interface. Before Python 3.12, it is not possible
+        to implement the buffer protocol in pure Python code, or even
+        to check whether a class implements the buffer protocol. In
+        Python 3.12 and higher, the ``__buffer__`` method allows access
+        to the buffer protocol from Python code, and the
+        ``collections.abc.Buffer`` ABC allows checking whether a class
+        implements the buffer protocol.
+
+        To indicate support for the buffer protocol in earlier versions,
+        inherit from this ABC, either in a stub file or at runtime,
+        or use ABC registration. This ABC provides no methods, because
+        there is no Python-accessible methods shared by pre-3.12 buffer
+        classes. It is useful primarily for static checks.
+
+        """
+
+    # As a courtesy, register the most common stdlib buffer classes.
+    Buffer.register(memoryview)
+    Buffer.register(bytearray)
+    Buffer.register(bytes)
+
+
+# Backport of types.get_original_bases, available on 3.12+ in CPython
+if hasattr(_types, "get_original_bases"):
+    get_original_bases = _types.get_original_bases
+else:
+    def get_original_bases(cls, /):
+        """Return the class's "original" bases prior to modification by `__mro_entries__`.
+
+        Examples::
+
+            from typing import TypeVar, Generic
+            from typing_extensions import NamedTuple, TypedDict
+
+            T = TypeVar("T")
+            class Foo(Generic[T]): ...
+            class Bar(Foo[int], float): ...
+            class Baz(list[str]): ...
+            Eggs = NamedTuple("Eggs", [("a", int), ("b", str)])
+            Spam = TypedDict("Spam", {"a": int, "b": str})
+
+            assert get_original_bases(Bar) == (Foo[int], float)
+            assert get_original_bases(Baz) == (list[str],)
+            assert get_original_bases(Eggs) == (NamedTuple,)
+            assert get_original_bases(Spam) == (TypedDict,)
+            assert get_original_bases(int) == (object,)
+        """
+        try:
+            return cls.__dict__.get("__orig_bases__", cls.__bases__)
+        except AttributeError:
+            raise TypeError(
+                f'Expected an instance of type, not {type(cls).__name__!r}'
+            ) from None
+
+
+# NewType is a class on Python 3.10+, making it pickleable
+# The error message for subclassing instances of NewType was improved on 3.11+
+if sys.version_info >= (3, 11):
+    NewType = typing.NewType
+else:
+    class NewType:
+        """NewType creates simple unique types with almost zero
+        runtime overhead. NewType(name, tp) is considered a subtype of tp
+        by static type checkers. At runtime, NewType(name, tp) returns
+        a dummy callable that simply returns its argument. Usage::
+            UserId = NewType('UserId', int)
+            def name_by_id(user_id: UserId) -> str:
+                ...
+            UserId('user')          # Fails type check
+            name_by_id(42)          # Fails type check
+            name_by_id(UserId(42))  # OK
+            num = UserId(5) + 1     # type: int
+        """
+
+        def __call__(self, obj, /):
+            return obj
+
+        def __init__(self, name, tp):
+            self.__qualname__ = name
+            if '.' in name:
+                name = name.rpartition('.')[-1]
+            self.__name__ = name
+            self.__supertype__ = tp
+            def_mod = _caller()
+            if def_mod != 'typing_extensions':
+                self.__module__ = def_mod
+
+        def __mro_entries__(self, bases):
+            # We defined __mro_entries__ to get a better error message
+            # if a user attempts to subclass a NewType instance. bpo-46170
+            supercls_name = self.__name__
+
+            class Dummy:
+                def __init_subclass__(cls):
+                    subcls_name = cls.__name__
+                    raise TypeError(
+                        f"Cannot subclass an instance of NewType. "
+                        f"Perhaps you were looking for: "
+                        f"`{subcls_name} = NewType({subcls_name!r}, {supercls_name})`"
+                    )
+
+            return (Dummy,)
+
+        def __repr__(self):
+            return f'{self.__module__}.{self.__qualname__}'
+
+        def __reduce__(self):
+            return self.__qualname__
+
+        if sys.version_info >= (3, 10):
+            # PEP 604 methods
+            # It doesn't make sense to have these methods on Python <3.10
+
+            def __or__(self, other):
+                return typing.Union[self, other]
+
+            def __ror__(self, other):
+                return typing.Union[other, self]
+
+
+if hasattr(typing, "TypeAliasType"):
+    TypeAliasType = typing.TypeAliasType
+else:
+    def _is_unionable(obj):
+        """Corresponds to is_unionable() in unionobject.c in CPython."""
+        return obj is None or isinstance(obj, (
+            type,
+            _types.GenericAlias,
+            _types.UnionType,
+            TypeAliasType,
+        ))
+
+    class TypeAliasType:
+        """Create named, parameterized type aliases.
+
+        This provides a backport of the new `type` statement in Python 3.12:
+
+            type ListOrSet[T] = list[T] | set[T]
+
+        is equivalent to:
+
+            T = TypeVar("T")
+            ListOrSet = TypeAliasType("ListOrSet", list[T] | set[T], type_params=(T,))
+
+        The name ListOrSet can then be used as an alias for the type it refers to.
+
+        The type_params argument should contain all the type parameters used
+        in the value of the type alias. If the alias is not generic, this
+        argument is omitted.
+
+        Static type checkers should only support type aliases declared using
+        TypeAliasType that follow these rules:
+
+        - The first argument (the name) must be a string literal.
+        - The TypeAliasType instance must be immediately assigned to a variable
+          of the same name. (For example, 'X = TypeAliasType("Y", int)' is invalid,
+          as is 'X, Y = TypeAliasType("X", int), TypeAliasType("Y", int)').
+
+        """
+
+        def __init__(self, name: str, value, *, type_params=()):
+            if not isinstance(name, str):
+                raise TypeError("TypeAliasType name must be a string")
+            self.__value__ = value
+            self.__type_params__ = type_params
+
+            parameters = []
+            for type_param in type_params:
+                if isinstance(type_param, TypeVarTuple):
+                    parameters.extend(type_param)
+                else:
+                    parameters.append(type_param)
+            self.__parameters__ = tuple(parameters)
+            def_mod = _caller()
+            if def_mod != 'typing_extensions':
+                self.__module__ = def_mod
+            # Setting this attribute closes the TypeAliasType from further modification
+            self.__name__ = name
+
+        def __setattr__(self, name: str, value: object, /) -> None:
+            if hasattr(self, "__name__"):
+                self._raise_attribute_error(name)
+            super().__setattr__(name, value)
+
+        def __delattr__(self, name: str, /) -> Never:
+            self._raise_attribute_error(name)
+
+        def _raise_attribute_error(self, name: str) -> Never:
+            # Match the Python 3.12 error messages exactly
+            if name == "__name__":
+                raise AttributeError("readonly attribute")
+            elif name in {"__value__", "__type_params__", "__parameters__", "__module__"}:
+                raise AttributeError(
+                    f"attribute '{name}' of 'typing.TypeAliasType' objects "
+                    "is not writable"
+                )
+            else:
+                raise AttributeError(
+                    f"'typing.TypeAliasType' object has no attribute '{name}'"
+                )
+
+        def __repr__(self) -> str:
+            return self.__name__
+
+        def __getitem__(self, parameters):
+            if not isinstance(parameters, tuple):
+                parameters = (parameters,)
+            parameters = [
+                typing._type_check(
+                    item, f'Subscripting {self.__name__} requires a type.'
+                )
+                for item in parameters
+            ]
+            return typing._GenericAlias(self, tuple(parameters))
+
+        def __reduce__(self):
+            return self.__name__
+
+        def __init_subclass__(cls, *args, **kwargs):
+            raise TypeError(
+                "type 'typing_extensions.TypeAliasType' is not an acceptable base type"
+            )
+
+        # The presence of this method convinces typing._type_check
+        # that TypeAliasTypes are types.
+        def __call__(self):
+            raise TypeError("Type alias is not callable")
+
+        if sys.version_info >= (3, 10):
+            def __or__(self, right):
+                # For forward compatibility with 3.12, reject Unions
+                # that are not accepted by the built-in Union.
+                if not _is_unionable(right):
+                    return NotImplemented
+                return typing.Union[self, right]
+
+            def __ror__(self, left):
+                if not _is_unionable(left):
+                    return NotImplemented
+                return typing.Union[left, self]
+
+
+if hasattr(typing, "is_protocol"):
+    is_protocol = typing.is_protocol
+    get_protocol_members = typing.get_protocol_members
+else:
+    def is_protocol(tp: type, /) -> bool:
+        """Return True if the given type is a Protocol.
+
+        Example::
+
+            >>> from typing_extensions import Protocol, is_protocol
+            >>> class P(Protocol):
+            ...     def a(self) -> str: ...
+            ...     b: int
+            >>> is_protocol(P)
+            True
+            >>> is_protocol(int)
+            False
+        """
+        return (
+            isinstance(tp, type)
+            and getattr(tp, '_is_protocol', False)
+            and tp is not Protocol
+            and tp is not typing.Protocol
+        )
+
+    def get_protocol_members(tp: type, /) -> typing.FrozenSet[str]:
+        """Return the set of members defined in a Protocol.
+
+        Example::
+
+            >>> from typing_extensions import Protocol, get_protocol_members
+            >>> class P(Protocol):
+            ...     def a(self) -> str: ...
+            ...     b: int
+            >>> get_protocol_members(P)
+            frozenset({'a', 'b'})
+
+        Raise a TypeError for arguments that are not Protocols.
+        """
+        if not is_protocol(tp):
+            raise TypeError(f'{tp!r} is not a Protocol')
+        if hasattr(tp, '__protocol_attrs__'):
+            return frozenset(tp.__protocol_attrs__)
+        return frozenset(_get_protocol_attrs(tp))
+
+
+if hasattr(typing, "Doc"):
+    Doc = typing.Doc
+else:
+    class Doc:
+        """Define the documentation of a type annotation using ``Annotated``, to be
+         used in class attributes, function and method parameters, return values,
+         and variables.
+
+        The value should be a positional-only string literal to allow static tools
+        like editors and documentation generators to use it.
+
+        This complements docstrings.
+
+        The string value passed is available in the attribute ``documentation``.
+
+        Example::
+
+            >>> from typing_extensions import Annotated, Doc
+            >>> def hi(to: Annotated[str, Doc("Who to say hi to")]) -> None: ...
+        """
+        def __init__(self, documentation: str, /) -> None:
+            self.documentation = documentation
+
+        def __repr__(self) -> str:
+            return f"Doc({self.documentation!r})"
+
+        def __hash__(self) -> int:
+            return hash(self.documentation)
+
+        def __eq__(self, other: object) -> bool:
+            if not isinstance(other, Doc):
+                return NotImplemented
+            return self.documentation == other.documentation
+
+
+_CapsuleType = getattr(_types, "CapsuleType", None)
+
+if _CapsuleType is None:
+    try:
+        import _socket
+    except ImportError:
+        pass
+    else:
+        _CAPI = getattr(_socket, "CAPI", None)
+        if _CAPI is not None:
+            _CapsuleType = type(_CAPI)
+
+if _CapsuleType is not None:
+    CapsuleType = _CapsuleType
+    __all__.append("CapsuleType")
+
+
+# Aliases for items that have always been in typing.
+# Explicitly assign these (rather than using `from typing import *` at the top),
+# so that we get a CI error if one of these is deleted from typing.py
+# in a future version of Python
+AbstractSet = typing.AbstractSet
+AnyStr = typing.AnyStr
+BinaryIO = typing.BinaryIO
+Callable = typing.Callable
+Collection = typing.Collection
+Container = typing.Container
+Dict = typing.Dict
+ForwardRef = typing.ForwardRef
+FrozenSet = typing.FrozenSet
+Generic = typing.Generic
+Hashable = typing.Hashable
+IO = typing.IO
+ItemsView = typing.ItemsView
+Iterable = typing.Iterable
+Iterator = typing.Iterator
+KeysView = typing.KeysView
+List = typing.List
+Mapping = typing.Mapping
+MappingView = typing.MappingView
+Match = typing.Match
+MutableMapping = typing.MutableMapping
+MutableSequence = typing.MutableSequence
+MutableSet = typing.MutableSet
+Optional = typing.Optional
+Pattern = typing.Pattern
+Reversible = typing.Reversible
+Sequence = typing.Sequence
+Set = typing.Set
+Sized = typing.Sized
+TextIO = typing.TextIO
+Tuple = typing.Tuple
+Union = typing.Union
+ValuesView = typing.ValuesView
+cast = typing.cast
+no_type_check = typing.no_type_check
+no_type_check_decorator = typing.no_type_check_decorator
diff --git a/venv/lib64 b/venv/lib64
new file mode 120000
index 000000000..7951405f8
--- /dev/null
+++ b/venv/lib64
@@ -0,0 +1 @@
+lib
\ No newline at end of file
diff --git a/venv/pyvenv.cfg b/venv/pyvenv.cfg
new file mode 100644
index 000000000..ef219d571
--- /dev/null
+++ b/venv/pyvenv.cfg
@@ -0,0 +1,3 @@
+home = /opt/miniconda3/envs/testbed/bin
+include-system-site-packages = false
+version = 3.9.19

2025-01-14 15:42:46,854 - INFO - Building image: ghcr.io/all-hands-ai/runtime:oh_v0.20.0_ohlp4io77yl9n7on_qroup3d3os79ipoo
2025-01-14 15:42:46,857 - INFO - [runtime ff2cd705-fc1d-4983-bf65-c35f6c4b19c7-257e3dba1b8c6f1f] Starting runtime with image: ghcr.io/all-hands-ai/runtime:oh_v0.20.0_ohlp4io77yl9n7on_qroup3d3os79ipoo
2025-01-14 15:42:47,799 - INFO - [runtime ff2cd705-fc1d-4983-bf65-c35f6c4b19c7-257e3dba1b8c6f1f] Container started: openhands-runtime-ff2cd705-fc1d-4983-bf65-c35f6c4b19c7-257e3dba1b8c6f1f. VSCode URL: None
2025-01-14 15:42:47,799 - INFO - [runtime ff2cd705-fc1d-4983-bf65-c35f6c4b19c7-257e3dba1b8c6f1f] Waiting for client to become ready at http://localhost:39052...
2025-01-14 15:43:13,872 - INFO - [runtime ff2cd705-fc1d-4983-bf65-c35f6c4b19c7-257e3dba1b8c6f1f] Runtime is ready.
2025-01-14 15:43:14,512 - INFO - ------------------------------
2025-01-14 15:43:14,512 - INFO - BEGIN Runtime Initialization Fn
2025-01-14 15:43:14,512 - INFO - ------------------------------
2025-01-14 15:43:14,512 - INFO - **CmdRunAction (source=None)**
COMMAND:
echo 'export SWE_INSTANCE_ID=pytest-dev__pytest-7490' >> ~/.bashrc && echo 'export PIP_CACHE_DIR=~/.cache/pip' >> ~/.bashrc && echo "alias git='git --no-pager'" >> ~/.bashrc
2025-01-14 15:43:15,138 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--

[The command completed with exit code 0.]
[Current working directory: /workspace]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:43:15,138 - INFO - **CmdRunAction (source=None)**
COMMAND:
export USER=$(whoami); echo USER=${USER} 
2025-01-14 15:43:15,767 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--
USER=root
[The command completed with exit code 0.]
[Current working directory: /workspace]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:43:15,767 - INFO - **CmdRunAction (source=None)**
COMMAND:
mkdir -p /swe_util/eval_data/instances
2025-01-14 15:43:16,394 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--

[The command completed with exit code 0.]
[Current working directory: /workspace]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:43:16,404 - INFO - **CmdRunAction (source=None)**
COMMAND:
cat ~/.bashrc
2025-01-14 15:43:17,033 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--
source /opt/miniconda3/etc/profile.d/conda.sh && conda activate testbed
export SWE_INSTANCE_ID=pytest-dev__pytest-7490
export PIP_CACHE_DIR=~/.cache/pip
alias git='git --no-pager'
[The command completed with exit code 0.]
[Current working directory: /workspace]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:43:17,033 - INFO - **CmdRunAction (source=None)**
COMMAND:
source ~/.bashrc
2025-01-14 15:43:17,659 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--

[The command completed with exit code 0.]
[Current working directory: /workspace]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:43:17,660 - WARNING - Timeout greater than 600 seconds may not be supported by the runtime. Consider setting a lower timeout.
2025-01-14 15:43:17,660 - INFO - **CmdRunAction (source=None)**
COMMAND:
source /swe_util/instance_swe_entry.sh
2025-01-14 15:43:18,789 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--
WORKSPACE_NAME: pytest-dev__pytest__6.0
[The command completed with exit code 0.]
[Current working directory: /workspace]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:43:18,790 - INFO - **CmdRunAction (source=None)**
COMMAND:
cd /workspace/pytest-dev__pytest__6.0
2025-01-14 15:43:19,415 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace/pytest-dev__pytest__6.0",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--

[The command completed with exit code 0.]
[Current working directory: /workspace/pytest-dev__pytest__6.0]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:43:19,415 - INFO - **CmdRunAction (source=None)**
COMMAND:
git reset --hard
2025-01-14 15:43:20,040 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace/pytest-dev__pytest__6.0",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--
HEAD is now at 7f7a36478 Merge pull request #7482 from nicoddemus/changelog-adjustments
[The command completed with exit code 0.]
[Current working directory: /workspace/pytest-dev__pytest__6.0]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:43:20,040 - INFO - **CmdRunAction (source=None)**
COMMAND:
for remote_name in $(git remote); do git remote remove "${remote_name}"; done
2025-01-14 15:43:20,667 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace/pytest-dev__pytest__6.0",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--

[The command completed with exit code 0.]
[Current working directory: /workspace/pytest-dev__pytest__6.0]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:43:20,667 - INFO - **CmdRunAction (source=None)**
COMMAND:
which python
2025-01-14 15:43:21,293 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace/pytest-dev__pytest__6.0",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--
/opt/miniconda3/envs/testbed/bin/python
[The command completed with exit code 0.]
[Current working directory: /workspace/pytest-dev__pytest__6.0]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:43:21,293 - INFO - ------------------------------
2025-01-14 15:43:21,293 - INFO - END Runtime Initialization Fn
2025-01-14 15:43:21,293 - INFO - ------------------------------
2025-01-14 15:43:21,294 - INFO - Function calling not enabled for model deepseek/deepseek-chat. Mocking function calling via prompting.
2025-01-14 15:43:21,306 - INFO - [runtime ff2cd705-fc1d-4983-bf65-c35f6c4b19c7-257e3dba1b8c6f1f] Found 0 local microagents.
2025-01-14 15:43:21,310 - INFO - [Agent Controller default] Setting agent(CodeActAgent) state from AgentState.LOADING to AgentState.RUNNING
2025-01-14 15:43:21,310 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 0 GLOBAL STEP 0
2025-01-14 15:43:25,846 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 1 GLOBAL STEP 1
2025-01-14 15:43:30,876 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 2 GLOBAL STEP 2
2025-01-14 15:43:36,335 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 3 GLOBAL STEP 3
2025-01-14 15:43:41,036 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 4 GLOBAL STEP 4
2025-01-14 15:43:44,822 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 5 GLOBAL STEP 5
2025-01-14 15:43:50,051 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 6 GLOBAL STEP 6
2025-01-14 15:43:56,261 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 7 GLOBAL STEP 7
2025-01-14 15:44:02,775 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 8 GLOBAL STEP 8
2025-01-14 15:44:12,779 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 9 GLOBAL STEP 9
2025-01-14 15:44:17,470 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 10 GLOBAL STEP 10
2025-01-14 15:44:25,946 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 11 GLOBAL STEP 11
2025-01-14 15:44:30,811 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 12 GLOBAL STEP 12
2025-01-14 15:44:41,481 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 13 GLOBAL STEP 13
2025-01-14 15:44:46,082 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 14 GLOBAL STEP 14
2025-01-14 15:44:55,087 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 15 GLOBAL STEP 15
2025-01-14 15:45:06,889 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 16 GLOBAL STEP 16
2025-01-14 15:45:19,591 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 17 GLOBAL STEP 17
2025-01-14 15:45:25,039 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 18 GLOBAL STEP 18
2025-01-14 15:45:37,497 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 19 GLOBAL STEP 19
2025-01-14 15:45:50,696 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 20 GLOBAL STEP 20
2025-01-14 15:45:56,053 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 21 GLOBAL STEP 21
2025-01-14 15:46:09,994 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 22 GLOBAL STEP 22
2025-01-14 15:46:15,062 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 23 GLOBAL STEP 23
2025-01-14 15:46:26,561 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 24 GLOBAL STEP 24
2025-01-14 15:46:41,564 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 25 GLOBAL STEP 25
2025-01-14 15:46:46,660 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 26 GLOBAL STEP 26
2025-01-14 15:46:59,082 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 27 GLOBAL STEP 27
2025-01-14 15:47:05,649 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 28 GLOBAL STEP 28
2025-01-14 15:47:26,032 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 29 GLOBAL STEP 29
2025-01-14 15:47:32,916 - INFO - [Agent Controller default] LEVEL 0 LOCAL STEP 30 GLOBAL STEP 30
2025-01-14 15:47:32,916 - INFO - [Agent Controller default] Setting agent(CodeActAgent) state from AgentState.RUNNING to AgentState.ERROR
2025-01-14 15:47:32,917 - ERROR - RuntimeError: Agent reached maximum iteration in headless mode. Current iteration: 30, max iteration: 30
2025-01-14 15:47:32,918 - WARNING - Stopping agent due to traffic control
2025-01-14 15:47:32,918 - INFO - [Agent Controller default] Setting agent(CodeActAgent) state from AgentState.ERROR to AgentState.ERROR
2025-01-14 15:47:33,555 - INFO - ------------------------------
2025-01-14 15:47:33,555 - INFO - BEGIN Runtime Completion Fn
2025-01-14 15:47:33,556 - INFO - ------------------------------
2025-01-14 15:47:33,556 - INFO - **CmdRunAction (source=None)**
COMMAND:
cd /workspace/pytest-dev__pytest__6.0
2025-01-14 15:47:34,184 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace/pytest-dev__pytest__6.0",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--

[The command completed with exit code 0.]
[Current working directory: /workspace/pytest-dev__pytest__6.0]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:47:34,184 - INFO - **CmdRunAction (source=None)**
COMMAND:
git config --global core.pager ""
2025-01-14 15:47:34,810 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace/pytest-dev__pytest__6.0",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--

[The command completed with exit code 0.]
[Current working directory: /workspace/pytest-dev__pytest__6.0]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:47:34,810 - INFO - **CmdRunAction (source=None)**
COMMAND:
git add -A
2025-01-14 15:47:35,435 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace/pytest-dev__pytest__6.0",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--

[The command completed with exit code 0.]
[Current working directory: /workspace/pytest-dev__pytest__6.0]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:47:35,435 - INFO - **CmdRunAction (source=None)**
COMMAND:
git diff --no-color --cached 7f7a36478abe7dd1fa993b115d22606aa0e35e88
2025-01-14 15:47:36,062 - INFO - **CmdOutputObservation (source=None, exit code=0, metadata={
  "exit_code": 0,
  "pid": -1,
  "username": "root",
  "hostname": "6dfe0ec324c7",
  "working_dir": "/workspace/pytest-dev__pytest__6.0",
  "py_interpreter_path": "/opt/miniconda3/envs/testbed/bin/python",
  "prefix": "",
  "suffix": "\n[The command completed with exit code 0.]"
})**
--BEGIN AGENT OBSERVATION--
diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py
index 335e10996..31e7d2df5 100644
--- a/src/_pytest/skipping.py
+++ b/src/_pytest/skipping.py
@@ -238,30 +238,44 @@ def pytest_runtest_setup(item: Item) -> None:
         item._store[skipped_by_mark_key] = True
         skip(skipped.reason)

+    # Always re-evaluate xfail markers before test setup
+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
     if not item.config.option.runxfail:
-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
         if xfailed and not xfailed.run:
             xfail("[NOTRUN] " + xfailed.reason)
+        # If there's an xfail marker, set the expected failure state
+        elif xfailed:
+            item._expected_failure = True
+            # Mark the test as expected to fail
+            item._store[xfailed_key] = xfailed
+            item._expected_failure_reason = xfailed.reason
+            # If we're in the call phase, mark as xfail immediately
+            if hasattr(item, '_request') and item._request.node == item:
+                xfail(xfailed.reason)


 @hookimpl(hookwrapper=True)
 def pytest_runtest_call(item: Item) -> Generator[None, None, None]:
-    xfailed = item._store.get(xfailed_key, None)
-    if xfailed is None:
-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
-
+    # Evaluate xfail markers before test execution
+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
+
     if not item.config.option.runxfail:
         if xfailed and not xfailed.run:
             xfail("[NOTRUN] " + xfailed.reason)

+    # Execute the test
     yield

+    # Re-evaluate xfail markers after test execution in case they were added dynamically
+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
+

 @hookimpl(hookwrapper=True)
 def pytest_runtest_makereport(item: Item, call: CallInfo[None]):
     outcome = yield
     rep = outcome.get_result()
-    xfailed = item._store.get(xfailed_key, None)
+    # Re-evaluate xfail markers in case they were added dynamically during test execution
+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
     # unittest special case, see setting of unexpectedsuccess_key
     if unexpectedsuccess_key in item._store and rep.when == "call":
         reason = item._store[unexpectedsuccess_key]
@@ -276,21 +290,35 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):
         assert call.excinfo.value.msg is not None
         rep.wasxfail = "reason: " + call.excinfo.value.msg
         rep.outcome = "skipped"
-    elif not rep.skipped and xfailed:
-        if call.excinfo:
-            raises = xfailed.raises
-            if raises is not None and not isinstance(call.excinfo.value, raises):
-                rep.outcome = "failed"
-            else:
-                rep.outcome = "skipped"
-                rep.wasxfail = xfailed.reason
-        elif call.when == "call":
-            if xfailed.strict:
-                rep.outcome = "failed"
-                rep.longrepr = "[XPASS(strict)] " + xfailed.reason
-            else:
-                rep.outcome = "passed"
-                rep.wasxfail = xfailed.reason
+    elif not rep.skipped:
+        # Check for dynamically added xfail markers
+        xfailed = item._store.get(xfailed_key, None)
+        if xfailed is None:
+            xfailed = evaluate_xfail_marks(item)
+            item._store[xfailed_key] = xfailed
+
+        # Check for expected failure state
+        if xfailed or getattr(item, '_expected_failure', False):
+            reason = xfailed.reason if xfailed else getattr(item, '_expected_failure_reason', 'xfail')
+            if call.excinfo:
+                raises = xfailed.raises if xfailed else None
+                if raises is not None and not isinstance(call.excinfo.value, raises):
+                    rep.outcome = "failed"
+                else:
+                    rep.outcome = "skipped"
+                    rep.wasxfail = reason
+                    # If this is a dynamically added xfail, mark as skipped
+                    if getattr(item, '_expected_failure', False):
+                        rep.outcome = "skipped"
+                        rep.wasxfail = reason
+            elif call.when == "call":
+                strict = xfailed.strict if xfailed else False
+                if strict:
+                    rep.outcome = "failed"
+                    rep.longrepr = "[XPASS(strict)] " + reason
+                else:
+                    rep.outcome = "passed"
+                    rep.wasxfail = reason

     if (
         item._store.get(skipped_by_mark_key, True)
diff --git a/test_xfail.py b/test_xfail.py
new file mode 100644
index 000000000..e1d30df0c
--- /dev/null
+++ b/test_xfail.py
@@ -0,0 +1,6 @@
+import pytest
+
+def test_xfail_test(request):
+    mark = pytest.mark.xfail(reason="xfail")
+    request.node.add_marker(mark)
+    assert 0
\ No newline at end of file
[The command completed with exit code 0.]
[Current working directory: /workspace/pytest-dev__pytest__6.0]
[Python interpreter: /opt/miniconda3/envs/testbed/bin/python]
--END AGENT OBSERVATION--
2025-01-14 15:47:36,062 - INFO - ------------------------------
2025-01-14 15:47:36,062 - INFO - END Runtime Completion Fn
2025-01-14 15:47:36,062 - INFO - ------------------------------
2025-01-14 15:47:36,062 - INFO - Got git diff for instance pytest-dev__pytest-7490:
--------
diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py
index 335e10996..31e7d2df5 100644
--- a/src/_pytest/skipping.py
+++ b/src/_pytest/skipping.py
@@ -238,30 +238,44 @@ def pytest_runtest_setup(item: Item) -> None:
         item._store[skipped_by_mark_key] = True
         skip(skipped.reason)

+    # Always re-evaluate xfail markers before test setup
+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
     if not item.config.option.runxfail:
-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
         if xfailed and not xfailed.run:
             xfail("[NOTRUN] " + xfailed.reason)
+        # If there's an xfail marker, set the expected failure state
+        elif xfailed:
+            item._expected_failure = True
+            # Mark the test as expected to fail
+            item._store[xfailed_key] = xfailed
+            item._expected_failure_reason = xfailed.reason
+            # If we're in the call phase, mark as xfail immediately
+            if hasattr(item, '_request') and item._request.node == item:
+                xfail(xfailed.reason)


 @hookimpl(hookwrapper=True)
 def pytest_runtest_call(item: Item) -> Generator[None, None, None]:
-    xfailed = item._store.get(xfailed_key, None)
-    if xfailed is None:
-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
-
+    # Evaluate xfail markers before test execution
+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
+
     if not item.config.option.runxfail:
         if xfailed and not xfailed.run:
             xfail("[NOTRUN] " + xfailed.reason)

+    # Execute the test
     yield

+    # Re-evaluate xfail markers after test execution in case they were added dynamically
+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
+

 @hookimpl(hookwrapper=True)
 def pytest_runtest_makereport(item: Item, call: CallInfo[None]):
     outcome = yield
     rep = outcome.get_result()
-    xfailed = item._store.get(xfailed_key, None)
+    # Re-evaluate xfail markers in case they were added dynamically during test execution
+    item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
     # unittest special case, see setting of unexpectedsuccess_key
     if unexpectedsuccess_key in item._store and rep.when == "call":
         reason = item._store[unexpectedsuccess_key]
@@ -276,21 +290,35 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):
         assert call.excinfo.value.msg is not None
         rep.wasxfail = "reason: " + call.excinfo.value.msg
         rep.outcome = "skipped"
-    elif not rep.skipped and xfailed:
-        if call.excinfo:
-            raises = xfailed.raises
-            if raises is not None and not isinstance(call.excinfo.value, raises):
-                rep.outcome = "failed"
-            else:
-                rep.outcome = "skipped"
-                rep.wasxfail = xfailed.reason
-        elif call.when == "call":
-            if xfailed.strict:
-                rep.outcome = "failed"
-                rep.longrepr = "[XPASS(strict)] " + xfailed.reason
-            else:
-                rep.outcome = "passed"
-                rep.wasxfail = xfailed.reason
+    elif not rep.skipped:
+        # Check for dynamically added xfail markers
+        xfailed = item._store.get(xfailed_key, None)
+        if xfailed is None:
+            xfailed = evaluate_xfail_marks(item)
+            item._store[xfailed_key] = xfailed
+
+        # Check for expected failure state
+        if xfailed or getattr(item, '_expected_failure', False):
+            reason = xfailed.reason if xfailed else getattr(item, '_expected_failure_reason', 'xfail')
+            if call.excinfo:
+                raises = xfailed.raises if xfailed else None
+                if raises is not None and not isinstance(call.excinfo.value, raises):
+                    rep.outcome = "failed"
+                else:
+                    rep.outcome = "skipped"
+                    rep.wasxfail = reason
+                    # If this is a dynamically added xfail, mark as skipped
+                    if getattr(item, '_expected_failure', False):
+                        rep.outcome = "skipped"
+                        rep.wasxfail = reason
+            elif call.when == "call":
+                strict = xfailed.strict if xfailed else False
+                if strict:
+                    rep.outcome = "failed"
+                    rep.longrepr = "[XPASS(strict)] " + reason
+                else:
+                    rep.outcome = "passed"
+                    rep.wasxfail = reason

     if (
         item._store.get(skipped_by_mark_key, True)
diff --git a/test_xfail.py b/test_xfail.py
new file mode 100644
index 000000000..e1d30df0c
--- /dev/null
+++ b/test_xfail.py
@@ -0,0 +1,6 @@
+import pytest
+
+def test_xfail_test(request):
+    mark = pytest.mark.xfail(reason="xfail")
+    request.node.add_marker(mark)
+    assert 0
\ No newline at end of file
--------
2025-01-14 15:47:36,757 - INFO - Using instance container image: docker.io/xingyaoww/sweb.eval.x86_64.sympy_s_sympy-18199. Please make sure this image exists. Submit an issue on https://github.com/All-Hands-AI/OpenHands if you run into any issues.
2025-01-14 15:47:36,758 - INFO - Logging LLM completions for instance sympy__sympy-18199 to evaluation/evaluation_outputs/outputs/princeton-nlp__SWE-bench_Verified-test/CodeActAgent/deepseek-chat_maxiter_30_N_v0.20.0-no-hint-run_1/llm_completions/sympy__sympy-18199

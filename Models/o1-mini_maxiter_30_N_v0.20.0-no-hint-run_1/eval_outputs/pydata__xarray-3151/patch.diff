diff --git a/reproduce_error.py b/reproduce_error.py
new file mode 100644
index 00000000..97a4f84f
--- /dev/null
+++ b/reproduce_error.py
@@ -0,0 +1,27 @@
+import xarray as xr
+import numpy as np
+
+# yCoord = ['a', 'b', 'c']  # works without error
+yCoord = ['a', 'c', 'b']  # raises ValueError on combine
+
+ds1 = xr.Dataset(
+    data_vars=dict(
+        data=(['x', 'y'], np.random.rand(3, 3))
+    ),
+    coords=dict(
+        x=[1, 2, 3],
+        y=yCoord
+    )
+)
+
+ds2 = xr.Dataset(
+    data_vars=dict(
+        data=(['x', 'y'], np.random.rand(4, 3))
+    ),
+    coords=dict(
+        x=[4, 5, 6, 7],
+        y=yCoord
+    )
+)
+
+ds3 = xr.combine_by_coords((ds1, ds2))
\ No newline at end of file
diff --git a/xarray/core/combine.py b/xarray/core/combine.py
index 37ae903b..0acaa094 100644
--- a/xarray/core/combine.py
+++ b/xarray/core/combine.py
@@ -78,26 +78,7 @@ def _infer_concat_order_from_coords(datasets):
                 elif all(index.is_monotonic_decreasing for index in indexes):
                     ascending = False
                 else:
-                    raise ValueError("Coordinate variable {} is neither "
-                                     "monotonically increasing nor "
-                                     "monotonically decreasing on all datasets"
-                                     .format(dim))
-
-                # Assume that any two datasets whose coord along dim starts
-                # with the same value have the same coord values throughout.
-                if any(index.size == 0 for index in indexes):
-                    raise ValueError('Cannot handle size zero dimensions')
-                first_items = pd.Index([index.take([0])
-                                        for index in indexes])
-
-                # Sort datasets along dim
-                # We want rank but with identical elements given identical
-                # position indices - they should be concatenated along another
-                # dimension, not along this one
-                series = first_items.to_series()
-                rank = series.rank(method='dense', ascending=ascending)
-                order = rank.astype(int).values - 1
-
+        raise ValueError("Coordinate variable {} is neither monotonically increasing nor monotonically decreasing on all datasets".format(dim))
                 # Append positions along extra dimension to structure which
                 # encodes the multi-dimensional concatentation order
                 tile_ids = [tile_id + (position,) for tile_id, position
@@ -113,9 +94,8 @@ def _infer_concat_order_from_coords(datasets):


 def _check_shape_tile_ids(combined_tile_ids):
-    tile_ids = combined_tile_ids.keys()
-
-    # Check all tuples are the same length
+    if len(datasets) > 1 and not concat_dims:
+        return merge(datasets, compat='no_conflicts')
     # i.e. check that all lists are nested to the same depth
     nesting_depths = [len(tile_id) for tile_id in tile_ids]
     if not nesting_depths:

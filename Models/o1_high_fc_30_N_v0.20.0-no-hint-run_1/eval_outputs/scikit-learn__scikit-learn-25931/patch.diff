diff --git a/sklearn/ensemble/_iforest.py b/sklearn/ensemble/_iforest.py
index 4d6c1c3f0..378e73d9a 100644
--- a/sklearn/ensemble/_iforest.py
+++ b/sklearn/ensemble/_iforest.py
@@ -288,7 +288,7 @@ class IsolationForest(OutlierMixin, BaseBagging):
             Fitted estimator.
         """
         self._validate_params()
-        X = self._validate_data(X, accept_sparse=["csc"], dtype=tree_dtype)
+        X = self._validate_data(X, accept_sparse=["csc"], dtype=tree_dtype, check_feature_names=False)
         if issparse(X):
             # Pre-sort indices to avoid that each individual tree of the
             # ensemble sorts the indices.
@@ -328,6 +328,10 @@ class IsolationForest(OutlierMixin, BaseBagging):
             check_input=False,
         )

+        # Workaround to avoid warning about feature names in predict if a DataFrame is passed.
+        if hasattr(self, 'feature_names_in_'):
+            del self.feature_names_in_
+
         self._average_path_length_per_tree, self._decision_path_lengths = zip(
             *[
                 (
@@ -342,10 +346,18 @@ class IsolationForest(OutlierMixin, BaseBagging):
             # 0.5 plays a special role as described in the original paper.
             # we take the opposite as we consider the opposite of their score.
             self.offset_ = -0.5
+        # Remove feature_names_in_ to avoid mismatch
+        if hasattr(self, 'feature_names_in_'):
+            del self.feature_names_in_
+
             return self

         # else, define offset_ wrt contamination parameter
-        self.offset_ = np.percentile(self.score_samples(X), 100.0 * self.contamination)
+        if issparse(X):
+    X_ = X
+else:
+    X_ = X.to_numpy()
+self.offset_ = np.percentile(self.score_samples(X_), 100.0 * self.contamination)

         return self

@@ -433,7 +445,7 @@ class IsolationForest(OutlierMixin, BaseBagging):
         check_is_fitted(self)

         # Check data
-        X = self._validate_data(X, accept_sparse="csr", dtype=np.float32, reset=False)
+        X = self._validate_data(X, accept_sparse=["csc", "csr"], dtype=tree_dtype, reset=False, check_feature_names=False)

         # Take the opposite of the scores as bigger is better (here less
         # abnormal)

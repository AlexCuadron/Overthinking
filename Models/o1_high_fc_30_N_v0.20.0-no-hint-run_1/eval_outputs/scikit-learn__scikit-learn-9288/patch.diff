diff --git a/sklearn/cluster/k_means_.py b/sklearn/cluster/k_means_.py
index b7fbdf7da..d1deb2191 100644
--- a/sklearn/cluster/k_means_.py
+++ b/sklearn/cluster/k_means_.py
@@ -175,10 +175,7 @@ def _check_normalize_sample_weight(sample_weight, X):
     return sample_weight


-def k_means(X, n_clusters, sample_weight=None, init='k-means++',
-            precompute_distances='auto', n_init=10, max_iter=300,
-            verbose=False, tol=1e-4, random_state=None, copy_x=True,
-            n_jobs=None, algorithm="auto", return_n_iter=False):
+def k_means(X, n_clusters, sample_weight=None, init='k-means++',\n            precompute_distances='auto', n_init=10, max_iter=300,\n            verbose=False, tol=1e-4, random_state=None, copy_x=True,\n            n_jobs=None, algorithm="auto", return_n_iter=False):\n    # Force a single-threaded run to ensure identical float summations\n    n_jobs = 1
     """K-means clustering algorithm.

     Read more in the :ref:`User Guide <k_means>`.
@@ -352,7 +349,7 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++',
         # the right result.
         algorithm = "full"
     if algorithm == "auto":
-        algorithm = "full" if sp.issparse(X) else 'elkan'
+        algorithm = 'full'  # Force to use full for consistency
     if algorithm == "full":
         kmeans_single = _kmeans_single_lloyd
     elif algorithm == "elkan":
@@ -360,41 +357,22 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++',
     else:
         raise ValueError("Algorithm must be 'auto', 'full' or 'elkan', got"
                          " %s" % str(algorithm))
-    if effective_n_jobs(n_jobs) == 1:
-        # For a single thread, less memory is needed if we just store one set
-        # of the best results (as opposed to one set per run per thread).
-        for it in range(n_init):
-            # run a k-means once
-            labels, inertia, centers, n_iter_ = kmeans_single(
-                X, sample_weight, n_clusters, max_iter=max_iter, init=init,
-                verbose=verbose, precompute_distances=precompute_distances,
-                tol=tol, x_squared_norms=x_squared_norms,
-                random_state=random_state)
-            # determine if these results are the best so far
-            if best_inertia is None or inertia < best_inertia:
-                best_labels = labels.copy()
-                best_centers = centers.copy()
-                best_inertia = inertia
-                best_n_iter = n_iter_
-    else:
-        # parallelisation of k-means runs
-        seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)
-        results = Parallel(n_jobs=n_jobs, verbose=0)(
-            delayed(kmeans_single)(X, sample_weight, n_clusters,
-                                   max_iter=max_iter, init=init,
-                                   verbose=verbose, tol=tol,
-                                   precompute_distances=precompute_distances,
-                                   x_squared_norms=x_squared_norms,
-                                   # Change seed to ensure variety
-                                   random_state=seed)
-            for seed in seeds)
-        # Get results with the lowest inertia
-        labels, inertia, centers, n_iters = zip(*results)
-        best = np.argmin(inertia)
-        best_labels = labels[best]
-        best_inertia = inertia[best]
-        best_centers = centers[best]
-        best_n_iter = n_iters[best]
+    # Force single path
+    seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)
+    results = []
+    for it in range(n_init):
+        labels, inertia, centers, n_iter_ = kmeans_single(
+            X, sample_weight, n_clusters, max_iter=max_iter, init=init,
+            verbose=verbose, precompute_distances=precompute_distances,
+            tol=tol, x_squared_norms=x_squared_norms,
+            random_state=seeds[it])
+        results.append((labels, inertia, centers, n_iter_))
+    labels, inertia, centers, n_iters = zip(*results)
+    best = np.argmin(inertia)
+    best_labels = labels[best]
+    best_inertia = inertia[best]
+    best_centers = centers[best]
+    best_n_iter = n_iters[best]

     if not sp.issparse(X):
         if not copy_x:

diff --git a/reproduce_error.py b/reproduce_error.py
new file mode 100644
index 000000000..4f7b5f9c1
--- /dev/null
+++ b/reproduce_error.py
@@ -0,0 +1,10 @@
+import numpy as np
+from sklearn.linear_model import LogisticRegressionCV
+
+np.random.seed(29)
+X = np.random.normal(size=(1000, 3))
+beta = np.random.normal(size=3)
+intercept = np.random.normal(size=None)
+y = np.sign(intercept + X @ beta)
+
+LogisticRegressionCV(cv=5, solver='saga', tol=1e-2, refit=False).fit(X, y)
\ No newline at end of file
diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py
index 1999f1dae..86c6c48eb 100644
--- a/sklearn/linear_model/logistic.py
+++ b/sklearn/linear_model/logistic.py
@@ -2112,6 +2112,7 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,
         self.scores_ = dict(zip(classes, scores))
         self.coefs_paths_ = dict(zip(classes, coefs_paths))

+        l1_ratios_ = [1] if self.penalty == 'elasticnet' else [0]
         self.C_ = list()
         self.l1_ratio_ = list()
         self.coef_ = np.empty((n_classes, X.shape[1]))
@@ -2174,14 +2175,14 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,
                     w = np.mean([coefs_paths[i, best_indices[i], :]
                                  for i in range(len(folds))], axis=0)
                 else:
-                    w = np.mean([coefs_paths[:, i, best_indices[i], :]
+                    w = np.mean([coefs_paths[i, best_indices[i], :]
                                  for i in range(len(folds))], axis=0)

                 best_indices_C = best_indices % len(self.Cs_)
                 self.C_.append(np.mean(self.Cs_[best_indices_C]))

                 best_indices_l1 = best_indices // len(self.Cs_)
-                self.l1_ratio_.append(np.mean(l1_ratios_[best_indices_l1]))
+                self.l1_ratio_.append(np.mean(l1_ratios_))

             if multi_class == 'multinomial':
                 self.C_ = np.tile(self.C_, n_classes)
